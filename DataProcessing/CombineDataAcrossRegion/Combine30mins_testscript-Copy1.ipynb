{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f2d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "import os\n",
    "import glob as glob\n",
    "import datetime as datetime\n",
    "import iris.coord_categorisation as cat\n",
    "import sys\n",
    "import iris.plot as iplt\n",
    "\n",
    "# Set up path to root directory\n",
    "root_fp = \"/nfs/a319/gy17m2a/PhD/\"\n",
    "os.chdir(root_fp)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Create path to files containing functions\n",
    "sys.path.insert(0, root_fp + 'Scripts/GlobalFunctions')\n",
    "from Spatial_plotting_functions import *\n",
    "from Spatial_geometry_functions import *\n",
    "\n",
    "\n",
    "# ### Load necessary spatial data\n",
    "# This is a square area surrounding Leeds\n",
    "leeds_at_centre_gdf = create_leeds_at_centre_outline({'init' :'epsg:3857'})\n",
    "\n",
    "\n",
    "# ### Establish the corresponding ensemble member numbers\n",
    "em_matching_dict = {'01':'bc005', '04': 'bc006', '05': 'bc007', '06':'bc009',  '07':'bc010', \n",
    "                    '08': 'bc011', '09':'bc013', '10': 'bc015', '11': 'bc016', '12': 'bc017', '13':'bc018', '15':'bc012'}\n",
    "\n",
    "resolution = '2.2km'\n",
    "yrs_range = \"2002_2020\"\n",
    "# em_1hr = '05'\n",
    "# yr = 2012\n",
    "# month_num = '06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "228778af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em09, yr 2006, month 01\n",
      "already exists\n",
      "em09, yr 2006, month 02\n",
      "already exists\n",
      "em09, yr 2006, month 03\n",
      "already exists\n",
      "em09, yr 2006, month 04\n",
      "already exists\n",
      "em09, yr 2006, month 05\n",
      "already exists\n",
      "em09, yr 2006, month 06\n",
      "already exists\n",
      "em09, yr 2006, month 07\n",
      "already exists\n",
      "em09, yr 2006, month 08\n",
      "already exists\n",
      "em09, yr 2006, month 09\n",
      "already exists\n",
      "em09, yr 2006, month 10\n",
      "already exists\n",
      "em09, yr 2006, month 11\n",
      "already exists\n",
      "em09, yr 2006, month 12\n",
      "already exists\n",
      "em09, yr 2007, month 01\n",
      "already exists\n",
      "em09, yr 2007, month 02\n",
      "already exists\n",
      "em09, yr 2007, month 03\n",
      "already exists\n",
      "em09, yr 2007, month 04\n",
      "already exists\n",
      "em09, yr 2007, month 05\n",
      "already exists\n",
      "em09, yr 2007, month 06\n",
      "already exists\n",
      "em09, yr 2007, month 07\n",
      "already exists\n",
      "em09, yr 2007, month 08\n",
      "already exists\n",
      "em09, yr 2007, month 09\n",
      "already exists\n",
      "em09, yr 2007, month 10\n",
      "already exists\n",
      "em09, yr 2007, month 11\n",
      "already exists\n",
      "em09, yr 2007, month 12\n",
      "already exists\n",
      "em09, yr 2008, month 01\n",
      "already exists\n",
      "em09, yr 2008, month 02\n",
      "already exists\n",
      "em09, yr 2008, month 03\n",
      "already exists\n",
      "em09, yr 2008, month 04\n",
      "already exists\n",
      "em09, yr 2008, month 05\n",
      "already exists\n",
      "em09, yr 2008, month 06\n",
      "already exists\n",
      "em09, yr 2008, month 07\n",
      "already exists\n",
      "em09, yr 2008, month 08\n",
      "already exists\n",
      "em09, yr 2008, month 09\n",
      "already exists\n",
      "em09, yr 2008, month 10\n",
      "already exists\n",
      "em09, yr 2008, month 11\n",
      "already exists\n",
      "em09, yr 2008, month 12\n",
      "already exists\n",
      "em09, yr 2009, month 01\n",
      "already exists\n",
      "em09, yr 2009, month 02\n",
      "already exists\n",
      "em09, yr 2009, month 03\n",
      "already exists\n",
      "em09, yr 2009, month 04\n",
      "already exists\n",
      "em09, yr 2009, month 05\n",
      "already exists\n",
      "em09, yr 2009, month 06\n",
      "already exists\n",
      "em09, yr 2009, month 07\n",
      "already exists\n",
      "em09, yr 2009, month 08\n",
      "already exists\n",
      "em09, yr 2009, month 09\n",
      "already exists\n",
      "em09, yr 2009, month 10\n",
      "already exists\n",
      "em09, yr 2009, month 11\n",
      "already exists\n",
      "em09, yr 2009, month 12\n",
      "already exists\n",
      "em09, yr 2010, month 01\n",
      "already exists\n",
      "em09, yr 2010, month 02\n",
      "already exists\n",
      "em09, yr 2010, month 03\n",
      "already exists\n",
      "em09, yr 2010, month 04\n",
      "already exists\n",
      "em09, yr 2010, month 05\n",
      "already exists\n",
      "em09, yr 2010, month 06\n",
      "already exists\n",
      "em09, yr 2010, month 07\n",
      "already exists\n",
      "em09, yr 2010, month 08\n",
      "already exists\n",
      "em09, yr 2010, month 09\n",
      "already exists\n",
      "em09, yr 2010, month 10\n",
      "already exists\n",
      "em09, yr 2010, month 11\n",
      "already exists\n",
      "em09, yr 2010, month 12\n",
      "already exists\n",
      "em09, yr 2011, month 01\n",
      "already exists\n",
      "em09, yr 2011, month 02\n",
      "already exists\n",
      "em09, yr 2011, month 03\n",
      "already exists\n",
      "em09, yr 2011, month 04\n",
      "already exists\n",
      "em09, yr 2011, month 05\n",
      "already exists\n",
      "em09, yr 2011, month 06\n",
      "already exists\n",
      "em09, yr 2011, month 07\n",
      "already exists\n",
      "em09, yr 2011, month 08\n",
      "already exists\n",
      "em09, yr 2011, month 09\n",
      "already exists\n",
      "em09, yr 2011, month 10\n",
      "already exists\n",
      "em09, yr 2011, month 11\n",
      "already exists\n",
      "em09, yr 2011, month 12\n",
      "already exists\n",
      "em09, yr 2012, month 01\n",
      "already exists\n",
      "em09, yr 2012, month 02\n",
      "already exists\n",
      "em09, yr 2012, month 03\n",
      "already exists\n",
      "em09, yr 2012, month 04\n",
      "already exists\n",
      "em09, yr 2012, month 05\n",
      "already exists\n",
      "em09, yr 2012, month 06\n",
      "already exists\n",
      "em09, yr 2012, month 07\n",
      "already exists\n",
      "em09, yr 2012, month 08\n",
      "already exists\n",
      "em09, yr 2012, month 09\n",
      "already exists\n",
      "em09, yr 2012, month 10\n",
      "already exists\n",
      "em09, yr 2012, month 11\n",
      "already exists\n",
      "em09, yr 2012, month 12\n",
      "already exists\n",
      "em09, yr 2013, month 01\n",
      "already exists\n",
      "em09, yr 2013, month 02\n",
      "already exists\n",
      "em09, yr 2013, month 03\n",
      "already exists\n",
      "em09, yr 2013, month 04\n",
      "already exists\n",
      "em09, yr 2013, month 05\n",
      "already exists\n",
      "em09, yr 2013, month 06\n",
      "already exists\n",
      "em09, yr 2013, month 07\n",
      "already exists\n",
      "em09, yr 2013, month 08\n",
      "already exists\n",
      "em09, yr 2013, month 09\n",
      "already exists\n",
      "em09, yr 2013, month 10\n",
      "already exists\n",
      "em09, yr 2013, month 11\n",
      "already exists\n",
      "em09, yr 2013, month 12\n",
      "already exists\n",
      "em09, yr 2014, month 01\n",
      "already exists\n",
      "em09, yr 2014, month 02\n",
      "already exists\n",
      "em09, yr 2014, month 03\n",
      "already exists\n",
      "em09, yr 2014, month 04\n",
      "already exists\n",
      "em09, yr 2014, month 05\n",
      "already exists\n",
      "em09, yr 2014, month 06\n",
      "already exists\n",
      "em09, yr 2014, month 07\n",
      "already exists\n",
      "em09, yr 2014, month 08\n",
      "already exists\n",
      "em09, yr 2014, month 09\n",
      "already exists\n",
      "em09, yr 2014, month 10\n",
      "already exists\n",
      "em09, yr 2014, month 11\n",
      "already exists\n",
      "em09, yr 2014, month 12\n",
      "already exists\n",
      "em09, yr 2015, month 01\n",
      "already exists\n",
      "em09, yr 2015, month 02\n",
      "already exists\n",
      "em09, yr 2015, month 03\n",
      "already exists\n",
      "em09, yr 2015, month 04\n",
      "already exists\n",
      "em09, yr 2015, month 05\n",
      "already exists\n",
      "em09, yr 2015, month 06\n",
      "already exists\n",
      "em09, yr 2015, month 07\n",
      "already exists\n",
      "em09, yr 2015, month 08\n",
      "already exists\n",
      "em09, yr 2015, month 09\n",
      "already exists\n",
      "em09, yr 2015, month 10\n",
      "already exists\n",
      "em09, yr 2015, month 11\n",
      "already exists\n",
      "em09, yr 2015, month 12\n",
      "already exists\n",
      "em09, yr 2016, month 01\n",
      "already exists\n",
      "em09, yr 2016, month 02\n",
      "already exists\n",
      "em09, yr 2016, month 03\n",
      "already exists\n",
      "em09, yr 2016, month 04\n",
      "already exists\n",
      "em09, yr 2016, month 05\n",
      "Running for month 05 in 2016, for 09 (which equatees to bc013)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function CFReader.__del__ at 0x7f8d39ccfb90>\n",
      "Traceback (most recent call last):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/fileformats/cf.py\", line 1263, in __del__\n",
      "    self._dataset.close()\n",
      "AttributeError: 'CFReader' object has no attribute '_dataset'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists\n",
      "datadir/UKCP18_every30mins/2.2km/bc013/2002_2020/bc013a.pr201605.nc\n",
      "em09, yr 2016, month 06\n",
      "already exists\n",
      "em09, yr 2016, month 07\n",
      "already exists\n",
      "em09, yr 2016, month 08\n",
      "already exists\n",
      "em09, yr 2016, month 09\n",
      "already exists\n",
      "em09, yr 2016, month 10\n",
      "already exists\n",
      "em09, yr 2016, month 11\n",
      "Running for month 11 in 2016, for 09 (which equatees to bc013)\n",
      "Exists\n",
      "datadir/UKCP18_every30mins/2.2km/bc013/2002_2020/bc013a.pr201611.nc\n",
      "em09, yr 2016, month 12\n",
      "already exists\n",
      "em09, yr 2017, month 01\n",
      "already exists\n",
      "em09, yr 2017, month 02\n",
      "already exists\n",
      "em09, yr 2017, month 03\n",
      "already exists\n",
      "em09, yr 2017, month 04\n",
      "already exists\n",
      "em09, yr 2017, month 05\n",
      "already exists\n",
      "em09, yr 2017, month 06\n",
      "already exists\n",
      "em09, yr 2017, month 07\n",
      "already exists\n",
      "em09, yr 2017, month 08\n",
      "already exists\n",
      "em09, yr 2017, month 09\n",
      "already exists\n",
      "em09, yr 2017, month 10\n",
      "already exists\n",
      "em09, yr 2017, month 11\n",
      "already exists\n",
      "em09, yr 2017, month 12\n",
      "already exists\n",
      "em09, yr 2018, month 01\n",
      "already exists\n",
      "em09, yr 2018, month 02\n",
      "already exists\n",
      "em09, yr 2018, month 03\n",
      "already exists\n",
      "em09, yr 2018, month 04\n",
      "already exists\n",
      "em09, yr 2018, month 05\n",
      "already exists\n",
      "em09, yr 2018, month 06\n",
      "already exists\n",
      "em09, yr 2018, month 07\n",
      "already exists\n",
      "em09, yr 2018, month 08\n",
      "already exists\n",
      "em09, yr 2018, month 09\n",
      "already exists\n",
      "em09, yr 2018, month 10\n",
      "already exists\n",
      "em09, yr 2018, month 11\n",
      "already exists\n",
      "em09, yr 2018, month 12\n",
      "already exists\n",
      "em09, yr 2019, month 01\n",
      "already exists\n",
      "em09, yr 2019, month 02\n",
      "already exists\n",
      "em09, yr 2019, month 03\n",
      "already exists\n",
      "em09, yr 2019, month 04\n",
      "already exists\n",
      "em09, yr 2019, month 05\n",
      "already exists\n",
      "em09, yr 2019, month 06\n",
      "already exists\n",
      "em09, yr 2019, month 07\n",
      "already exists\n",
      "em09, yr 2019, month 08\n",
      "already exists\n",
      "em09, yr 2019, month 09\n",
      "already exists\n",
      "em09, yr 2019, month 10\n",
      "already exists\n",
      "em09, yr 2019, month 11\n",
      "already exists\n",
      "em09, yr 2019, month 12\n",
      "already exists\n"
     ]
    }
   ],
   "source": [
    "# for em_1hr in ['01', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '15']:\n",
    "for em_1hr in ['09']:\n",
    "    em_30mins = em_matching_dict[em_1hr]\n",
    "    for yr in range(2006,2020):\n",
    "        for month_num in ['01', '02','03','04', '05', '06', '07', '08', '09', '10','11','12']:\n",
    "            print(f\"em{em_1hr}, yr {yr}, month {month_num}\")\n",
    "            if (os.path.isfile(f\"/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/{resolution}/{em_30mins}/{yrs_range}/{em_30mins}a.pr{yr}{month_num}.nc\")):\n",
    "                print(\"already exists\")\n",
    "            else:\n",
    "                print(f\"Running for month {month_num} in {yr}, for {em_1hr} (which equatees to {em_30mins})\")\n",
    "\n",
    "                ####################################################### \n",
    "                #######################################################\n",
    "                ## Get one month of data - HOURLY\n",
    "                ####################################################### \n",
    "                #######################################################\n",
    "                ### Get a list of filenames for hourly data\n",
    "                general_filename_1hr = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km/{em_1hr}/{yrs_range}/pr_rcp85_land-cpm_uk_2.2km_{em_1hr}_1hr_{yr}{month_num}*'\n",
    "                filenames_1hr = []\n",
    "                for filename in glob.glob(general_filename_1hr):\n",
    "                        filenames_1hr.append(filename)\n",
    "                # If don't find any files matching this string in the 2001_2020 folder, then check the 1980_2001\n",
    "                if len(filenames_1hr) == 0:\n",
    "                    general_filename_1hr = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km/{em_1hr}/1980_2001/pr_rcp85_land-cpm_uk_2.2km_{em_1hr}_1hr_{yr}{month_num}*'\n",
    "                    for filename in glob.glob(general_filename_1hr):\n",
    "                            filenames_1hr.append(filename)\n",
    "                    print(len(filenames_1hr))\n",
    "\n",
    "                # ### Load in the data and remove the ensemble member dimension\n",
    "                monthly_cubes_list_1hr = iris.load(filenames_1hr)\n",
    "                cube_1hr = monthly_cubes_list_1hr[0]\n",
    "                cube_1hr = cube_1hr[0,:,:,:]\n",
    "\n",
    "                # ### Trim to Leeds\n",
    "                # cube_1hr = trim_to_bbox_of_region(cube_1hr, leeds_at_centre_gdf)\n",
    "\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                ## Get one month of data - 30mins\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                # ### Get all files for this ensemble member\n",
    "                general_filename_30mins = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_first30mins/{yrs_range}/{em_30mins}/{em_30mins}a.pr{yr}{month_num}*'\n",
    "                filenames_first30mins = []\n",
    "                for filename_30mins in glob.glob(general_filename_30mins):\n",
    "                    filenames_first30mins.append(filename_30mins)\n",
    "                filenames_first30mins.sort()\n",
    "\n",
    "                # ### Load in the data \n",
    "                monthly_cubes_list_30mins = iris.load(filenames_first30mins)\n",
    "\n",
    "                # Equalise\n",
    "                for cube in monthly_cubes_list_30mins:\n",
    "                    for attr in ['forecast_period', 'forecast_reference_time']:\n",
    "                        if attr in cube.attributes:\n",
    "                            del cube.attributes[attr]\n",
    "\n",
    "\n",
    "                monthly_cube_30mins = monthly_cubes_list_30mins.concatenate_cube()      \n",
    "\n",
    "                # ### Trim to be the same shape as the hourly data\n",
    "                # monthly_cube_30mins_1st = trim_to_bbox_of_region_30mins(monthly_cube_30mins, leeds_at_centre_gdf)\n",
    "                monthly_cube_30mins_1st = monthly_cube_30mins[:,24:-24,24:-24]\n",
    "\n",
    "                # ### Convert units of 30 mins data\n",
    "                # Check current units\n",
    "                # print(monthly_cube_30mins_1st.units)\n",
    "                # Set the units to those of the 1 hr cube\n",
    "                monthly_cube_30mins_1st.units = cube_1hr.units\n",
    "                # print(monthly_cube_30mins_1st.units)\n",
    "\n",
    "                # Convert the data to also be this unit\n",
    "                monthly_cube_30mins_1st_data = monthly_cube_30mins_1st.data\n",
    "                monthly_cube_30mins_1st_data = monthly_cube_30mins_1st_data*3600\n",
    "\n",
    "                monthly_cube_30mins_1st.data = monthly_cube_30mins_1st_data\n",
    "\n",
    "\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                ## Find the second half of the hour, using the first half of hour and hourly values\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                # get the hourly data\n",
    "                cube_1hr_data = cube_1hr.data\n",
    "                # calculate value for second half of hour\n",
    "                second_half_of_the_hour_mean_hourly_rainfall_rate_data = 2*cube_1hr_data-monthly_cube_30mins_1st_data\n",
    "                # Create a new cube for the second half of the hour (start by copying the first half of hour cube)\n",
    "                monthly_cube_30mins_2nd = monthly_cube_30mins_1st.copy()\n",
    "                # Set values as calculated\n",
    "                monthly_cube_30mins_2nd.data = second_half_of_the_hour_mean_hourly_rainfall_rate_data\n",
    "\n",
    "\n",
    "                # ### Edit the times to be 30 mins later\n",
    "                # get the times from the first half hour\n",
    "                first_half_hour_times = monthly_cube_30mins_1st.coord('time').copy()\n",
    "                # add 30 mins\n",
    "                second_half_hour_times = first_half_hour_times + 0.5\n",
    "                # for the second hald hour cube, remove the time dimension and then re-add the edited one\n",
    "                monthly_cube_30mins_2nd.remove_coord('time')\n",
    "                monthly_cube_30mins_2nd.add_dim_coord(second_half_hour_times, 0)\n",
    "\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                ## Join first half hour and second half hour into one cube\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                # ### Get a list of all the cubes in each of the monthly cubes\n",
    "                list_30mins_1st = iris.cube.CubeList(monthly_cube_30mins_1st.slices_over('time'))\n",
    "                list_30mins_2nd = iris.cube.CubeList(monthly_cube_30mins_2nd.slices_over('time'))\n",
    "                list_30mins = list_30mins_1st +  list_30mins_2nd\n",
    "\n",
    "                ### Merge back into one cube\n",
    "                monthly_cube_30mins = list_30mins.merge_cube()\n",
    "\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                ## Save\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                dir_to_save = f\"datadir/UKCP18_every30mins/{resolution}/{em_30mins}/{yrs_range}/\"\n",
    "\n",
    "                if os.path.isdir(dir_to_save):\n",
    "                    print(\"Exists\")\n",
    "                else:\n",
    "                    print(\"Doesn't exist\")\n",
    "                    os.makedirs(dir_to_save)\n",
    "                fp_to_save = f\"datadir/UKCP18_every30mins/{resolution}/{em_30mins}/{yrs_range}/{em_30mins}a.pr{yr}{month_num}.nc\" \n",
    "                print(fp_to_save)\n",
    "                iris.save(monthly_cube_30mins, fp_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca242a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "import os\n",
    "import glob as sir_globington_the_file_gatherer\n",
    "import datetime as datetime\n",
    "import iris.coord_categorisation as cat\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import glob as glob\n",
    "\n",
    "# Set up path to root directory\n",
    "root_fp = \"/nfs/a319/gy17m2a/PhD/\"\n",
    "os.chdir(root_fp)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Create path to files containing functions\n",
    "sys.path.insert(0, root_fp + 'Scripts/GlobalFunctions')\n",
    "from Spatial_plotting_functions import *\n",
    "from Spatial_geometry_functions import *\n",
    "\n",
    "##################################################################\n",
    "# Load necessary spatial data\n",
    "##################################################################\n",
    "# This is a square area surrounding Leeds\n",
    "leeds_at_centre_gdf = create_leeds_at_centre_outline({'init' :'epsg:3857'})\n",
    "uk_gdf = create_uk_outline({'init' :'epsg:3857'})\n",
    "gb_gdf = create_gb_outline({'init' :'epsg:3857'})\n",
    "##################################################################\n",
    "\n",
    "# ### Establish the ensemble member\n",
    "trim_to_leeds = False\n",
    "\n",
    "ems= ['bc005', 'bc006', 'bc007', 'bc009', 'bc010', 'bc011', 'bc013',  'bc015',  'bc016', 'bc017', 'bc018', 'bc012']\n",
    "yrs_range = \"2002_2020\"\n",
    "resolution = '2.2km' #2.2km, 12km, 2.2km_regridded_12km\n",
    "in_jja=iris.Constraint(time=lambda cell: 6 <= cell.point.month <= 8)\n",
    "yrs= range(2001,2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8178f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001 already exists\n",
      "2002 already exists\n",
      "2003 already exists\n",
      "2004 already exists\n",
      "2005 already exists\n",
      "2006 already exists\n",
      "2007 already exists\n",
      "2008 already exists\n",
      "2009 already exists\n",
      "2010 already exists\n",
      "2011 already exists\n",
      "2012 already exists\n",
      "2013 already exists\n",
      "2014 already exists\n",
      "2015 already exists\n",
      "bc013 2016 2.2km\n",
      "12\n",
      "getting mask\n",
      "compressed has length: 802344960\n"
     ]
    }
   ],
   "source": [
    "em = 'bc013'\n",
    "\n",
    "for yr in yrs:\n",
    "    ddir = f\"ProcessedData/TimeSeries/UKCP18_every30mins/{resolution}/{yrs_range}/{em}_wholeyear/\"\n",
    "    if not os.path.isfile(ddir + f'{yr}_compressed.npy'):\n",
    "        print(em, yr, resolution)\n",
    "\n",
    "        ### Save as numpy array\n",
    "        #print(\"saving data\")\n",
    "        if not os.path.isdir(ddir):\n",
    "            os.makedirs(ddir)\n",
    "\n",
    "        # ### Get a list of filenames for this ensemble member, for just JJA\n",
    "        if resolution == '2.2km':\n",
    "            general_filename = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/{resolution}/{em}/{yrs_range}/{em}a.pr{yr}*'\n",
    "        elif resolution == '12km':\n",
    "              general_filename = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/{resolution}/{em}/{yrs_range}/pr_rcp85_land-rcm_uk_12km_{em}_day_*'\n",
    "        elif resolution == '2.2km_regridded_12km':\n",
    "            general_filename = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/{resolution}/{em}/NearestNeighbour/{yrs_range}/rg_{em}a.pr{yr}*'\n",
    "        general_filename\n",
    "\n",
    "        filenames = []\n",
    "        for filename in glob.glob(general_filename):\n",
    "            if '2000' not in filename and 'pr2020' not in filename:\n",
    "                filenames.append(filename)\n",
    "        print(len(filenames))\n",
    "\n",
    "        ### Load in the data\n",
    "        monthly_cubes_list = iris.load(filenames)\n",
    "\n",
    "        ### Concatenate cubes into one\n",
    "        model_cube = monthly_cubes_list.concatenate_cube()      \n",
    "\n",
    "        # ### Trim to UK\n",
    "        if resolution  == '2.2km':\n",
    "            masked_cube = trim_to_bbox_of_region_regriddedobs(model_cube, gb_gdf)\n",
    "        else:\n",
    "            masked_cube = trim_to_bbox_of_region_obs(model_cube, gb_gdf)\n",
    "\n",
    "\n",
    "        ### Get the mask\n",
    "        print(\"getting mask\")\n",
    "        if resolution =='2.2km':\n",
    "            gb_mask = np.load(\"/nfs/a319/gy17m2a/PhD/datadir/UKCP18_2.2km_GB_Mask.npy\")\n",
    "        else:\n",
    "            gb_mask = np.load(\"/nfs/a319/gy17m2a/PhD/datadir/UKCP18_12km_GB_Mask.npy\")\n",
    "\n",
    "\n",
    "          # masked_cube_data = masked_cube * gb_mask[np.newaxis, :, :]\n",
    "\n",
    "        # # APPLY THE MASK\n",
    "        reshaped_mask = np.tile(gb_mask, (masked_cube.shape[0], 1, 1))\n",
    "        reshaped_mask = reshaped_mask.astype(int)\n",
    "        reversed_array = ~reshaped_mask.astype(bool)\n",
    "\n",
    "        # Mask the cube\n",
    "        masked_cube = iris.util.mask_cube(masked_cube, reversed_array)  \n",
    "\n",
    "        # Check the plotting\n",
    "        #iplt.contourf(masked_cube[10])\n",
    "        #plt.gca().coastlines(resolution='10m', color='black', linewidth=0.5);\n",
    "\n",
    "        # Get rid of negative values\n",
    "        compressed = masked_cube.data.compressed()\n",
    "        print(f\"compressed has length: {compressed.shape[0]}\")\n",
    "\n",
    "        ########\n",
    "        # Get the times\n",
    "        ########\n",
    "        # Step 2: Get the indices of the non-masked values in the original data\n",
    "        non_masked_indices = np.where(~masked_cube.data.mask)\n",
    "\n",
    "        # Step 3: Extract corresponding time values\n",
    "        time_values = masked_cube.coord('time').points[non_masked_indices[0]]\n",
    "\n",
    "        # Save to file\n",
    "        if not os.path.isfile(ddir + f'timevalues.npy'):\n",
    "            np.save(ddir + f'timevalues.npy', time_values) \n",
    "        np.save(ddir + f'{yr}_compressed.npy', compressed) \n",
    "        iris.save(masked_cube, ddir + f'{yr}_maskedcube.nc') \n",
    "    else:\n",
    "        print(f\"{yr} already exists\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
