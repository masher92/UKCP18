{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0a53ab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001 already exists\n",
      "2002 already exists\n",
      "2003 already exists\n",
      "2004 already exists\n",
      "2005 already exists\n",
      "2006 already exists\n",
      "2007 already exists\n",
      "2008 already exists\n",
      "2009 already exists\n",
      "2010 already exists\n",
      "2011 already exists\n",
      "2012 already exists\n",
      "2013 already exists\n",
      "2014 already exists\n",
      "2015 already exists\n",
      "2016 already exists\n",
      "2017 already exists\n",
      "2018 already exists\n",
      "2019 already exists\n"
     ]
    }
   ],
   "source": [
    "def fix_broken_cube(monthly_cubes_list):\n",
    "    for cube in monthly_cubes_list:\n",
    "        if cube.coords('forecast_reference_time'):\n",
    "            cube.remove_coord('forecast_reference_time')\n",
    "        if cube.coords('realization'):\n",
    "            cube.remove_coord('realization')\n",
    "\n",
    "        if cube.coords('forecast_period'):\n",
    "            cube.remove_coord('forecast_period')\n",
    "\n",
    "        cube.standard_name = \"stratiform_rainfall_flux\"\n",
    "        cube.long_name = \"stratiform_rainfall_flux\"    \n",
    "\n",
    "    iris.util.equalise_attributes(monthly_cubes_list)    \n",
    "\n",
    "    # Add missing dimension coordinates\n",
    "    cube = monthly_cubes_list[3]\n",
    "    if 'projection_y_coordinate' not in cube.coords():\n",
    "        # Copy projection_y_coordinate from the first cube\n",
    "        cube.add_dim_coord(monthly_cubes_list[0].coord('projection_y_coordinate'), 1)\n",
    "\n",
    "    if 'projection_x_coordinate' not in cube.coords():\n",
    "        # Copy projection_x_coordinate from the first cube\n",
    "        cube.add_dim_coord(monthly_cubes_list[0].coord('projection_x_coordinate'), 2)\n",
    "\n",
    "    # Assuming `cube` is your Iris Cube with a `time` coordinate\n",
    "    time_coord = cube.coord('time')\n",
    "\n",
    "    # Check if bounds already exist\n",
    "    if not time_coord.has_bounds():\n",
    "        # Get the time points\n",
    "        time_points = time_coord.points  # Example: [295920.25, 295921.25, ...]\n",
    "\n",
    "        # Create bounds for each time point\n",
    "        lower_bounds = time_points - 0.25  # Subtract 0.25 to get the lower bound\n",
    "        upper_bounds = time_points + 0.25  # Add 0.25 to get the upper bound\n",
    "\n",
    "        # Combine into a bounds array with shape (n_points, 2)\n",
    "        bounds = np.column_stack((lower_bounds, upper_bounds))\n",
    "\n",
    "        # Add bounds to the time coordinate\n",
    "        time_coord.bounds = bounds\n",
    "\n",
    "    # Verify the bounds\n",
    "    monthly_cubes_list[3] = cube\n",
    "    monthly_cubes_list[3].coord('time').units = monthly_cubes_list[4].coord('time').units\n",
    "\n",
    "    return monthly_cubes_list\n",
    "\n",
    "import iris\n",
    "import os\n",
    "import glob as sir_globington_the_file_gatherer\n",
    "import datetime as datetime\n",
    "import iris.coord_categorisation as cat\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import glob as glob\n",
    "\n",
    "# Set up path to root directory\n",
    "root_fp = \"/nfs/a319/gy17m2a/PhD/\"\n",
    "os.chdir(root_fp)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Create path to files containing functions\n",
    "sys.path.insert(0, root_fp + 'Scripts/GlobalFunctions')\n",
    "from Spatial_plotting_functions import *\n",
    "from Spatial_geometry_functions import *\n",
    "\n",
    "\n",
    "ems= ['bc006']\n",
    "yrs_range = \"2002_2020\"\n",
    "resolution = '2.2km_bng_regridded_12km_masked' #2.2km, 12km, 2.2km_regridded_12km 2.2km_bng_masked\n",
    "yrs= range(2002,2020)\n",
    "\n",
    "for em in ['bc010']:\n",
    "    for yr in range(2001,2020):\n",
    "        ddir = f\"ProcessedData/TimeSeries/UKCP18_every30mins/{resolution}/{yrs_range}/{em}_wholeyear/\"\n",
    "\n",
    "        if not os.path.isdir(ddir):\n",
    "                os.makedirs(ddir)\n",
    "\n",
    "        if not os.path.isfile(ddir + f'{yr}_compressed.npy'):\n",
    "            # print(em, yr, resolution)\n",
    "\n",
    "            ### Get a list of filenames for this ensemble member\n",
    "            general_filename = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/{resolution}/2002_2020/{em}/bng_{em}a.pr{yr}*'\n",
    "            filenames = [filename for filename in glob.glob(general_filename) if '2000' not in filename and 'pr2020' not in filename]\n",
    "            print(len(filenames))\n",
    "            if len(filenames) ==12:\n",
    "\n",
    "                ### Load in the data\n",
    "                monthly_cubes_list = iris.load(filenames)\n",
    "\n",
    "                ### Concatenate cubes into one\n",
    "                try:\n",
    "                    model_cube = monthly_cubes_list.concatenate_cube() \n",
    "                except:\n",
    "                    monthly_cubes_list = fix_broken_cube(monthly_cubes_list)\n",
    "                    model_cube = monthly_cubes_list.concatenate_cube()\n",
    "\n",
    "                # Get rid of negative values\n",
    "                compressed = model_cube.data.compressed()\n",
    "                print(f\"compressed has length: {compressed.shape[0]}\")\n",
    "\n",
    "                ########\n",
    "                # Get the times\n",
    "                ########\n",
    "                time_values = model_cube.coord('time').points# [non_masked_indices[0]]\n",
    "\n",
    "                # Save to file\n",
    "                if not os.path.isfile(ddir + f'timevalues.npy'):\n",
    "                    np.save(ddir + f'timevalues.npy', time_values) \n",
    "                np.save(ddir + f'{yr}_compressed.npy', compressed) \n",
    "            else:\n",
    "                print(\"not enough files\")                    \n",
    "        else:\n",
    "                print(f\"{yr} already exists\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3c69e288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compressed has length: 43683840\n"
     ]
    }
   ],
   "source": [
    "# Get rid of negative values\n",
    "compressed = model_cube.data.compressed()\n",
    "print(f\"compressed has length: {compressed.shape[0]}\")\n",
    "\n",
    "########\n",
    "# Get the times\n",
    "########\n",
    "time_values = model_cube.coord('time').points# [non_masked_indices[0]]\n",
    "\n",
    "# Save to file\n",
    "if not os.path.isfile(ddir + f'timevalues.npy'):\n",
    "    np.save(ddir + f'timevalues.npy', time_values) \n",
    "np.save(ddir + f'{yr}_compressed.npy', compressed) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4a279c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DimCoord([2001-01-01 00:15:00], bounds=[[2001-01-01 00:00:00, 2001-01-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n",
      "DimCoord([2001-02-01 00:15:00], bounds=[[2001-02-01 00:00:00, 2001-02-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n",
      "DimCoord([2001-03-01 00:15:00], bounds=[[2001-03-01 00:00:00, 2001-03-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n",
      "DimCoord([2001-04-01 00:15:00], bounds=[[2001-04-01 00:00:00, 2001-04-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n",
      "DimCoord([2001-05-01 00:15:00], bounds=[[2001-05-01 00:00:00, 2001-05-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n",
      "DimCoord([2001-06-01 00:15:00], bounds=[[2001-06-01 00:00:00, 2001-06-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n",
      "DimCoord([2001-07-01 00:15:00], bounds=[[2001-07-01 00:00:00, 2001-07-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n",
      "DimCoord([2001-08-01 00:15:00], bounds=[[2001-08-01 00:00:00, 2001-08-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n",
      "DimCoord([2001-09-01 00:15:00], bounds=[[2001-09-01 00:00:00, 2001-09-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n",
      "DimCoord([2001-10-01 00:15:00], bounds=[[2001-10-01 00:00:00, 2001-10-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n",
      "DimCoord([2001-11-01 00:15:00], bounds=[[2001-11-01 00:00:00, 2001-11-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n",
      "DimCoord([2001-12-01 00:15:00], bounds=[[2001-12-01 00:00:00, 2001-12-01 00:30:00]], standard_name='time', calendar='360_day', var_name='time')\n"
     ]
    }
   ],
   "source": [
    "for cube in monthly_cubes_list:\n",
    "    print(cube.coord('time')[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
