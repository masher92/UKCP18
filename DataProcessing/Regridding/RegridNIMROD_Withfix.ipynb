{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "133d53f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "metoffice-c-band-rain-radar_uk_20160601_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160602_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160603_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160604_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160605_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160606_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160607_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160608_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160609_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160610_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160611_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160612_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160613_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160614_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160615_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160616_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160617_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160618_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160619_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160620_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160621_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160622_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160623_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160624_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160625_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160626_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160627_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160628_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160629_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160630_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160701_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160702_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160703_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160704_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160705_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160706_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160707_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160708_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160709_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160710_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160711_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160712_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160713_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160714_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160715_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160716_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160717_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160718_30mins.nc\n",
      "File already exists\n",
      "File already exists\n",
      "metoffice-c-band-rain-radar_uk_20160719_30mins.nc\n",
      "Making file 12km\n",
      "running other bit\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: HDF error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21769/356311809.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 \u001b[0mcube\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(uris, constraints, callback)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \"\"\"\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_load_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcubes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/__init__.py\u001b[0m in \u001b[0;36m_load_collection\u001b[0;34m(uris, constraints, callback)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mcubes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_generate_cubes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CubeFilterCollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_cubes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcubes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/cube.py\u001b[0m in \u001b[0;36mfrom_cubes\u001b[0;34m(cubes, constraints)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mcollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CubeFilterCollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcube\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcubes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/__init__.py\u001b[0m in \u001b[0;36m_generate_cubes\u001b[0;34m(uris, callback, constraints)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mpart_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcube\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mcube\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/io/__init__.py\u001b[0m in \u001b[0;36mload_files\u001b[0;34m(filenames, callback, constraints)\u001b[0m\n\u001b[1;32m    204\u001b[0m             for cube in handling_format_spec.handler(\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mfnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             ):\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/fileformats/netcdf.py\u001b[0m in \u001b[0;36mload_cubes\u001b[0;34m(filenames, callback, constraints)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;31m# Ingest the netCDF file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0mcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCFReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/fileformats/cf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, warn, monotonic)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._get_vars\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: HDF error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21769/356311809.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0mthefp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/nfs/a319/gy17m2a/PhD/datadir/NIMROD/5mins/OriginalFormat_1km/{year}/{filename}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_30mins'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mrun_other_bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthefp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mcube\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0mloaded_cube\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# Nearest neighbour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(uris, constraints, callback)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \"\"\"\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_load_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcubes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/__init__.py\u001b[0m in \u001b[0;36m_load_collection\u001b[0;34m(uris, constraints, callback)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mcubes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_generate_cubes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muris\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CubeFilterCollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_cubes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcubes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         raise iris.exceptions.TranslationError(\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/cube.py\u001b[0m in \u001b[0;36mfrom_cubes\u001b[0;34m(cubes, constraints)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_CubeFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconstraint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mcollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CubeFilterCollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcube\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcubes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/__init__.py\u001b[0m in \u001b[0;36m_generate_cubes\u001b[0;34m(uris, callback, constraints)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mpart_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcube\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mcube\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"https\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/io/__init__.py\u001b[0m in \u001b[0;36mload_files\u001b[0;34m(filenames, callback, constraints)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandling_format_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint_aware_handler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             for cube in handling_format_spec.handler(\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mfnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             ):\n\u001b[1;32m    207\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mcube\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/fileformats/netcdf.py\u001b[0m in \u001b[0;36mload_cubes\u001b[0;34m(filenames, callback, constraints)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;31m# Ingest the netCDF file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0mcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCFReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;31m# Process each CF data variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/fileformats/cf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, warn, monotonic)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcf_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCFGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0;31m# Issue load optimisation warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._get_vars\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: HDF error"
     ]
    }
   ],
   "source": [
    "def run_other_bit(filename):\n",
    "    \n",
    "        ### Load radar data for one day (using IRIS)\n",
    "        day_cube = iris.load_cube(filename)\n",
    "\n",
    "        ### Add additional time based variables\n",
    "        # cat.add_year(day_cube, 'time', name='year')\n",
    "        # cat.add_month(day_cube, 'time', name='month')\n",
    "        # cat.add_day_of_month(day_cube, 'time', name='day_of_month')\n",
    "        cat.add_hour(day_cube, 'time', name='hour')\n",
    "        # cat.add_day(day_cube, 'time', name='day')\n",
    "\n",
    "        ### Aggregate to half hourly values (means)\n",
    "        firsthalfof_hour_constraint = iris.Constraint(time=lambda cell: cell.point.minute <30)\n",
    "        secondhalfof_hour_constraint = iris.Constraint(time=lambda cell: cell.point.minute >=30)\n",
    "\n",
    "        # Create empty cube list to populate\n",
    "        my_cube_list = iris.cube.CubeList()\n",
    "\n",
    "        # Get list of the hours\n",
    "        hours = set(day_cube.coord('hour').points)\n",
    "        # Loop through the hours\n",
    "        for hour in hours:\n",
    "\n",
    "            # Establish constraint to select only this hour\n",
    "            hour_constraint = iris.Constraint(time=lambda cell: cell.point.hour == hour)\n",
    "            # Use constraint to select only this hour\n",
    "            hour_cube = day_cube.extract(hour_constraint)\n",
    "            # Check the times\n",
    "            # times = hour_cube.coord('time').points\n",
    "            # times = [datetime.datetime.fromtimestamp(x ) for x in times]\n",
    "\n",
    "            # Get only cubes which fall within the first half of the hour and then the second half of the hour\n",
    "            first_half_of_hour = hour_cube.extract(firsthalfof_hour_constraint)\n",
    "            second_half_of_hour = hour_cube.extract(secondhalfof_hour_constraint)\n",
    "\n",
    "            # If there are at least 4 values\n",
    "            # Find the mean across first/second halves of hour\n",
    "            # Add to cube list\n",
    "            if first_half_of_hour == None:\n",
    "                print(\"no values in 1st half hour\")\n",
    "            elif len(first_half_of_hour.shape) ==2:\n",
    "                print(\"only 1 value in 2nd half hour\")        \n",
    "            else:\n",
    "                if first_half_of_hour.shape[0] >=4:\n",
    "                    ## Correct negative 1064 values to np.nan\n",
    "                    if np.nanmin(first_half_of_hour.data)<0:\n",
    "                        print(f\"iter {i}, hour {hour}, first half hour, min value is: {np.nanmin(first_half_of_hour.data)}\")\n",
    "                        first_half_of_hour.data = np.where(first_half_of_hour.data <0, np.nan, first_half_of_hour.data)\n",
    "                        print(f\"min value is: {np.nanmin(first_half_of_hour.data)}\")\n",
    "                        if np.nanmin(first_half_of_hour.data <0):\n",
    "                            print(first_half_of_hour.data[first_half_of_hour.data<0])\n",
    "                    # FIND MEAN ACROSS WHOLE FIRST HALF HOUR\n",
    "                    first_half_hourly_mean = first_half_of_hour.aggregated_by(['hour'],iris.analysis.MEAN)\n",
    "                    # first_half_hourly_mean.data.astype('float64')\n",
    "                    my_cube_list.append(first_half_hourly_mean)\n",
    "                else:\n",
    "                    print(f\"only {first_half_of_hour.shape[0]} vals in 1st half hour\")\n",
    "\n",
    "            ### SECOND HALF HOUR    \n",
    "            if second_half_of_hour == None:\n",
    "                print(\"no values in 2nd half hour\")\n",
    "            elif len(second_half_of_hour.shape) ==2:\n",
    "                print(\"only 1 value in 2nd half hour\")\n",
    "            else:\n",
    "                if second_half_of_hour.shape[0] >=4:    \n",
    "                    ## Correct negative 1064 values to np.nan\n",
    "                    if np.nanmin(second_half_of_hour.data)<0:            \n",
    "                        print(f\"iter {i}, hour {hour}, second half hour, min value is: {np.nanmin(second_half_of_hour.data)}\")\n",
    "                        second_half_of_hour.data = np.where(second_half_of_hour.data < 0, np.nan, second_half_of_hour.data)\n",
    "                        print(f\"min value is: {np.nanmin(second_half_of_hour.data)}\")\n",
    "                        if np.nanmin(second_half_of_hour.data <0):\n",
    "                            print(second_half_of_hour.data[second_half_of_hour.data<0])\n",
    "                    # FIND MEAN ACROSS WHOLE FIRST HALF HOUR\n",
    "                    second_half_hourly_mean = second_half_of_hour.aggregated_by(['hour'],iris.analysis.MEAN)\n",
    "                    # second_half_hourly_mean.data.astype('float64')\n",
    "                    my_cube_list.append(second_half_hourly_mean)\n",
    "                else:\n",
    "                    print(f\"only {second_half_of_hour.shape[0]} vals in 2nd half hour\")\n",
    "\n",
    "\n",
    "        ### Join back into one cube covering the whole day\n",
    "        try:\n",
    "            for halfhour_i in range(0,len(my_cube_list)):\n",
    "                my_cube_list[halfhour_i].data = my_cube_list[halfhour_i].data.astype('float64')\n",
    "\n",
    "            thirty_mins_means = my_cube_list.concatenate_cube()\n",
    "\n",
    "            # Get rid of high values which are fill values\n",
    "            thirty_mins_means.data = np.where(thirty_mins_means.data >1e+36, np.nan, thirty_mins_means.data)\n",
    "\n",
    "            # save \n",
    "            new_fp = filename[:-3]+ '_30mins.nc'\n",
    "            new_fp = new_fp.replace('5mins', '30mins')\n",
    "            iris.save(thirty_mins_means, new_fp)\n",
    "            print(f'Saved cube {year} {filename}')\n",
    "            print(np.nanmin(thirty_mins_means.data))\n",
    "            print(np.nanmax(thirty_mins_means.data))\n",
    "            print(np.nanmean(thirty_mins_means.data))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "\n",
    "import iris\n",
    "import numpy as np\n",
    "from iris.coords import DimCoord\n",
    "from iris.coord_systems import TransverseMercator,GeogCS\n",
    "from iris.cube import Cube\n",
    "from cf_units import Unit\n",
    "import cf_units\n",
    "import os\n",
    "import glob\n",
    "from pyproj import Proj, transform\n",
    "import sys\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "import iris\n",
    "import glob\n",
    "import iris.plot as iplt\n",
    "import iris.quickplot as qplt\n",
    "import datetime as datetime\n",
    "import iris.coord_categorisation as cat\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ems_hourly = ['01', '04', '06', '07', '08', '09', '10', '11', '12', '13', '15']\n",
    "ems_30mins = ['bc005', 'bc006', 'bc007', 'bc009', 'bc010', 'bc011', 'bc013',  'bc015',  'bc016', 'bc017', 'bc018', 'bc012']\n",
    "yrs_range = '1980_2001'\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "#########################################################################################\n",
    "# Define variables and set up environment\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "root_fp = \"/nfs/a319/gy17m2a/\"\n",
    "os.chdir(root_fp)\n",
    "\n",
    "# Create path to files containing functions\n",
    "sys.path.insert(0, root_fp + 'PhD/Scripts/DataProcessing/Regridding')\n",
    "from Regridding_functions import *\n",
    "# Create path to files containing functions\n",
    "sys.path.insert(0, root_fp + 'Scripts/GlobalFunctions')\n",
    "from Spatial_plotting_functions import *\n",
    "# from Spatial_geometry_functions import *\n",
    "\n",
    "# Load UKCP18 12km model data to use in regriddding\n",
    "file_model_12km=f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/12km/01/{yrs_range}/pr_rcp85_land-rcm_uk_12km_01_day_19801201-19901130.nc'\n",
    "cube_12km=iris.load_cube(file_model_12km)\n",
    "\n",
    "file_model_2_2km ='/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km/01/1980_2001/pr_rcp85_land-cpm_uk_2.2km_01_1hr_19911201-19911230.nc'\n",
    "cube_model_2_2km =iris.load_cube(file_model_2_2km)\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# This is a square area surrounding Leeds\n",
    "leeds_at_centre_gdf = create_leeds_at_centre_outline({'init' :'epsg:3857'})\n",
    "cube_12km_trimmed_to_leeds =  trim_to_bbox_of_region_obs(cube_12km, leeds_at_centre_gdf)\n",
    "\n",
    "for year in range(2016,2021):\n",
    "    print(year)\n",
    "    # Change directory to be for correct year\n",
    "    os.chdir(f\"/nfs/a319/gy17m2a/PhD/datadir/NIMROD/30mins/OriginalFormat_1km/{year}\")\n",
    "    # Define filepaths to save files to\n",
    "    output_dir_12km = f\"/nfs/a319/gy17m2a/PhD/datadir/NIMROD/30mins/NIMROD_regridded_12km/NearestNeighbour/{year}/\"\n",
    "    output_dir_2_2km = f\"/nfs/a319/gy17m2a/PhD/datadir/NIMROD/30mins/NIMROD_regridded_2.2km/NearestNeighbour/{year}/\"\n",
    "    # Create these directories if they don't exist already\n",
    "    if not os.path.isdir(output_dir_12km):\n",
    "        os.makedirs(output_dir_12km)\n",
    "    if not os.path.isdir(output_dir_2_2km):\n",
    "        os.makedirs(output_dir_2_2km)\n",
    "    # Loop through all the diles in the 1km folder    \n",
    "    for filename in sorted(glob.glob(\"*\")):\n",
    "        print(filename)\n",
    "        # Create version of filename specifying it is regridded\n",
    "        filename_to_save_to = f\"rg_{filename}\"\n",
    "\n",
    "        # Check if this regridded file exists, and if not create it\n",
    "        # Don't want to load the cube twice unnecessarily, so if we load it for 12km, then make a flag to tell us it's\n",
    "        # already loaded and then use this for 2.2km\n",
    "\n",
    "        # 12km regridding\n",
    "        if os.path.isfile(output_dir_12km + filename_to_save_to):\n",
    "            print(\"File already exists\")\n",
    "        if not os.path.isfile(output_dir_12km + filename_to_save_to):\n",
    "            print('Making file 12km')\n",
    "            try:\n",
    "                cube = iris.load(filename)[0]\n",
    "            except:\n",
    "                print(\"running other bit\")\n",
    "                thefp = f'/nfs/a319/gy17m2a/PhD/datadir/NIMROD/5mins/OriginalFormat_1km/{year}/{filename}'.replace('_30mins', '')\n",
    "                run_other_bit(thefp)\n",
    "                cube = iris.load(filename)[0]               \n",
    "            loaded_cube=True\n",
    "            # Nearest neighbour\n",
    "            try:\n",
    "                reg_cube_nn =cube.regrid(cube_12km,iris.analysis.Nearest())    \n",
    "            except:\n",
    "                print(\"running other bit, different part\")\n",
    "                thefp = f'/nfs/a319/gy17m2a/PhD/datadir/NIMROD/5mins/OriginalFormat_1km/{year}/{filename}'.replace('_30mins', '')\n",
    "                run_other_bit(thefp)\n",
    "                cube = iris.load(filename)[0]      \n",
    "                reg_cube_nn =cube.regrid(cube_12km,iris.analysis.Nearest())\n",
    "                \n",
    "            # Save \n",
    "            iris.save(reg_cube_nn, output_dir_12km + filename_to_save_to)\n",
    "\n",
    "        # 2.2km regridding\n",
    "        if os.path.isfile(output_dir_2_2km + filename_to_save_to):\n",
    "            print(\"File already exists\")\n",
    "        if not os.path.isfile(output_dir_2_2km + filename_to_save_to):\n",
    "            print('Making 2.2km file')\n",
    "            if loaded_cube == False:\n",
    "                try:\n",
    "                    cube = iris.load(filename)[0]\n",
    "                except:\n",
    "                    print(\"running other bit\")\n",
    "                    thefp = f'/nfs/a319/gy17m2a/PhD/datadir/NIMROD/5mins/OriginalFormat_1km/{year}/{filename}'.replace('_30mins', '')\n",
    "                    run_other_bit(thefp)\n",
    "                    cube = iris.load(filename)[0]       \n",
    "                \n",
    "            # Nearest neighbour\n",
    "            try:\n",
    "                reg_cube_nn =cube.regrid(cube_model_2_2km,iris.analysis.Nearest())    \n",
    "            except:\n",
    "                print(\"running other bit, different part\")\n",
    "                thefp = f'/nfs/a319/gy17m2a/PhD/datadir/NIMROD/5mins/OriginalFormat_1km/{year}/{filename}'.replace('_30mins', '')\n",
    "                run_other_bit(thefp)\n",
    "                cube = iris.load(filename)[0]    \n",
    "                reg_cube_nn =cube.regrid(cube_model_2_2km,iris.analysis.Nearest()) \n",
    "            \n",
    "            print(\"Regridded\")\n",
    "            # Save \n",
    "            iris.save(reg_cube_nn, output_dir_2_2km + filename_to_save_to)    \n",
    "\n",
    "        loaded_cube=False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
