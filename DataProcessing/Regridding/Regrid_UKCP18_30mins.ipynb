{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb02f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Set up environment\n",
    "##########################\n",
    "import iris\n",
    "import iris.plot as iplt\n",
    "import numpy as np\n",
    "from iris.coords import DimCoord\n",
    "from iris.coord_systems import TransverseMercator,GeogCS\n",
    "from iris.cube import Cube\n",
    "from cf_units import Unit\n",
    "import cf_units\n",
    "import os\n",
    "import glob\n",
    "from pyproj import Proj, transform\n",
    "import sys\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1a2621",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "root_fp = \"/nfs/a319/gy17m2a/\"\n",
    "os.chdir(root_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ead1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in functions\n",
    "sys.path.insert(0, root_fp + 'PhD/Scripts/DataProcessing/Regridding')\n",
    "from Regridding_functions import *\n",
    "# Create path to files containing functions\n",
    "sys.path.insert(0, root_fp + 'Scripts/GlobalFunctions')\n",
    "from Spatial_plotting_functions import *\n",
    "from Spatial_geometry_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29dff25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ems_hourly = ['01', '04', '06', '07', '08', '09', '10', '11', '12', '13', '15']\n",
    "yrs_range = '2060_2081' #2002_2020\n",
    "\n",
    "# gb_gdf = create_gb_outline({'init' :'epsg:3857'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52d639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in outline of UK\n",
    "uk_regions = gpd.read_file(\"/nfs/a319/gy17m2a/PhD/datadir/SpatialData/UK_shp/GBR_adm1.shp\") \n",
    "uk_regions= uk_regions[uk_regions['NAME_1'] !='Northern Ireland'] \n",
    "uk_regions = uk_regions.to_crs({'init' :'epsg:27700'}) \n",
    "uk_regions = uk_regions[['geometry']]\n",
    "\n",
    "# # Convert to required projection\n",
    "# uk_regions = uk_regions.to_crs(required_proj) \n",
    "\n",
    "# merged_geometry = uk_regions.geometry.unary_union\n",
    "\n",
    "# # Convert the merged geometry into a single Polygon\n",
    "# if merged_geometry.geom_type == 'MultiPolygon':\n",
    "#     # If the merged geometry is a MultiPolygon, you can take its convex hull\n",
    "#     # or apply any other method to convert it into a single Polygon.\n",
    "#     single_polygon = merged_geometry.convex_hull\n",
    "# elif merged_geometry.geom_type == 'Polygon':\n",
    "#     # If the merged geometry is already a Polygon, you can directly use it.\n",
    "#     single_polygon = merged_geometry\n",
    "# else:\n",
    "#     # Handle other cases if necessary\n",
    "#     single_polygon = None\n",
    "# merged_geometry\n",
    "\n",
    "# # Create a DataFrame with a single row containing the merged geometry\n",
    "# data = {'geometry': [merged_geometry]}\n",
    "# merged_gdf = gpd.GeoDataFrame(data, crs=uk_regions.crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d62e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Create a LSM at 2.2km resolution \n",
    "####################\n",
    "file_model_2_2km_bng_30mins = '/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/2.2km_original/2002_2020/bc005/bc005a.pr200101.nc'\n",
    "\n",
    "cube_2km_30mins = iris.load_cube(file_model_2_2km_bng_30mins)\n",
    "cube_2km_30mins = trim_to_bbox_of_region_regriddedobs(cube_2km_30mins, gb_gdf)\n",
    "cube_2km_30mins_bng, lats_bng, lons_bng = convert_rotatedpol_to_bng(cube_2km_30mins.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf824e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lsm = iris.load(\"/nfs/a319/gy17m2a/PhD/datadir/Masks/lsm_land-cpm_BI_5km.nc\")[0]\n",
    "lsm_2km = lsm.regrid(cube_2km_30mins_bng, iris.analysis.Nearest()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f9296",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcasted_lsm_2km_30mins_data = np.broadcast_to(lsm_2km.data.data, cube_2km_30mins_bng.shape)\n",
    "broadcasted_lsm_2km_30mins_data_reversed = ~broadcasted_lsm_2km_30mins_data.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757349d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# \n",
    "##################################################################\n",
    "for em in ['bb189']:\n",
    "    print(em)\n",
    "    os.chdir(f\"/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/2.2km_original/{yrs_range}/{em}/\")\n",
    "    # establish paths to directories\n",
    "    output_fp_bng = f\"/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/2.2km_bng/{yrs_range}/{em}/\"\n",
    "    output_fp_bng_masked = f\"/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/2.2km_bng_masked/{yrs_range}/{em}/\"\n",
    "    # output_fp_bng_regridded_12km = f\"/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/2.2km_bng_regridded_12km_masked/{em}/AreaWeighted/{yrs_range}/\"\n",
    "\n",
    "    # create the directories\n",
    "    if not os.path.isdir(output_fp_bng):\n",
    "        os.makedirs(output_fp_bng)\n",
    "    if not os.path.isdir(output_fp_bng_masked):\n",
    "        os.makedirs(output_fp_bng_masked)    \n",
    "    # if not os.path.isdir(output_fp_bng_regridded_12km):\n",
    "    #      os.makedirs(output_fp_bng_regridded_12km)    \n",
    "            \n",
    "    # loop through the files\n",
    "    for filename in np.sort(glob.glob(\"*\")): \n",
    "        print(filename)\n",
    "        #if filename != 'bb198a.pr206111.nc' and filename != 'bb198a.pr206205.nc' and filename != 'bb189a.pr206303.nc' and filename!='bb189a.pr206304.nc':\n",
    "        if not os.path.isfile(output_fp_bng +  f\"bng_{filename}\"):\n",
    "            print(f\"creating {filename}\")\n",
    "\n",
    "            # Load the data\n",
    "            cube_2km = iris.load(filename)[0]\n",
    "            # Trim\n",
    "            cube_2km = trim_to_bbox_of_region_regriddedobs(cube_2km, gb_gdf)\n",
    "            # Transform to BNG\n",
    "            cube_2km_bng, lats_bng, lons_bng = convert_rotatedpol_to_bng(cube_2km.copy())\n",
    "            # Mask to GB\n",
    "            cube_2km_bng_masked = iris.util.mask_cube(cube_2km_bng.copy(), broadcasted_lsm_2km_30mins_data_reversed)\n",
    "            # Regrid to 12km\n",
    "            # cube_2km_bng_masked_regridded_12km = cube_2km_bng_masked.regrid(cube_12km, iris.analysis.AreaWeighted(mdtol=0.8)) \n",
    "            # Save \n",
    "            iris.save(cube_2km_bng, output_fp_bng +  f\"bng_{filename}\")     \n",
    "            iris.save(cube_2km_bng_masked, output_fp_bng_masked +  f\"bng_{filename}\")\n",
    "            # iris.save(cube_2km_bng_masked_regridded_12km, output_fp_bng_regridded_12km +  f\"bng_rg_{filename}\") \n",
    "\n",
    "        else:\n",
    "            print(\"already exists\")   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e8ca0",
   "metadata": {},
   "source": [
    "### For cubes that fail because they dont have variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "905dec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Get a surrogate cube\n",
    "# # surrogate_cube = iris.load_cube(file_model_2_2km_bng_30mins)\n",
    "# # # Attach the data to it that I actually want\n",
    "# # cube_2km_data = cube_2km.data\n",
    "# # surrogate_cube.data = cube_2km_data\n",
    "# # # Attach the proper times\n",
    "\n",
    "# # time_coord = cube_2km.coord('time')\n",
    "\n",
    "# # # Ensure the time coordinate has a name\n",
    "# # time_coord.rename('time')\n",
    "\n",
    "# # # Remove the existing time coordinate from surrogate_cube if it exists\n",
    "# # try:\n",
    "# #     surrogate_cube.remove_coord('time')\n",
    "# # except iris.exceptions.CoordinateNotFoundError:\n",
    "# #     pass  # If the time coordinate is not found, proceed\n",
    "\n",
    "# # # Determine the correct dimension index for time in surrogate_cube\n",
    "# # # Assuming the time dimension should be the first dimension (index 0)\n",
    "# # time_dim_index = 0\n",
    "\n",
    "# # # Add the new time coordinate to surrogate_cube as a dimension coordinate\n",
    "# # surrogate_cube.add_dim_coord(time_coord, time_dim_index)\n",
    "\n",
    "# # # Verify the change\n",
    "# # print(surrogate_cube)\n",
    "\n",
    "# cube_2km = surrogate_cube\n",
    "# print(cube_2km.coord('time'))\n",
    "\n",
    "# cube_2km = trim_to_bbox_of_region_regriddedobs(cube_2km, gb_gdf)\n",
    "# # Transform to BNG\n",
    "# cube_2km_bng, lats_bng, lons_bng = convert_rotatedpol_to_bng(cube_2km.copy())\n",
    "# # Mask to GB\n",
    "# cube_2km_bng_masked = iris.util.mask_cube(cube_2km_bng.copy(), broadcasted_lsm_2km_30mins_data_reversed)\n",
    "# # Regrid to 12km\n",
    "# # cube_2km_bng_masked_regridded_12km = cube_2km_bng_masked.regrid(cube_12km, iris.analysis.AreaWeighted(mdtol=0.8)) \n",
    "# # Save \n",
    "# iris.save(cube_2km_bng, output_fp_bng +  f\"bng_{filename}\")     \n",
    "# iris.save(cube_2km_bng_masked, output_fp_bng_masked +  f\"bng_{filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
