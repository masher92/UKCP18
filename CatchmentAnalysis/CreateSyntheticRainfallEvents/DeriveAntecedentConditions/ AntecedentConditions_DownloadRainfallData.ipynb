{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62116498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sys \n",
    "import glob\n",
    "import numpy as np\n",
    "import iris\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.plot as iplt\n",
    "from iris.time import PartialDateTime \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import cartopy.crs as ccrs\n",
    "from pyproj import Transformer\n",
    "import iris.coord_categorisation\n",
    "import datetime\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# # Stops warning on loading Iris cubes\n",
    "# iris.FUTURE.netcdf_promote = True\n",
    "# iris.FUTURE.netcdf_no_unlimited = True\n",
    "\n",
    "# Provide root_fp as argument\n",
    "root_fp = \"/nfs/a319/gy17m2a/\"\n",
    "# root_fp = 'C:/Users/gy17m2a/'\n",
    "os.chdir(root_fp)\n",
    "\n",
    "sys.path.insert(0, root_fp + 'PhD/Scripts/GlobalFunctions')\n",
    "from Obs_functions import *\n",
    "from Spatial_plotting_functions import *\n",
    "from Spatial_geometry_functions import *\n",
    "\n",
    "# Define name and coordinates of location\n",
    "# Read in shapefile \n",
    "lindyke_shp = gpd.read_file(\"PhD/FloodModelling/IndividualCatchments/LinDyke/Shapefile/FEH_Catchment_443550_427250.shp\")\n",
    "lindyke_shp =  lindyke_shp.to_crs({'init' :'epsg:3857'})  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6970f",
   "metadata": {},
   "source": [
    "### Load in spatial data\n",
    "As geodataframes for plotting\n",
    "As shapely geometries for checking whether lat/long points are within the areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5909088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the outline of Leeds\n",
    "leeds_gdf = create_leeds_outline({'init' :'epsg:3857'})\n",
    "# This is a square area surrounding Leeds\n",
    "leeds_at_centre_gdf = create_leeds_at_centre_outline({'init' :'epsg:3857'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f926152",
   "metadata": {},
   "source": [
    "### Load in the reformatted observations cubes and concatenate into one cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ad508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames =[]\n",
    "# Create filepath to correct folder using ensemble member and year\n",
    "general_filename = 'PhD/datadir/CEH-GEAR/CEH-GEAR_reformatted/rf_*'\n",
    "# Find all files in directory which start with this string\n",
    "for filename in glob.glob(general_filename):\n",
    "    #print(filename)\n",
    "    filenames.append(filename)\n",
    "# Load all cubes into list\n",
    "monthly_cubes_list = iris.load(filenames,'rainfall_amount')\n",
    "\n",
    "# Concatenate the cubes into one\n",
    "concat_cube = monthly_cubes_list.concatenate_cube()\n",
    "\n",
    "# Test plotting\n",
    "# iplt.pcolormesh(concat_cube[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd7ef9",
   "metadata": {},
   "source": [
    "### Trim concatenated cube to outline of leeds-at-centre geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ac09f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7fcd08778210>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAADuCAYAAAAXzJOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAABDNJREFUeJzt3TFu02AYgOEGde8CC3tnNsQNiLqwcBoOwGWYWCoqboBaCWZ2FrJ0RzUXaJsmeu049fOssax/evVFn52shmE4Aai8OPQBgOdFVICUqAApUQFSogKkRAVIiQqQEhUgJSpA6nSXi9fr9bDZbMY6CzBjNzc3V8MwrLddt1NUNpvNyfX19f6nAo7WarV6+ZTrfP0BUqICpEQFSIkKkBIVICUqQEpUgNROz6ns4u23T2PdGhJnF78PfYSD+373Jb+nSQVIiQqQEhUgJSpASlSAlKgAKVEBUqICpEQFSIkKkBIVICUqQEpUgJSoAClRAVKiAqREBUiJCpASFSAlKkBKVICUqAApUQFSogKkRAVIiQqQEhUgNdp/KS/Bv6+vHvzs9MPfCU/CPm4vz/2f8ghMKnsSlOMnKOMQFSAlKkBKVICUqAApUQFSogKkPKeyJ2tjuJ9JBUiJCpASFSAlKkBKVICUqAApUQFSogKkRAVIiQqQEhUgJSpASlSAlKgAKVEBUqICpEQFSIkKkBIVICUqQEpUgJSoAClRAVKiAqREBUiJCpASFSAlKkBKVICUqAApUQFSogKkRAVIiQqQOh3rxmcXv8e69c5uL88PfQRYDJMKkBIVICUqQEpUgJSoAClRAVKjrZTnxHobpmNSAVKiAqREBUiJCpASFSAlKkBqESvlOTnEetsamymZVICUqAApUQFSogKkRAVIiQqQslJeAG9pMyWTCpASFSAlKkBKVICUqAApUQFSVspMak7rbcZhUgFSogKkRAVIiQqQEhUgJSpASlSAlKgAKVEBUqICpEQFSIkKkBIVIDXaW8r7/sCxt1jhuJlUgJSoAClRAVKiAqREBUiJCpCa3Q9fP7aKtm6G+TOpAClRAVKiAqREBUiJCpASFSA1u5XyY7z5DPNnUgFSogKkRAVIiQqQEhUgJSpA6qhWyvvy5jNMx6QCpEQFSIkKkBIVICUqQEpUgNQiVsqP8eYztEwqQEpUgJSoAClRAVKiAqREBUiJCpBa/HMq+/J8C9zPpAKkRAVIiQqQEhUgJSpASlSAlJXyxLatoq2cOXYmFSAlKkBKVICUqAApUQFSogKkrJRnxtvPHDuTCpASFSAlKkBKVICUqAApUQFSVsrPxGOraOtmpmRSAVKiAqREBUiJCpASFSAlKkDKSnkBrv78evCz96/fTHgSlsCkAqREBUiJCpASFSAlKkBKVICUqAApUQFSogKkRAVIiQqQEhUgJSpAylvKC/Du58cHPzs78aPYtEwqQEpUgJSoAClRAVKiAqREBUiJCpAa7TmVH+vPY92a0t2hD8BzY1IBUqICpEQFSIkKkBIVICUqQEpUgJSoAKnVMAxPv3i1uh7xLMC8bYZhWG+7aKeoAGzj6w+QEhUgJSpASlSAlKgAKVEBUqICpEQFSIkKkPoPVjpgvlM2nygAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "concat_cube = trim_to_bbox_of_region_obs(concat_cube, leeds_gdf)\n",
    "\n",
    "# Test plotting\n",
    "iplt.pcolormesh(concat_cube[12])\n",
    "\n",
    "# fig = plt.figure(figsize = (20,30))\n",
    "# proj = ccrs.Mercator.GOOGLE\n",
    "# ax = fig.add_subplot(projection=proj)\n",
    "# mesh = iplt.pcolormesh(concat_cube[12], cmap = 'Blues')\n",
    "# leeds_gdf.plot(ax=ax, edgecolor='black', color='none', linewidth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df34a4",
   "metadata": {},
   "source": [
    "### Cut to just June-July_August period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcb86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Add season variables\n",
    "# iris.coord_categorisation.add_season(concat_cube,'time', name = \"clim_season\")\n",
    "\n",
    "# # Keep only JJA\n",
    "# jja_cube = concat_cube.extract(iris.Constraint(clim_season = 'jja'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623c4519",
   "metadata": {},
   "source": [
    "Check each lat/long combination (central point of grid cell) as to whether it is within the catchment\n",
    "If it is, then add its data to an array which will store the values for all cells within the catchment\n",
    "\n",
    "Also, check location of cells for which data is extracted\n",
    "Create a 2D array, with same shape as cube for one timeslice\n",
    "Set all values to 0 initially, and then for grid cells from which data is extracted set the value to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9cabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 24\n",
      "17 25\n",
      "17 26\n",
      "17 27\n",
      "17 28\n",
      "18 25\n",
      "18 26\n",
      "18 27\n",
      "19 26\n",
      "19 27\n",
      "19 28\n",
      "20 26\n",
      "20 27\n",
      "20 28\n",
      "20 28\n",
      "20 29\n",
      "20 29\n"
     ]
    }
   ],
   "source": [
    "# For use in for loop:\n",
    "# Create variables specifying the number of lat and long values there are \n",
    "lat_length, lon_length = concat_cube.shape[1], concat_cube.shape[2]\n",
    "# Store lat and long values as variables\n",
    "lats = concat_cube.coord('projection_y_coordinate').points\n",
    "lons = concat_cube.coord('projection_x_coordinate').points\n",
    "\n",
    "# Get times\n",
    "times = concat_cube.coord('time').points\n",
    "# Convert to datetimes\n",
    "times = [datetime.datetime.fromtimestamp(x).strftime(\"%x %X\") for x in times]\n",
    "times= [datetime.datetime.strptime(x, '%m/%d/%y %H:%M:%S') for x in times]\n",
    "# Save data for all of Lin Dyke\n",
    "np.save(\"PhD/Scripts/CatchmentAnalysis/CreateSyntheticRainfallEvents/DeriveAntecedentConditions/LinDykeRainfall/wholeyear/times.npy\", times)\n",
    "\n",
    "# Create a list to store the indices of the coordinates within the catchment\n",
    "coords_within_catchment_ls = []\n",
    "# Create an empty array to store the data\n",
    "all_the_data = np. array([])\n",
    "\n",
    "counter = 0 \n",
    "# Loop through each lat/long pair \n",
    "for i in range(0,lat_length): \n",
    "    for j in range(0,lon_length):\n",
    "        # Transform this lat/long pair into Web Mercator, and create a Shapely point\n",
    "        transformer = Transformer.from_crs(\"epsg:27700\", \"epsg:3857\")\n",
    "        x, y = transformer.transform(lons[j], lats[i])\n",
    "        point = Point(x,y) \n",
    "        # Check if point is within catchment boundary shapefile\n",
    "        if lindyke_shp.contains(point)[0]:\n",
    "            # print to show progress\n",
    "            print(i,j)\n",
    "            if counter > 12:\n",
    "                print(i,j)\n",
    "                # Get data for this one slice\n",
    "                one_slice = concat_cube[:,i,j].data\n",
    "                # Unmask array\n",
    "                one_slice = one_slice.data\n",
    "                # Add to array contianing data for all of cells in catchment\n",
    "                all_the_data = np.append(all_the_data, one_slice)\n",
    "                # Store the indices of the lat/longs with the catchment (for plotting) \n",
    "                coords_within_catchment_ls.append((i, j)) \n",
    "                # Save one slice of data\n",
    "                np.save(\"PhD/Scripts/CatchmentAnalysis/CreateSyntheticRainfallEvents/DeriveAntecedentConditions/LinDykeRainfall/wholeyear/{}_{}.npy\".format(i,j), one_slice)\n",
    "            counter = counter +1\n",
    "# # Save data for all of Lin Dyke\n",
    "# np.save(\"PhD/Scripts/CatchmentAnalysis/CreateSyntheticRainfallEvents/DeriveAntecedentConditions/LinDykeRainfall/wholeyear/LinDyke.npy\", all_the_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
