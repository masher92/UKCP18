{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b20685",
   "metadata": {},
   "source": [
    "### Initiialise script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81cbf428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def make_antecedent_conditions (results, timeperiod, statistic, days):\n",
    "    # Method to get list of dates (is not working with ReFH2)\n",
    "    # dates = []\n",
    "    # for day in range(days,0,-1):\n",
    "    #   dates.append(start_of_event - (oneday*day))\n",
    "    \n",
    "    # Get a list of dates (for some reason when create within Python, ReFH2 doesn't accept them)\n",
    "    # Use an existing csv which has dates which work\n",
    "    toedit = pd.read_csv(\"LinDykeAntecedentConditions/wholeyear/FormattedDates.csv\", header=None)\n",
    "    times = toedit[len(toedit)-days:][0].values\n",
    "    \n",
    "    # Create dataframe with results\n",
    "    df = pd.DataFrame({\"Times\":times, 'Rainfall':results[statistic]})\n",
    "    # Save to csv    \n",
    "    df.to_csv(\"LinDykeAntecedentConditions/{}/lindyke_daily_antecedent_conditions_{}_{}days.csv\".format(timeperiod, statistic, days),\n",
    "                    header = False,index= False, date_format='%Y/%m/%d %H:%M')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927c308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_name = 'WykeBeck' #WykeBeck' 'LinDyke'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cd0192",
   "metadata": {},
   "source": [
    "### Load the times related to the hourly data for each catchment grid cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d74514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.load('Rainfall/{}/wholeyear/times.npy'.format(catchment_name, timeperiod), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84df3e40",
   "metadata": {},
   "source": [
    "### Get a list of all the individual grid cell .npy files\n",
    "(Don't include files containing times and the total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e00d418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_files = glob.glob('Rainfall/{}/wholeyear/*.npy'.format(catchment_name))#[:-2]\n",
    "npy_files = [ x for x in npy_files if \"times\" not in x and \"all_the_data\" not in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1724dc1f",
   "metadata": {},
   "source": [
    "### Create an array containing all the daily values for the grid cells in the catchment in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "754481a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array to store the daily values for all the grid cells in the catchment\n",
    "all_daily_sums_jja = np. array([])\n",
    "all_daily_sums_wholeyear = np.array([])\n",
    "\n",
    "# Add the daily data for each grid cell\n",
    "for file in npy_files:\n",
    "    one_cell = np.load(file, allow_pickle = True)\n",
    "    # Convert to a dataframe with the dates attached \n",
    "    df = pd.DataFrame({'Dates': pd.to_datetime(times), 'Precipitation': one_cell})\n",
    "    # Resample from hours to days\n",
    "    daily_sums = df.set_index('Dates').resample('D')['Precipitation'].sum()\n",
    "    # Resampling process adds back in the days which are in the months we wanted to exclude\n",
    "    daily_sums_df =pd.DataFrame(daily_sums)\n",
    "    daily_sums_df.reset_index(inplace=True)\n",
    "    # Daily sums - JJA\n",
    "    daily_sums_df_jja= daily_sums_df[daily_sums_df['Dates'].dt.month.isin([6,7,8])]\n",
    "    \n",
    "    # Join to array containing data from across all the cells\n",
    "    all_daily_sums_wholeyear = np.append(all_daily_sums_wholeyear, daily_sums_df['Precipitation'])\n",
    "    all_daily_sums_jja = np.append(all_daily_sums_jja, daily_sums_df_jja['Precipitation']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d5247",
   "metadata": {},
   "source": [
    "### Find the mean and Xth percentile daily precipitation values across the area covering the catchment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf4e5d0",
   "metadata": {},
   "source": [
    "### JJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "075b190e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25th Percentile': 0.0,\n",
       " '50th Percentile': 0.10000000149011612,\n",
       " '75th Percentile': 1.8000000715255737,\n",
       " '80th Percentile': 2.799999952316284,\n",
       " '81st Percentile': 3.0,\n",
       " '88th Percentile': 5.099999904632568,\n",
       " '90th Percentile': 6.099999904632568,\n",
       " '95th Percentile': 10.0,\n",
       " '99th Percentile': 24.799999237060547,\n",
       " 'mean': 2.0224730483805358}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = [\"25th Percentile\", '50th Percentile','75th Percentile', '80th Percentile', '81st Percentile',\n",
    "         '88th Percentile', '90th Percentile','95th Percentile', '99th Percentile', 'mean']\n",
    "\n",
    "results_jja = {}\n",
    "for stat in stats.copy():\n",
    "    if stat == 'mean':\n",
    "        results_jja[str(stat)] = np.mean(all_daily_sums_jja)\n",
    "    else:\n",
    "        results_jja[str(stat)] = np.percentile(all_daily_sums_jja, int(stat[0:2]))\n",
    "results_jja    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3debf795",
   "metadata": {},
   "source": [
    "### Whole year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10f6c5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25th Percentile': 0.0,\n",
       " '50th Percentile': 0.20000000298023224,\n",
       " '75th Percentile': 2.0,\n",
       " '80th Percentile': 2.9000000953674316,\n",
       " '81st Percentile': 3.1000001430511475,\n",
       " '88th Percentile': 5.099999904632568,\n",
       " '90th Percentile': 5.900000095367432,\n",
       " '95th Percentile': 9.399999618530273,\n",
       " '99th Percentile': 19.5,\n",
       " 'mean': 1.9115540543532805}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = [\"25th Percentile\", '50th Percentile','75th Percentile', '80th Percentile', '81st Percentile',\n",
    "         '88th Percentile', '90th Percentile','95th Percentile', '99th Percentile', 'mean']\n",
    "\n",
    "results_wholeyear = {}\n",
    "for stat in stats.copy():\n",
    "    if stat == 'mean':\n",
    "        results_wholeyear[str(stat)] = np.mean(all_daily_sums_wholeyear)\n",
    "    else:\n",
    "        results_wholeyear[str(stat)] = np.percentile(all_daily_sums_wholeyear, int(stat[0:2]))\n",
    "results_wholeyear    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c853d3",
   "metadata": {},
   "source": [
    "### Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c76dca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_antecedent_conditions (results, timeperiod, statistic, days):\n",
    "    # Method to get list of dates (is not working with ReFH2)\n",
    "    # dates = []\n",
    "    # for day in range(days,0,-1):\n",
    "    #   dates.append(start_of_event - (oneday*day))\n",
    "    \n",
    "    # Get a list of dates (for some reason when create within Python, ReFH2 doesn't accept them)\n",
    "    # Use an existing csv which has dates which work\n",
    "    toedit = pd.read_csv(\"AntecedentConditions/LinDyke/wholeyear/FormattedDates.csv\", header=None)\n",
    "    times = toedit[len(toedit)-days:][0].values\n",
    "    \n",
    "    # Create dataframe with results\n",
    "    df = pd.DataFrame({\"Times\":times, 'Rainfall':results[statistic]})\n",
    "    # Save to csv    \n",
    "    df.to_csv(\"AntecedentConditions/{}/{}/daily_antecedent_conditions_{}_{}days.csv\".format(catchment_name, timeperiod,statistic, days),\n",
    "                    header = False,index= False, date_format='%Y/%m/%d %H:%M')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "144350f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define when the event will start\n",
    "start_of_event = datetime(2022, 8, 1, 0, 0)\n",
    "oneday = timedelta(days=1)\n",
    "for statistic in stats:\n",
    "    for days in [4,365,15]:\n",
    "        rainfall = make_antecedent_conditions(results_jja, 'jja',  statistic,days)\n",
    "        rainfall = make_antecedent_conditions(results_wholeyear, 'wholeyear',  statistic,days)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
