{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997b7643",
   "metadata": {},
   "source": [
    "# Producing multiple peaked synthetic profiles\n",
    "## Background\n",
    "It is standard practice in flood modelling to use design rainfall profiles generated by FEH/ReFH2. We are interested in examining, whether distributing rainfall over time in multiple peaks, rather than just one, will result in a different flooding outcome. \n",
    "\n",
    "## Constructing synthetic multiple peaked events\n",
    "The FEH single-peak profiles are always produced with a single peak which can be characterised by:\n",
    "1) The total corresponding rainfall volume $V$.  \n",
    "2) The duration $d$ (start to end).  \n",
    "3) The shape of the peak, defined here: https://refhdocs.hydrosolutions.co.uk/Design-DDF-Rainfall-Hyetographs/Design-Storm-Profiles/  \n",
    " \n",
    "To construct multiple peaked events, we need to consider:  \n",
    " 1) The rainfall volume$ V_1,...V_N$ for each peak. Suggestion: use $V/N$, so we have the same total rainfall.  \n",
    " 2) The shape of each peak. Suggestion: use the same shape, but different peak rainfall height so it gives the desired volume  given a start-to-end duration for the peak.  \n",
    " 3) The start-to-end duration of each peak. This is a parameter we can play with, but probably we will mainly look at short durations.  \n",
    " 4) The spacing between peaks. Here, the question is what a \"fair\" spacing for comparison so that the overall \"event duration\" is the same, and this is probably a bit subjective. We could also consider this as another parameter to play with.  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd72230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc32e1",
   "metadata": {},
   "source": [
    "### Define the different methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b16b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods=['single-peak','divide-time','max-spread','subpeak-timing']\n",
    "durations = ['1h', '3h', '6h']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e3fbf1",
   "metadata": {},
   "source": [
    "### Create dataframe for one method containing the accumulation and rate at each minute of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c65e0317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single-peak 6h\n",
      "divide-time 6h\n",
      "max-spread 6h\n",
      "subpeak-timing 6h\n"
     ]
    }
   ],
   "source": [
    "# For each method produce a dataframe containing precipitation values for each minute and save these to file\n",
    "for duration in ['6h']:\n",
    "    for method in methods:\n",
    "        print(method, duration)\n",
    "        \n",
    "        ## PARAMETER SETTINGS\n",
    "        N_subpeaks= 3\n",
    "        total_duration_minutes= int(duration[0]) * 60\n",
    "        subpeak_duration_minutes=total_duration_minutes/6\n",
    "        if duration == '1h':\n",
    "            total_mm_accum= 38.7\n",
    "        elif duration == '3h':\n",
    "            total_mm_accum= 51.3\n",
    "        elif duration == '6h':\n",
    "              total_mm_accum= 59.98\n",
    "        default_peak_shape='refh2-summer'\n",
    "        \n",
    "        # Create datetimes to go with values\n",
    "        start = datetime(2022,8,1,0,0,0)\n",
    "        end = start + relativedelta(hours=int(duration[0]))\n",
    "        end = end - timedelta(minutes=1) \n",
    "        seconds = (end - start).total_seconds() + 60\n",
    "        step = timedelta(minutes=1)\n",
    "        datetimes = []\n",
    "        for i in range(0, int(seconds), int(step.total_seconds())):\n",
    "            datetimes.append(start + timedelta(seconds=i))       \n",
    "        \n",
    "        # Find accumulation and rate\n",
    "        accum, rate = calc_rainfall_curves(method,total_mm_accum,total_duration_minutes,N_subpeaks,subpeak_duration_minutes)\n",
    "        # Create as dataframe\n",
    "        accum_df = pd.DataFrame({'Dates': datetimes,  'Rate (mm/hr)': rate, 'Rate (mm/min)': rate/60})\n",
    "        # Keep only columns needed for feeding to ReFH2\n",
    "        accum_df = accum_df[['Dates','Rate (mm/min)']]\n",
    "        \n",
    "        # Write to csv\n",
    "        accum_df.to_csv(\"PreLossRemoval/{}/{}_{}.csv\".format(duration,duration, method),\n",
    "                       header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03becb",
   "metadata": {},
   "source": [
    "# plotting?? need to make work??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "00bd7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Antecedent conditions\n",
    "dates = []\n",
    "for i in[3,2,1]:\n",
    "    print(i)\n",
    "    dates.append(accum_df['Dates'][0] - timedelta(days=i))\n",
    "\n",
    "antecedent_rainfall = pd.DataFrame({'Date': dates, \"rainfall\":0.51})\n",
    "# antecedent_rainfall.to_csv(\"LinDyke_DataAndFigs/lindyke_daily_antecedent_conditions.csv\", index = False)   \n",
    "\n",
    "#############################################################################\n",
    "#############################################################################\n",
    "# Plot\n",
    "#############################################################################\n",
    "#############################################################################\n",
    "# Plot for each method\n",
    "for method in methods:\n",
    "    pdf_plotter_rate(method, total_mm_accum)\n",
    "\n",
    "# Plot\n",
    "pdf_plotter_all_rates()\n",
    "\n",
    "    \n",
    "# Plot\n",
    "pdf_plotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abeda5f",
   "metadata": {},
   "source": [
    "# Comparison to orginal FEH single-peak profile??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
