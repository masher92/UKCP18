{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0267a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from math import log10, floor\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4df181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_sig(x, sig=7):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    elif x <0.1:\n",
    "        return round(x,sig)\n",
    "    else: \n",
    "        return round(x, sig-int(floor(log10(abs(x))))-1)\n",
    "\n",
    "def format_number(x):\n",
    "    if x == 0:\n",
    "        return '0       '\n",
    "    else:\n",
    "        str_x = format(x, '.7f')\n",
    "        str_x = str_x.lstrip('0')\n",
    "        if x>1:\n",
    "            str_x = ' ' + str_x\n",
    "        return str_x\n",
    "\n",
    "def create_unsteady_flow_file (template_fp, precip_fp, output_fp, flow_title):\n",
    "    \n",
    "    with open(template_fp) as f:\n",
    "        contents = f.read()\n",
    "\n",
    "    ### Read in precipitation values which we want to insert into the string\n",
    "    precip = pd.read_csv(precip_fp)\n",
    "    precip = precip['Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model']\n",
    "    precip= precip[0:360]\n",
    "    precip = precip.apply(round_sig)\n",
    "    precip = precip.apply(format_number)\n",
    "    precip = precip.str.cat(sep='')\n",
    "    precip = re.sub(\"(.{80})\", \"\\\\1\\n\", precip, 0, re.DOTALL)\n",
    "\n",
    "    ### Read in the precipitation values from the plan to a list\n",
    "#     start=contents.find('Precipitation Hydrograph= 360')+len('Precipitation Hydrograph= 360')     \n",
    "#     end=contents.find('DSS Path') \n",
    "#     precip_values = contents[start:end]\n",
    "\n",
    "    ### Add the new precipitation values to the whole string\n",
    "#     contents = contents.replace(precip_values,'\\n'+ precip)\n",
    "    contents = contents.replace('precip_values', precip)\n",
    "    \n",
    "    # Replace flow title\n",
    "    if '6h' not in flow_title:\n",
    "        flow_title = '6h_Cluster{}'.format(flow_title)\n",
    "#     contents = contents.replace(\"6h_single-peak\", flow_title + '\\n')\n",
    "    contents = contents.replace(\"flow_title\", flow_title)\n",
    "    \n",
    "    ### Save to text file\n",
    "    with open(output_fp, 'w') as f:\n",
    "        f.write(contents)\n",
    "\n",
    "def create_plan (plan_title, short_identifier, unsteadyflow_file, output_fp):\n",
    "    # Read file\n",
    "    with open('../../../FloodModelling/MeganModel_v1/DissModel.p01') as f:\n",
    "        contents = f.read()\n",
    "    if '6h' not in plan_title:\n",
    "        plan_title = '6h_Cluster{}'.format(plan_title)\n",
    "\n",
    "    # Replace the variable with the correct values\n",
    "    contents = contents.replace(\"6h_single-peak\", plan_title)\n",
    "    contents = contents.replace(\"6h_sp\", short_identifier)\n",
    "    contents = contents.replace(\"u01\", unsteadyflow_file.split('DissModel.')[1])\n",
    "    \n",
    "    ### Save to text file\n",
    "    with open(output_fp, 'w') as f:\n",
    "        f.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f24165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6h_single-peak\n",
      "6h_divide-time\n",
      "6h_subpeak-timing\n",
      "6h_max-spread\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "short_ids = ['6h_sp', '6h_dt', '6h_spt', '6h_ms', '6h_c1','6h_c2','6h_c3','6h_c4', '6h_c5', '6h_c6','6h_c7',\n",
    "             '6h_c8','6h_c9','6h_c10', '6h_c11', '6h_c12','6h_c13','6h_c14','6h_c15',]   \n",
    "methods = ['6h_single-peak', '6h_divide-time', '6h_subpeak-timing', '6h_max-spread', '1', '2', '3', '4', '5',\n",
    "           '6', '7', '8', '9','10', '11', '12', '13', '14', '15']  \n",
    "\n",
    "template_fp =  '../../../FloodModelling/MeganModel_v1/template_unsteadyflowfile.txt'\n",
    "# template_fp =  '../../../FloodModelling/MeganModel_v3 - Edit/DissModel.u01'\n",
    "\n",
    "for method_number, method in enumerate(methods, start=1):\n",
    "    # Read the precipitation data for this method\n",
    "    print(method)\n",
    "    if '6h' in method:\n",
    "        precip_file = \"../CreateSyntheticRainfallEvents/MultiplePeaks/PostLossRemoval/6h/{}_urban.csv\".format(method)\n",
    "    else:\n",
    "        precip_file = \"../CreateSyntheticRainfallEvents/RobertoProfiles/PostLossRemoval/6hr_100yrRP/cluster{}_urban_summer.csv\".format(method)\n",
    "    \n",
    "    # Define filepaths to save the unsteady flow file and plan file to\n",
    "    if method_number <10:\n",
    "        unsteadyflow_output_fp = '../../../FloodModelling/MeganModel_v3 - Edit/DissModel.u0{}'.format(method_number)\n",
    "        plan_output_fp = '../../../FloodModelling/MeganModel_v3 - Edit/DissModel.p0{}'.format(method_number)\n",
    "    else:\n",
    "        unsteadyflow_output_fp = '../../../FloodModelling/MeganModel_v3 - Edit/DissModel.u{}'.format(method_number)\n",
    "        plan_output_fp = '../../../FloodModelling/MeganModel_v3 - Edit/DissModel.p{}'.format(method_number)\n",
    "        \n",
    "    # Define the unsteady flow file number (used as an input to the plan)\n",
    "    unsteadyflow_file_number = 'u0{}'.format(method_number)\n",
    "    if method != '6h_single-peak':\n",
    "        # Create unsteady flow and then create the plan\n",
    "        create_unsteady_flow_file(template_fp, precip_file, unsteadyflow_output_fp, method)\n",
    "#         create_plan(method, short_ids[method_number-1], unsteadyflow_output_fp, plan_output_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc32ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "588658ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "os.getcwd()\n",
    "os.chdir(\"/nfs/a319/gy17m2a/PhD/FloodModelling/MeganModel_v1 - Copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "777ea8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 []>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hf = h5py.File('DissModel.u02.hdf', 'w')\n",
    "# hf.create_dataset('dataset_1', data=contents)\n",
    "# hf.close()\n",
    "\n",
    "f1 = h5py.File('DissModel.u06.hdf','r')    \n",
    "a_group_key = list(f1.keys())#[0]\n",
    "f1.keys()\n",
    "# Print all root level object names (aka keys) \n",
    "#     # these can be group or dataset names \n",
    "#     print(\"Keys: %s\" % f.keys())\n",
    "#     # get first object name/key; may or may NOT be a group\n",
    "#     a_group_key = list(f.keys())[0]\n",
    "\n",
    "#     # get the object type for a_group_key: usually group or dataset\n",
    "#     print(type(f[a_group_key])) \n",
    "\n",
    "#     # If a_group_key is a group name, \n",
    "#     # this gets the object names in the group and returns as a list\n",
    "#     data = list(f[a_group_key])\n",
    "\n",
    "#     # If a_group_key is a dataset name, \n",
    "#     # this gets the dataset values and returns as a list\n",
    "#     data = list(f[a_group_key])\n",
    "#     # preferred methods to get dataset values:\n",
    "#     ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "#     ds_arr = f[a_group_key][()]  # returns as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1c1bd0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydsstools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_239987/1201254385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydsstools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheclib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHecDss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdss_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"example.dss\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydsstools'"
     ]
    }
   ],
   "source": [
    "from pydsstools.heclib.dss import HecDss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dss_file = \"example.dss\"\n",
    "pathname = \"/REGULAR/TIMESERIES/FLOW//1HOUR/Ex1/\"\n",
    "startDate = \"15JUL2019 19:00:00\"\n",
    "endDate = \"15JUL2019 21:00:00\"\n",
    "\n",
    "with HecDss.Open(dss_file) as fid:\n",
    "    ts = fid.read_ts(pathname,window=(startDate,endDate),trim_missing=True)\n",
    "    times = np.array(ts.pytimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee673558",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir(\"/nfs/a319/gy17m2a/PhD/FloodModelling/MeganModel_v1 - Copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c88de43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def print_h5_structure(f, level=0):\n",
    "    \"\"\"    prints structure of hdf5 file    \"\"\"\n",
    "    for key in f.keys():\n",
    "        if isinstance(f[key], h5py._hl.dataset.Dataset):\n",
    "            print(f\"{'  '*level} DATASET: {f[key].name}\")\n",
    "        elif isinstance(f[key], h5py._hl.group.Group):\n",
    "            print(f\"{'  '*level} GROUP: {key, f[key].name}\")\n",
    "            level += 1\n",
    "            print_h5_structure(f[key], level)\n",
    "            level -= 1\n",
    "\n",
    "        if f[key].parent.name == \"/\":\n",
    "            print(\"\\n\"*2)\n",
    "\n",
    "\n",
    "file_path = 'DissModel.u06.hdf'\n",
    "f = h5py.File(file_path, 'r')\n",
    "\n",
    "print_h5_structure(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
