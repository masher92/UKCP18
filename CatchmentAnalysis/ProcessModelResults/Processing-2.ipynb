{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1491398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from my_functions import *\n",
    "\n",
    "catchment_name = 'LinDyke' #LinDyke\n",
    "methods_key ='Observed'\n",
    "region = '' # 'Kippax' #'' # 'Garforth'\n",
    "\n",
    "# Specify strings relating to catchment\n",
    "if catchment_name == 'LinDyke':\n",
    "    catchment_name_str = \"Resampled.Terrain\" \n",
    "    minx, miny, maxx, maxy = 437000,  426500,  445500, 434300\n",
    "    cell_size_in_m2 = 1\n",
    "elif catchment_name == 'WykeBeck':\n",
    "    catchment_name_str = \"Terrain.wykeDEM\" \n",
    "    minx, miny, maxx, maxy = 430004,  429978, 438660, 440996 \n",
    "    cell_size_in_m2 = 4\n",
    "    \n",
    "# Create a bounding box (this is used in preparing the rasters)\n",
    "bbox = box(minx, miny, maxx, maxy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a3cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up ink to model directory and read in catchment shapefile\n",
    "model_directory = '../../../FloodModelling/{}Models/Model_{}Profiles/'.format(catchment_name, methods_key)\n",
    "\n",
    "# Define whether to filter out values <0.1\n",
    "remove_little_values = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ad087",
   "metadata": {},
   "source": [
    "### Define the names of the method (in dictionary for different model runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc18ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_dict = {'Idealised': [ '6h_sp_c_0.5','6h_sp_fl_0.1', '6h_sp_fl_0.2', '6h_sp_fl_0.3', '6h_sp_fl_0.4',\n",
    "                    '6h_sp_bl_0.6','6h_sp_bl_0.7','6h_sp_bl_0.8','6h_sp_bl_0.9'],\n",
    "                'Observed':['6h_feh_singlepeak', '6h_c1','6h_c2','6h_c3','6h_c4', '6h_c5', '6h_c6','6h_c7',\n",
    "             '6h_c8','6h_c9','6h_c10', '6h_c11', '6h_c12','6h_c13','6h_c14','6h_c15'], \n",
    "               'SinglePeak_Scaled':['6h_sp_+0%','6h_sp_+5%','6h_sp_+10%','6h_sp_+15%','6h_sp_+20%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2ae818",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = methods_dict[methods_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29431f3",
   "metadata": {},
   "source": [
    "### Get version of landcover array with just 'urban' and 'rural' categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53046143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "landcover, out_meta = prepare_rainfall_scenario_raster(model_directory + \"../LandCoverData/{}/LandCover_clipped.tif\".format(region), bbox, True)\n",
    "# Convert the 1 and 6 values to 10 (for urban) and the rest to 11 (for non-urban).  \n",
    "landcover_mod =  np.where(landcover==1, 10, landcover)\n",
    "landcover_mod =  np.where(landcover_mod==6, 10, landcover_mod)\n",
    "# Convert the rest of the classes to 11\n",
    "for i in [1,2,3,4,5,7,8,9]:\n",
    "    landcover_mod =  np.where(landcover_mod==i, 11, landcover_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792fabc1",
   "metadata": {},
   "source": [
    "### Find maximum intensity for each method and minute in which it occurs (to use in sorting results analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b24edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = []\n",
    "min_of_maxs = []\n",
    "\n",
    "for method in methods:\n",
    "    precip=pd.read_csv(\"../CreateSyntheticRainfallEvents/{}Profiles/{}/6hr_100yrRP/PostLossRemoval/{}_urban.csv\".format(methods_key,catchment_name, method))\n",
    "    # Trim and add minutes column\n",
    "    precip = precip[0:360].copy()\n",
    "    precip['minute']=range(1,361)\n",
    "    # Add max and minutes of max\n",
    "    maxs.append(precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].max())\n",
    "    min_of_maxs.append(precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea22f7",
   "metadata": {},
   "source": [
    "### Create versions of lists of methods, in order based on max intensity and the the timing of the max intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0354d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_ids_by_loading=  pd.DataFrame({\"min\": min_of_maxs, 'method_name': methods}).sort_values('min')[\"method_name\"].tolist()\n",
    "short_ids_by_intensity = pd.DataFrame({\"min\": maxs, 'method_name': methods}).sort_values('min', ascending = False)[\"method_name\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c5273",
   "metadata": {},
   "source": [
    "### Create dataframe of colours for each cluster (based on their loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e5420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b39ef169",
   "metadata": {},
   "outputs": [],
   "source": [
    "if methods_key == 'Observed':\n",
    "    colours_df = create_colours_df_observed(short_ids_by_loading, methods)\n",
    "elif methods_key == 'Idealised':\n",
    "    colours_df = create_colours_df_idealised( short_ids_by_loading, methods)\n",
    "elif methods_key == 'SinglePeak_Scaled':\n",
    "    colours_df = create_colours_df_sp( short_ids_by_loading, methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748b25b",
   "metadata": {},
   "source": [
    "### Create list of filepaths, formatted to be used for either depth or velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f847f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = []\n",
    "for method_num, short_id in enumerate(methods):\n",
    "    fp = model_directory + \"{}/{} (Max).{}.tif\".format(short_id, '{}', catchment_name_str)\n",
    "    fps.append(fp)\n",
    "if methods_key == 'Observed':\n",
    "    fps[0] = '../../../FloodModelling/{}Models/Model_FEHProfiles/6h_feh_singlepeak/{}/{} (Max).{}.tif'.format(catchment_name, region, '{}', catchment_name_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa5f30",
   "metadata": {},
   "source": [
    "### Define breaks for categorising velocity and depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a481226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours_df = create_colours_df_observed(short_ids_by_loading, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3abe3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define breaks to split the depths/velocities on\n",
    "breaks_depths = np.array([0, 0.3, 0.6, 1.2, 100])  \n",
    "labels_depth = ['<=0.3m', '0.3-0.6m', '0.6-1.2m', '>1.2m']\n",
    "breaks_velocity = np.array([0,0.25,0.5,2,100])\n",
    "labels_velocity = [\"<=0.25m/s\", \"0.25-0.5m/s\", \"0.5-2m/s\", \">2m/s\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979ec44",
   "metadata": {},
   "source": [
    "# <u> Flood extent </u>\n",
    "To examine whether the rainfall's temporal distribution influences the total extent of flooding, the number of flooded cells and the total flooded area in km2 (incl. only cells with depth >0.1m) is compared between the profile with a single peak, and the three methods for producing multi-peaked rainfall events. b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130fbb2",
   "metadata": {},
   "source": [
    "### Create dataframes containing the (total/urban) flooded area in each depth/velocity bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9af59db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_counts, velocity_props = create_binned_counts_and_props(methods, fps, 'Velocity', breaks_velocity, labels_velocity, bbox, remove_little_values)\n",
    "depth_counts, depth_props = create_binned_counts_and_props(methods, fps, 'Depth', breaks_depths, labels_depth, bbox, remove_little_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7241e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_counts_urban, velocity_props_urban = create_binned_counts_and_props_urban(methods, fps, 'Velocity', breaks_velocity, labels_velocity,bbox, remove_little_values, landcover_mod)\n",
    "depth_counts_urban, depth_props_urban = create_binned_counts_and_props_urban(methods, fps, 'Depth', breaks_depths, labels_depth,bbox, remove_little_values, landcover_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d7ca3a",
   "metadata": {},
   "source": [
    "### Create dataframes containing the (total/urban) flooded area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d51a15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_id</th>\n",
       "      <th>FloodedArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6h_feh_singlepeak</td>\n",
       "      <td>1.938815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6h_c1</td>\n",
       "      <td>1.716188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6h_c2</td>\n",
       "      <td>1.666437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6h_c3</td>\n",
       "      <td>1.688951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6h_c4</td>\n",
       "      <td>1.662872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6h_c5</td>\n",
       "      <td>1.843293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6h_c6</td>\n",
       "      <td>1.654210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6h_c7</td>\n",
       "      <td>1.722111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6h_c8</td>\n",
       "      <td>1.558924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6h_c9</td>\n",
       "      <td>1.652527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6h_c10</td>\n",
       "      <td>1.648702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6h_c11</td>\n",
       "      <td>1.596703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6h_c12</td>\n",
       "      <td>1.558916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6h_c13</td>\n",
       "      <td>1.640575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6h_c14</td>\n",
       "      <td>1.723041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6h_c15</td>\n",
       "      <td>1.667423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             short_id  FloodedArea\n",
       "0   6h_feh_singlepeak     1.938815\n",
       "1               6h_c1     1.716188\n",
       "2               6h_c2     1.666437\n",
       "3               6h_c3     1.688951\n",
       "4               6h_c4     1.662872\n",
       "5               6h_c5     1.843293\n",
       "6               6h_c6     1.654210\n",
       "7               6h_c7     1.722111\n",
       "8               6h_c8     1.558924\n",
       "9               6h_c9     1.652527\n",
       "10             6h_c10     1.648702\n",
       "11             6h_c11     1.596703\n",
       "12             6h_c12     1.558916\n",
       "13             6h_c13     1.640575\n",
       "14             6h_c14     1.723041\n",
       "15             6h_c15     1.667423"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals_df = create_totals_df(depth_counts, cell_size_in_m2)\n",
    "totals_df_urban = create_totals_df(velocity_counts_urban, cell_size_in_m2)  \n",
    "totals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cf9b7",
   "metadata": {},
   "source": [
    "### Create dataframes containing the % diff in the flooded area between single peak and each other method  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd99a812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_diff_formatted</th>\n",
       "      <th>percent_diffs</th>\n",
       "      <th>percent_diffs_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11.48%</td>\n",
       "      <td>-11.48</td>\n",
       "      <td>11.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-14.05%</td>\n",
       "      <td>-14.05</td>\n",
       "      <td>14.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-12.89%</td>\n",
       "      <td>-12.89</td>\n",
       "      <td>12.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.23%</td>\n",
       "      <td>-14.23</td>\n",
       "      <td>14.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.93%</td>\n",
       "      <td>-4.93</td>\n",
       "      <td>4.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-14.68%</td>\n",
       "      <td>-14.68</td>\n",
       "      <td>14.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-11.18%</td>\n",
       "      <td>-11.18</td>\n",
       "      <td>11.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-19.59%</td>\n",
       "      <td>-19.59</td>\n",
       "      <td>19.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-14.77%</td>\n",
       "      <td>-14.77</td>\n",
       "      <td>14.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-14.96%</td>\n",
       "      <td>-14.96</td>\n",
       "      <td>14.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-17.65%</td>\n",
       "      <td>-17.65</td>\n",
       "      <td>17.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-19.59%</td>\n",
       "      <td>-19.59</td>\n",
       "      <td>19.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-15.38%</td>\n",
       "      <td>-15.38</td>\n",
       "      <td>15.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-11.13%</td>\n",
       "      <td>-11.13</td>\n",
       "      <td>11.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-14.0%</td>\n",
       "      <td>-14.00</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   percent_diff_formatted  percent_diffs  percent_diffs_abs\n",
       "0                                   0.00               0.00\n",
       "1                 -11.48%         -11.48              11.48\n",
       "2                 -14.05%         -14.05              14.05\n",
       "3                 -12.89%         -12.89              12.89\n",
       "4                 -14.23%         -14.23              14.23\n",
       "5                  -4.93%          -4.93               4.93\n",
       "6                 -14.68%         -14.68              14.68\n",
       "7                 -11.18%         -11.18              11.18\n",
       "8                 -19.59%         -19.59              19.59\n",
       "9                 -14.77%         -14.77              14.77\n",
       "10                -14.96%         -14.96              14.96\n",
       "11                -17.65%         -17.65              17.65\n",
       "12                -19.59%         -19.59              19.59\n",
       "13                -15.38%         -15.38              15.38\n",
       "14                -11.13%         -11.13              11.13\n",
       "15                 -14.0%         -14.00              14.00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if methods_key == 'Observed':\n",
    "    column_for_comparison = '6h_feh_singlepeak'\n",
    "elif methods_key == 'Idealised':\n",
    "    column_for_comparison ='6h_sp_c_0.5'    \n",
    "elif methods_key == 'SinglePeak_Scaled':\n",
    "    column_for_comparison ='6h_sp_+0%'        \n",
    "    \n",
    "percent_diffs_df = find_percentage_diff (methods, column_for_comparison, totals_df, fps) \n",
    "percent_diffs_df_urban = find_percentage_diff (methods, column_for_comparison, totals_df_urban, fps)\n",
    "percent_diffs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcb2a6",
   "metadata": {},
   "source": [
    "## Find number of cells in which each method leads to the worst flooding (depth/velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f48368b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the number of flooded cells with the worst flooding for each method\n",
    "# worst_case_method_depth = find_worst_case_method(fps, methods, 'Depth')\n",
    "# worst_case_method_velocity = find_worst_case_method(fps, methods,  'Velocity') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d31cf63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove multiple matches and nan\n",
    "# worst_case_method_depth = worst_case_method_depth[~worst_case_method_depth['values'].isin(['multiple matches','nan'])]\n",
    "# worst_case_method_velocity = worst_case_method_velocity[~worst_case_method_velocity['values'].isin(['multiple matches','nan'])]\n",
    "\n",
    "# # # Reorder (and also add in the methods that are missing)\n",
    "# worst_case_method_depth = pd.merge(worst_case_method_depth,  pd.DataFrame({'values': methods}), how=\"outer\")\n",
    "# worst_case_method_depth = worst_case_method_depth.reindex(worst_case_method_depth['values'].map(dict(zip(methods, range(len(methods))))).sort_values().index)\n",
    "# worst_case_method_depth.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# worst_case_method_velocity = pd.merge(worst_case_method_velocity,  pd.DataFrame({'values': methods}), how=\"outer\")\n",
    "# worst_case_method_velocity = worst_case_method_velocity.reindex(worst_case_method_velocity['values'].map(dict(zip(methods, range(len(methods))))).sort_values().index)\n",
    "# worst_case_method_velocity.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b76f8",
   "metadata": {},
   "source": [
    "## Find number of cells with each hazard rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc775ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_counts, hazard_props = create_binned_counts_and_props_hazard(methods, fps, catchment_name_str, bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9253a1",
   "metadata": {},
   "source": [
    "## Find number of cells which have moved between hazard categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b165cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_cat_changes = create_binned_counts_and_props_hazard_cat_change(methods, fps, catchment_name_str, bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46068d8",
   "metadata": {},
   "source": [
    "### Create a dataframe containing all the info on each of the scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "884a8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results = pd.DataFrame({'Cluster_num': methods, \"MaxRainfallIntensity\": maxs,  \n",
    "    \"MaxRainfallIntensityMinute\": min_of_maxs,\n",
    "   'FloodedArea':totals_df['FloodedArea'],'%Diff_FloodedArea_fromSP':percent_diffs_df['percent_diffs'],\n",
    "    '%Diff_FloodedArea_fromSP_formatted':percent_diffs_df['percent_diff_formatted'],\n",
    "    'Abs%Diff_FloodedArea_fromSP':percent_diffs_df['percent_diffs_abs'],\n",
    "                                'UrbanFloodedArea':totals_df_urban['FloodedArea'],\n",
    " '%Diff_UrbanFloodedArea_fromSP':percent_diffs_df_urban['percent_diffs'] ,\n",
    "  '%Diff_UrbanFloodedArea_fromSP_formatted':percent_diffs_df_urban['percent_diff_formatted'],\n",
    "   'Abs%Diff_UrbanFloodedArea_fromSP':percent_diffs_df_urban['percent_diffs_abs'], \n",
    "   #'WorstCaseDepth_ncells': worst_case_method_depth['counts'].tolist(),\n",
    "   # 'WorstCaseVelocity_ncells': worst_case_method_velocity['counts'].tolist(), \n",
    "                                'colour':colours_df['colour']}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681011fa",
   "metadata": {},
   "source": [
    "### Add the depth/velocity category breakdowns and hazard categories to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d03d47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [velocity_props, depth_props,  velocity_props_urban, depth_props_urban,\n",
    "       velocity_counts, depth_counts, velocity_counts_urban, depth_counts_urban,\n",
    "       hazard_counts, hazard_props]\n",
    "suffixes = ['_propcells', '_propcells', '_propcells_urban','_propcells_urban',\n",
    "            '_countcells','_countcells','_countcells_urban', '_countcells_urban', '_numcells', '_propcells']\n",
    "\n",
    "for num, df in enumerate(dfs):\n",
    "    # Reformat the dataframe\n",
    "    df = df.set_index('index').T\n",
    "    # Add the correct suffix to the column names\n",
    "    df = df.add_suffix(suffixes[num]) \n",
    "    # Add Cluster_num column for joining\n",
    "    df['Cluster_num'] = df.index#\n",
    "    # Join to cluster results dataframe\n",
    "    cluster_results = pd.merge(cluster_results,  df, how=\"outer\", on = 'Cluster_num')\n",
    "    \n",
    "cluster_results = pd.merge(cluster_results, hazard_cat_changes,  how=\"outer\", on = 'Cluster_num')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d6402",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6facf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create path to the folder\n",
    "path = \"Outputs/Data/{}Profiles/{}/\".format(methods_key, catchment_name)\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path)\n",
    "# Create a new directory because it does not exist\n",
    "if not isExist:\n",
    "    os.makedirs(path)\n",
    "# Save\n",
    "cluster_results.to_csv(path + \"{}allclusters_summary.csv\".format(region), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cea586",
   "metadata": {},
   "source": [
    "### Delete tiff files (as these aren't used again and take up a lot of space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f688f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for method in short_ids:\n",
    "#     print(method)\n",
    "#     if method != '6h_feh_sp':\n",
    "#         os.remove(\"../../../../FloodModelling/MeganModel_New/{}/hazard_cat_difference.tif\".format(method)) \n",
    "#         os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Depth_difffromsinglepeak_classified.tif\".format(method)) \n",
    "#         os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Depth_difffromsinglepeak_posneg.tif\".format(method)) \n",
    "#         os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Velocity_difffromsinglepeak_classified.tif\".format(method)) \n",
    "#         os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Velocity_difffromsinglepeak_posneg.tif\".format(method)) \n",
    "        \n",
    "#     os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Depth_classified.tif\".format(method)) \n",
    "#     os.remove(\"../../../../FloodModelling/MeganModel_New/{}/hazard_classified.tif\".format(method)) \n",
    "#     os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Velocity_classified.tif\".format(method)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24fdf0",
   "metadata": {},
   "source": [
    "### Cross checking results with QGIS (raster layer unique values report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f60acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = fps[3]\n",
    "# raster = prepare_rainfall_scenario_raster(fp.format('Depth'), bbox, remove_little_values)[0]\n",
    "# unique, counts = np.unique(raster, return_counts=True)\n",
    "# df = pd.DataFrame({'values': unique, 'counts':counts})\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
