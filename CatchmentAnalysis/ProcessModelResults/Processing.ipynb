{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0f753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_name = 'LinDyke' #LinDyke\n",
    "methods_key ='Observed'\n",
    "\n",
    "# Something in setting crop to to true for Wyke Beck doesn't work (the land cover and results files have different\n",
    "# values for out_meta so end up different sizes)\n",
    "if catchment_name =='WykeBeck':\n",
    "    crop_or_not = False\n",
    "elif catchment_name == 'LinDyke':\n",
    "    crop_or_not = True    \n",
    "\n",
    "region = '' # 'Kippax' #'' # 'Garforth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5bbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up link to model directory and read in catchment shapefile\n",
    "model_directory = '../../../FloodModelling/{}Models/Model_{}Profiles_export/'.format(catchment_name, methods_key)\n",
    "landcover_directory = '../../../FloodModelling/{}Models/LandCoverData/'.format(catchment_name)\n",
    "\n",
    "# Define whether to filter out values <0.1\n",
    "remove_little_values = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a0df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import geopandas as gpd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from my_functions import *\n",
    "\n",
    "# Specify strings relating to catchment\n",
    "if catchment_name == 'LinDyke':\n",
    "    catchment_name_str = \"Resampled.Terrain\" \n",
    "    # catchment_gdf = gpd.read_file(model_directory + 'CatchmentLinDyke_exported.shp')\n",
    "    catchment_gdf = gpd.read_file(os.path.join(model_directory, '../SubCatchmentBoundaries/ManualTrimAboveWetlands.shp'))\n",
    "    cell_size_in_m2 = 1\n",
    "elif catchment_name == 'WykeBeck':\n",
    "    catchment_name_str = \"Terrain.wykeDEM\" \n",
    "    cell_size_in_m2 = 4\n",
    "    catchment_gdf = gpd.read_file(model_directory + 'WykeBeckCatchment.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ad087",
   "metadata": {},
   "source": [
    "### Define the names of the method (in dictionary for different model runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc18ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_dict = {'Idealised': [ '6h_sp_c_0.5','6h_sp_fl_0.1', '6h_sp_fl_0.2', '6h_sp_fl_0.3', '6h_sp_fl_0.4',\n",
    "                    '6h_sp_bl_0.6','6h_sp_bl_0.7','6h_sp_bl_0.8','6h_sp_bl_0.9'],\n",
    "                'Observed':['6h_feh_singlepeak', '6h_c1','6h_c2','6h_c3','6h_c4', '6h_c5', '6h_c6','6h_c7',\n",
    "             '6h_c8','6h_c9','6h_c10', '6h_c11', '6h_c12','6h_c13','6h_c14','6h_c15'], \n",
    "               'SinglePeak_Scaled':['6h_sp_+0%','6h_sp_+5%','6h_sp_+10%','6h_sp_+15%','6h_sp_+20%']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a2ae818",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = methods_dict[methods_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29431f3",
   "metadata": {},
   "source": [
    "### Get version of landcover array with just 'urban' and 'rural' categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d74109dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water landcover classification - 10 is water, 11 is eveyrthing else\n",
    "with rasterio.open(landcover_directory + 'LandCover_notwater_classification.tif', 'r') as ds:\n",
    "    landcover_notwater = ds.read()[0]\n",
    "    out_meta = ds.meta\n",
    "landcover_notwater_flat = landcover_notwater.flatten()\n",
    "\n",
    "# Urban landcover classification - 10 is urban, 1 is everything else\n",
    "with rasterio.open(landcover_directory + 'LandCover_urban_and_suburban_classification.tif', 'r') as ds:\n",
    "    landcover_urban = ds.read()[0]\n",
    "landcover_urban_flat = landcover_urban.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792fabc1",
   "metadata": {},
   "source": [
    "### Find maximum intensity for each method and minute in which it occurs (to use in sorting results analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b24edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = []\n",
    "min_of_maxs = []\n",
    "\n",
    "for method in methods:\n",
    "    if method == '6h_feh_singlepeak':\n",
    "        precip=pd.read_csv(\"../CreateSyntheticRainfallEvents/FEHProfiles/{}/6hr_100yrRP/PostLossRemoval/6hr_100yrRP_6.01h_1mintimestep.csv\".format(catchment_name))\n",
    "    elif method  == '6h_c12_copy':\n",
    "        method = '6h_c12'\n",
    "        precip=pd.read_csv(\"../CreateSyntheticRainfallEvents/{}Profiles/{}/6hr_100yrRP/PostLossRemoval/{}_urban.csv\".format(methods_key,catchment_name, method))\n",
    "    else:\n",
    "        precip=pd.read_csv(\"../CreateSyntheticRainfallEvents/{}Profiles/{}/6hr_100yrRP/PostLossRemoval/{}_urban.csv\".format(methods_key,catchment_name, method))\n",
    "    # Trim and add minutes column\n",
    "    precip = precip[0:360].copy()\n",
    "    precip['minute']=range(1,361)\n",
    "    # Add max and minutes of max\n",
    "    maxs.append(precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].max())\n",
    "    min_of_maxs.append(precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea22f7",
   "metadata": {},
   "source": [
    "### Create versions of lists of methods, in order based on max intensity and the the timing of the max intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c0354d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_ids_by_loading=  pd.DataFrame({\"min\": min_of_maxs, 'method_name': methods}).sort_values('min')[\"method_name\"].tolist()\n",
    "short_ids_by_intensity = pd.DataFrame({\"min\": maxs, 'method_name': methods}).sort_values('min', ascending = False)[\"method_name\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c5273",
   "metadata": {},
   "source": [
    "### Create dataframe of colours for each cluster (based on their loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b39ef169",
   "metadata": {},
   "outputs": [],
   "source": [
    "if methods_key == 'Observed':\n",
    "    colours_df = create_colours_df_observed(short_ids_by_loading, methods)\n",
    "elif methods_key == 'Idealised':\n",
    "    colours_df = create_colours_df_idealised( short_ids_by_loading, methods)\n",
    "elif methods_key == 'SinglePeak_Scaled':\n",
    "    colours_df = create_colours_df_sp( short_ids_by_loading, methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748b25b",
   "metadata": {},
   "source": [
    "### Create list of filepaths, formatted to be used for either depth or velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f847f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = []\n",
    "for method_num, short_id in enumerate(methods):\n",
    "    fp = model_directory + \"{}/{} (Max).{}.tif\".format(short_id, '{}', catchment_name_str)\n",
    "    fps.append(fp)\n",
    "if methods_key == 'Observed':\n",
    "    fps[0] = '../../../FloodModelling/{}Models/Model_FEHProfiles_export/6h_feh_singlepeak/{}/{} (Max).{}.tif'.format(catchment_name, region, '{}', catchment_name_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf33b1",
   "metadata": {},
   "source": [
    "# Hazard calculations\n",
    "The hazard is calculated based on definition here: https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/842485/What-is-the-Risk-of-Flooding-from-Surface-Water-Map.pdf . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8ea2d",
   "metadata": {},
   "source": [
    "### Calculate the hazard categories for the single peak results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2326e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in depth and velocity rasters\n",
    "sp_depth, out_meta = open_and_clip_to_catchment(fps[0].format('Depth'), catchment_gdf, crop_or_not)\n",
    "sp_velocity, out_meta = open_and_clip_to_catchment(fps[0].format('Velocity'),  catchment_gdf, crop_or_not)\n",
    "\n",
    "if remove_little_values == True:\n",
    "    sp_depth = remove_little_values_fxn(sp_depth, fp.format('Depth'), catchment_gdf, crop_or_not) \n",
    "    sp_velocity = remove_little_values_fxn(sp_velocity, fp.format('Velocity'), catchment_gdf, crop_or_not)    \n",
    "    \n",
    "# Create a composite hazard array\n",
    "sp_hazard= np.where((sp_depth.flatten())<0.25, (sp_depth.flatten()* (sp_velocity.flatten()+0.5) + 0.5) , (sp_depth.flatten() * (sp_velocity.flatten()+0.5) + 1))\n",
    "sp_hazard = sp_hazard.reshape(sp_depth.shape)    \n",
    "\n",
    "# Classify this according to bins\n",
    "breaks_hazard = np.array([0, 0.5, 0.75, 1.25,2, 100])  \n",
    "\n",
    "sp_classified_hazard = classify_raster(sp_hazard, breaks_hazard)\n",
    "# Save to file\n",
    "fp_for_hazard = fps[0].replace('{} (Max).{}'.format({}, catchment_name_str),'hazard_classified')\n",
    "save_array_as_raster(sp_classified_hazard, fp_for_hazard, out_meta) \n",
    "\n",
    "# Plot the classified hazard categories\n",
    "labels_hazard = ['Low hazard', 'Moderate hazard', 'Significant hazard', 'Extreme hazard']\n",
    "classified_colors_list_hazard = [mpl.cm.autumn_r(0.2),mpl.cm.autumn_r(0.5), mpl.cm.autumn_r(0.7),\"darkred\"]\n",
    "plot_classified_raster(fp_for_hazard, labels_hazard, classified_colors_list_hazard, catchment_gdf, catchment_name ,methods_key) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf0145",
   "metadata": {},
   "source": [
    "### Calculate the hazard categories for the other scenarios, and then find the difference in the categories between those and single peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "973f4a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c1/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c2/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c3/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c4/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c5/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c6/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c7/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c8/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c9/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c10/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c11/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c12/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c13/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c14/{} (Max).Resampled.Terrain.tif\n",
      "../../../FloodModelling/LinDykeModels/Model_ObservedProfiles_export/6h_c15/{} (Max).Resampled.Terrain.tif\n"
     ]
    }
   ],
   "source": [
    "for fp in fps[1:]:\n",
    "    print(fp)\n",
    "\n",
    "    # Read in depth and velocity rasters\n",
    "    depth, out_meta = open_and_clip_to_catchment(fp.format('Depth'), catchment_gdf, crop_or_not)\n",
    "    velocity, out_meta = open_and_clip_to_catchment(fp.format('Velocity'),  catchment_gdf, crop_or_not)\n",
    "\n",
    "    if remove_little_values == True:\n",
    "        depth = remove_little_values_fxn(depth, fp.format('Depth'), catchment_gdf, crop_or_not) \n",
    "        velocity = remove_little_values_fxn(velocity, fp.format('Velocity'), catchment_gdf, crop_or_not)    \n",
    "\n",
    "    # Create a composite hazard array\n",
    "    hazard= np.where((depth.flatten())<0.25, (depth.flatten()* (velocity.flatten()+0.5) + 0.5) , (depth.flatten() * (velocity.flatten()+0.5) + 1))\n",
    "    hazard = hazard.reshape(depth.shape)    \n",
    "    \n",
    "    # Classify this according to bins\n",
    "    classified_hazard = classify_raster(hazard, breaks_hazard)\n",
    "    # Save to file\n",
    "    fp_for_hazard = fp.replace('{} (Max).{}'.format({}, catchment_name_str),'{}_classified'.format('hazard') )\n",
    "    save_array_as_raster(classified_hazard, fp_for_hazard, out_meta) \n",
    "    # Plot the classified hazard categories\n",
    "    labels_hazard = ['Low hazard', 'Moderate hazard', 'Significant hazard', 'Extreme hazard']\n",
    "    classified_colors_list_hazard = [mpl.cm.autumn_r(0.2),mpl.cm.autumn_r(0.5), mpl.cm.autumn_r(0.7)]\n",
    "    plot_classified_raster(fp_for_hazard, labels_hazard, classified_colors_list_hazard, catchment_gdf, catchment_name ,methods_key)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979ec44",
   "metadata": {},
   "source": [
    "# <u> Flood extent </u>\n",
    "To examine whether the rainfall's temporal distribution influences the total extent of flooding, the number of flooded cells and the total flooded area in km2 (incl. only cells with depth >0.1m) is compared between the profile with a single peak, and the three methods for producing multi-peaked rainfall events. b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130fbb2",
   "metadata": {},
   "source": [
    "### Create dataframes containing the (total/urban) flooded area in each depth/velocity bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42e3818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define breaks to split the depths/velocities on\n",
    "breaks_depths = np.array([0, 0.3, 0.6, 1.2, 100])  \n",
    "labels_depth = ['<=0.3m', '0.3-0.6m', '0.6-1.2m', '>1.2m']\n",
    "breaks_velocity = np.array([0,0.25,0.5,2,100])\n",
    "labels_velocity = [\"<=0.25m/s\", \"0.25-0.5m/s\", \"0.5-2m/s\", \">2m/s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af59db8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "velocity_counts, velocity_props = create_binned_counts_and_props(methods, fps, '', 'Velocity',catchment_gdf, crop_or_not=crop_or_not,\n",
    "                                                                remove_little_values = remove_little_values)\n",
    "depth_counts, depth_props  = create_binned_counts_and_props(methods, fps, '', 'Depth',catchment_gdf, crop_or_not = crop_or_not,\n",
    "                                                           remove_little_values = remove_little_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7241e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_counts_urban, velocity_props_urban = create_binned_counts_and_props(methods, fps, True,'Velocity', catchment_gdf,\n",
    "                                                         crop_or_not, landcover_urban_flat,  remove_little_values = remove_little_values)\n",
    "depth_counts_urban, depth_props_urban= create_binned_counts_and_props(methods, fps, True,'Depth',  catchment_gdf, \n",
    "                                                      crop_or_not, landcover_urban_flat, remove_little_values = remove_little_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6e6233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_counts_notwater, velocity_props_notwater = create_binned_counts_and_props(methods, fps, True,'Velocity', catchment_gdf,\n",
    "                                      crop_or_not, landcover_notwater_flat, remove_little_values = remove_little_values)\n",
    "depth_counts_notwater, depth_props_notwater = create_binned_counts_and_props(methods, fps, True,'Depth',catchment_gdf, \n",
    "                                    crop_or_not, landcover_notwater_flat, remove_little_values = remove_little_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d7ca3a",
   "metadata": {},
   "source": [
    "### Create dataframes containing the (total/urban) flooded area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0e7e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_df = create_totals_df(velocity_counts, cell_size_in_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d51a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_df_urban = create_totals_df(velocity_counts_urban, cell_size_in_m2)  \n",
    "totals_df_notwater = create_totals_df(velocity_counts_notwater, cell_size_in_m2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cf9b7",
   "metadata": {},
   "source": [
    "### Create dataframes containing the % diff in the flooded area between single peak and each other method  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd99a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "if methods_key == 'Observed':\n",
    "    column_for_comparison = '6h_feh_singlepeak'\n",
    "elif methods_key == 'Idealised':\n",
    "    column_for_comparison ='6h_sp_c_0.5'    \n",
    "elif methods_key == 'SinglePeak_Scaled':\n",
    "    column_for_comparison ='6h_sp_+0%'        \n",
    "    \n",
    "percent_diffs_df = find_percentage_diff (methods, column_for_comparison, totals_df, fps) \n",
    "percent_diffs_df_urban = find_percentage_diff (methods, column_for_comparison, totals_df_urban, fps)\n",
    "percent_diffs_df_notwater = find_percentage_diff (methods, column_for_comparison, totals_df_notwater, fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b76f8",
   "metadata": {},
   "source": [
    "## Find number of cells with each hazard rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8865c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_counts, hazard_props = create_binned_counts_and_props_hazard(methods, fps, '', catchment_name_str,catchment_gdf, \n",
    "                                                                    crop_or_not, landcover_data=False, remove_little_values =remove_little_values )\n",
    "hazard_counts_urban, hazard_props_urban = create_binned_counts_and_props_hazard(methods, fps, 'Urban', catchment_name_str,\n",
    "                                                                catchment_gdf, crop_or_not, landcover_urban, remove_little_values = remove_little_values)\n",
    "hazard_counts_notwater, hazard_props_notwater = create_binned_counts_and_props_hazard(methods, fps, 'Notwater', \n",
    "                                                    catchment_name_str,catchment_gdf, crop_or_not, landcover_notwater, remove_little_values = remove_little_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "678e105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>6h_feh_singlepeak</th>\n",
       "      <th>6h_c1</th>\n",
       "      <th>6h_c2</th>\n",
       "      <th>6h_c3</th>\n",
       "      <th>6h_c4</th>\n",
       "      <th>6h_c5</th>\n",
       "      <th>6h_c6</th>\n",
       "      <th>6h_c7</th>\n",
       "      <th>6h_c8</th>\n",
       "      <th>6h_c9</th>\n",
       "      <th>6h_c10</th>\n",
       "      <th>6h_c11</th>\n",
       "      <th>6h_c12</th>\n",
       "      <th>6h_c13</th>\n",
       "      <th>6h_c14</th>\n",
       "      <th>6h_c15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low hazard</td>\n",
       "      <td>231129</td>\n",
       "      <td>273119</td>\n",
       "      <td>200362</td>\n",
       "      <td>232503</td>\n",
       "      <td>193337</td>\n",
       "      <td>293670</td>\n",
       "      <td>201872</td>\n",
       "      <td>232873</td>\n",
       "      <td>153019</td>\n",
       "      <td>186838</td>\n",
       "      <td>208267</td>\n",
       "      <td>158083</td>\n",
       "      <td>182634</td>\n",
       "      <td>193239</td>\n",
       "      <td>238517</td>\n",
       "      <td>227869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moderate hazard</td>\n",
       "      <td>67885</td>\n",
       "      <td>75205</td>\n",
       "      <td>56569</td>\n",
       "      <td>65118</td>\n",
       "      <td>54227</td>\n",
       "      <td>74328</td>\n",
       "      <td>58457</td>\n",
       "      <td>62562</td>\n",
       "      <td>48538</td>\n",
       "      <td>54397</td>\n",
       "      <td>59935</td>\n",
       "      <td>48535</td>\n",
       "      <td>52559</td>\n",
       "      <td>55904</td>\n",
       "      <td>65623</td>\n",
       "      <td>65866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Significant hazard</td>\n",
       "      <td>181454</td>\n",
       "      <td>202278</td>\n",
       "      <td>157624</td>\n",
       "      <td>177030</td>\n",
       "      <td>149838</td>\n",
       "      <td>215004</td>\n",
       "      <td>160992</td>\n",
       "      <td>175148</td>\n",
       "      <td>132380</td>\n",
       "      <td>150107</td>\n",
       "      <td>162535</td>\n",
       "      <td>135539</td>\n",
       "      <td>146114</td>\n",
       "      <td>153834</td>\n",
       "      <td>183620</td>\n",
       "      <td>174737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extreme hazard</td>\n",
       "      <td>29381</td>\n",
       "      <td>31669</td>\n",
       "      <td>26435</td>\n",
       "      <td>28351</td>\n",
       "      <td>24463</td>\n",
       "      <td>35066</td>\n",
       "      <td>25959</td>\n",
       "      <td>30621</td>\n",
       "      <td>17059</td>\n",
       "      <td>22830</td>\n",
       "      <td>25245</td>\n",
       "      <td>19575</td>\n",
       "      <td>23892</td>\n",
       "      <td>23077</td>\n",
       "      <td>31873</td>\n",
       "      <td>25270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index  6h_feh_singlepeak   6h_c1   6h_c2   6h_c3   6h_c4  \\\n",
       "0          Low hazard             231129  273119  200362  232503  193337   \n",
       "1     Moderate hazard              67885   75205   56569   65118   54227   \n",
       "2  Significant hazard             181454  202278  157624  177030  149838   \n",
       "3      Extreme hazard              29381   31669   26435   28351   24463   \n",
       "\n",
       "    6h_c5   6h_c6   6h_c7   6h_c8   6h_c9  6h_c10  6h_c11  6h_c12  6h_c13  \\\n",
       "0  293670  201872  232873  153019  186838  208267  158083  182634  193239   \n",
       "1   74328   58457   62562   48538   54397   59935   48535   52559   55904   \n",
       "2  215004  160992  175148  132380  150107  162535  135539  146114  153834   \n",
       "3   35066   25959   30621   17059   22830   25245   19575   23892   23077   \n",
       "\n",
       "   6h_c14  6h_c15  \n",
       "0  238517  227869  \n",
       "1   65623   65866  \n",
       "2  183620  174737  \n",
       "3   31873   25270  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hazard_counts_notwater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "295e8c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>6h_feh_singlepeak</th>\n",
       "      <th>6h_c1</th>\n",
       "      <th>6h_c2</th>\n",
       "      <th>6h_c3</th>\n",
       "      <th>6h_c4</th>\n",
       "      <th>6h_c5</th>\n",
       "      <th>6h_c6</th>\n",
       "      <th>6h_c7</th>\n",
       "      <th>6h_c8</th>\n",
       "      <th>6h_c9</th>\n",
       "      <th>6h_c10</th>\n",
       "      <th>6h_c11</th>\n",
       "      <th>6h_c12</th>\n",
       "      <th>6h_c13</th>\n",
       "      <th>6h_c14</th>\n",
       "      <th>6h_c15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low hazard</td>\n",
       "      <td>235335</td>\n",
       "      <td>277475</td>\n",
       "      <td>204083</td>\n",
       "      <td>236572</td>\n",
       "      <td>196884</td>\n",
       "      <td>297040</td>\n",
       "      <td>205693</td>\n",
       "      <td>236574</td>\n",
       "      <td>155604</td>\n",
       "      <td>190445</td>\n",
       "      <td>212186</td>\n",
       "      <td>160793</td>\n",
       "      <td>185830</td>\n",
       "      <td>196945</td>\n",
       "      <td>242199</td>\n",
       "      <td>232072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moderate hazard</td>\n",
       "      <td>70962</td>\n",
       "      <td>79170</td>\n",
       "      <td>58591</td>\n",
       "      <td>68405</td>\n",
       "      <td>55906</td>\n",
       "      <td>78963</td>\n",
       "      <td>60695</td>\n",
       "      <td>65978</td>\n",
       "      <td>49380</td>\n",
       "      <td>56053</td>\n",
       "      <td>62467</td>\n",
       "      <td>49530</td>\n",
       "      <td>53975</td>\n",
       "      <td>57678</td>\n",
       "      <td>69380</td>\n",
       "      <td>68957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Significant hazard</td>\n",
       "      <td>183752</td>\n",
       "      <td>205547</td>\n",
       "      <td>159635</td>\n",
       "      <td>179378</td>\n",
       "      <td>151738</td>\n",
       "      <td>219556</td>\n",
       "      <td>162898</td>\n",
       "      <td>177727</td>\n",
       "      <td>133550</td>\n",
       "      <td>151839</td>\n",
       "      <td>164404</td>\n",
       "      <td>136937</td>\n",
       "      <td>147898</td>\n",
       "      <td>155618</td>\n",
       "      <td>186334</td>\n",
       "      <td>176861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extreme hazard</td>\n",
       "      <td>29407</td>\n",
       "      <td>31695</td>\n",
       "      <td>26461</td>\n",
       "      <td>28376</td>\n",
       "      <td>24488</td>\n",
       "      <td>35102</td>\n",
       "      <td>25983</td>\n",
       "      <td>30648</td>\n",
       "      <td>17071</td>\n",
       "      <td>22848</td>\n",
       "      <td>25265</td>\n",
       "      <td>19590</td>\n",
       "      <td>23916</td>\n",
       "      <td>23101</td>\n",
       "      <td>31904</td>\n",
       "      <td>25293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index  6h_feh_singlepeak   6h_c1   6h_c2   6h_c3   6h_c4  \\\n",
       "0          Low hazard             235335  277475  204083  236572  196884   \n",
       "1     Moderate hazard              70962   79170   58591   68405   55906   \n",
       "2  Significant hazard             183752  205547  159635  179378  151738   \n",
       "3      Extreme hazard              29407   31695   26461   28376   24488   \n",
       "\n",
       "    6h_c5   6h_c6   6h_c7   6h_c8   6h_c9  6h_c10  6h_c11  6h_c12  6h_c13  \\\n",
       "0  297040  205693  236574  155604  190445  212186  160793  185830  196945   \n",
       "1   78963   60695   65978   49380   56053   62467   49530   53975   57678   \n",
       "2  219556  162898  177727  133550  151839  164404  136937  147898  155618   \n",
       "3   35102   25983   30648   17071   22848   25265   19590   23916   23101   \n",
       "\n",
       "   6h_c14  6h_c15  \n",
       "0  242199  232072  \n",
       "1   69380   68957  \n",
       "2  186334  176861  \n",
       "3   31904   25293  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hazard_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46068d8",
   "metadata": {},
   "source": [
    "### Create a dataframe containing all the info on each of the scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "884a8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results = pd.DataFrame({'Cluster_num': methods, \"MaxRainfallIntensity\": maxs,  \n",
    "    \"MaxRainfallIntensityMinute\": min_of_maxs,\n",
    "    # All cells\n",
    "   'FloodedArea':totals_df['FloodedArea'],\n",
    "    '%Diff_FloodedArea_fromSP':percent_diffs_df['percent_diffs'],\n",
    "    '%Diff_FloodedArea_fromSP_formatted':percent_diffs_df['percent_diff_formatted'],\n",
    "    'Abs%Diff_FloodedArea_fromSP':percent_diffs_df['percent_diffs_abs'],\n",
    "    # Urban cells\n",
    " 'UrbanFloodedArea':totals_df_urban['FloodedArea'],\n",
    " '%Diff_UrbanFloodedArea_fromSP':percent_diffs_df_urban['percent_diffs'] ,\n",
    "  '%Diff_UrbanFloodedArea_fromSP_formatted':percent_diffs_df_urban['percent_diff_formatted'],\n",
    "   'Abs%Diff_UrbanFloodedArea_fromSP':percent_diffs_df_urban['percent_diffs_abs'], \n",
    "    # Not water cells\n",
    " 'NotwaterFloodedArea':totals_df_notwater['FloodedArea'],\n",
    " '%Diff_NotwaterFloodedArea_fromSP':percent_diffs_df_notwater['percent_diffs'] ,\n",
    "  '%Diff_NotwaterFloodedArea_fromSP_formatted':percent_diffs_df_notwater['percent_diff_formatted'],\n",
    "   'Abs%Diff_NotwaterFloodedArea_fromSP':percent_diffs_df_notwater['percent_diffs_abs'],                                          \n",
    "   #'WorstCaseDepth_ncells': worst_case_method_depth['counts'].tolist(),\n",
    "   # 'WorstCaseVelocity_ncells': worst_case_method_velocity['counts'].tolist(), \n",
    "                                'colour':colours_df['colour']}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681011fa",
   "metadata": {},
   "source": [
    "### Add the depth/velocity category breakdowns and hazard categories to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d03d47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [velocity_props, depth_props,  velocity_props_urban, depth_props_urban,  velocity_props_notwater, depth_props_notwater,   \n",
    "       velocity_counts, depth_counts, velocity_counts_urban, depth_counts_urban, velocity_counts_notwater, depth_counts_notwater,  \n",
    "       hazard_counts, hazard_props, hazard_counts_urban, hazard_props_urban, hazard_counts_notwater, hazard_props_notwater, ]\n",
    "suffixes = ['_propcells', '_propcells', '_propcells_urban','_propcells_urban','_propcells_notwater','_propcells_notwater',\n",
    "            '_countcells','_countcells','_countcells_urban', '_countcells_urban','_countcells_notwater', '_countcells_notwater', '_countcells_notwater', '_countcells_notwater',\n",
    "            '_countcells', '_propcells',  '_countcells_urban', '_propcells_urban', '_countcells_notwater', '_propcells_notwater', ]\n",
    "\n",
    "for num, df in enumerate(dfs):\n",
    "    # Reformat the dataframe\n",
    "    df = df.set_index('index').T\n",
    "    # Add the correct suffix to the column names\n",
    "    df = df.add_suffix(suffixes[num]) \n",
    "    # Add Cluster_num column for joining\n",
    "    df['Cluster_num'] = df.index#\n",
    "    # Join to cluster results dataframe\n",
    "    cluster_results = pd.merge(cluster_results,  df, how=\"outer\", on = 'Cluster_num')\n",
    "    \n",
    "# cluster_results = pd.merge(cluster_results, hazard_cat_changes,  how=\"outer\", on = 'Cluster_num')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90adfff",
   "metadata": {},
   "source": [
    "### Finding proportion of area/urban area flooded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c2975ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_results['%floodedarea_urban'] = round(cluster_results['UrbanFloodedArea']/cluster_results['FloodedArea']*100,2)\n",
    "# cluster_results['%_of_area_flooded'] =(cluster_results['FloodedArea']/29.589)*100\n",
    "# cluster_results['%_of_urban_area_flooded'] =(cluster_results['UrbanFloodedArea']/7.987)*100\n",
    "# # Add NAs for SP\n",
    "# cluster_results['%Diff_FloodedArea_fromSP_formatted']=cluster_results['%Diff_FloodedArea_fromSP_formatted'].fillna('')\n",
    "# cluster_results['%Diff_UrbanFloodedArea_fromSP_formatted']=cluster_results['%Diff_UrbanFloodedArea_fromSP_formatted'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30496b10",
   "metadata": {},
   "source": [
    "## Summarise the number of cells in different depth/velocity categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1d4c8",
   "metadata": {},
   "source": [
    "#### Get one dataframe containing the values for all methods, one row per cell per method \n",
    "Also including the water class variable in that cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d263c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "each_cells_value = produce_df_of_cell_by_cell_values(model_directory, catchment_gdf, catchment_name_str, methods, \n",
    "                                                     landcover_notwater_flat,landcover_urban_flat, crop_or_not,\n",
    "                                                    remove_little_values = remove_little_values)\n",
    "# rename for consistency\n",
    "each_cells_value['short_id'] = each_cells_value['short_id'].map({'6h_feh_singlepeak': 'FEH'}).fillna(each_cells_value['short_id'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8638ecbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  3.,  4.,  5., nan]),\n",
       " array([297040,  78963, 219556,  35102, 490260]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(each_cells_value[each_cells_value['short_id']=='6h_c5']['Hazard'], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b701b1",
   "metadata": {},
   "source": [
    "### Rename the profile names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ed009e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if methods_key == 'Idealised':\n",
    "    cluster_results['Cluster_num']=['C', 'FL1', 'FL2', 'FL3', 'FL4','BL6', 'BL7', 'BL8','BL9']\n",
    "    ### Reorder to C in middle\n",
    "    cluster_results = cluster_results.reindex([1,2,3,4,0,5,6,7,8])\n",
    "    cluster_results.reset_index(inplace=True, drop=True)\n",
    "if methods_key == 'Observed':\n",
    "    methods = ['6h_feh_singlepeak','6h_c1','6h_c8','6h_c15','6h_c3','6h_c11','6h_c10','6h_c9','6h_c13','6h_c6',\n",
    "                 '6h_c2','6h_c12','6h_c14','6h_c4','6h_c7','6h_c5']\n",
    "    cluster_results = cluster_results.reindex(cluster_results['Cluster_num'].map(dict(zip(methods, range(len(methods))))).sort_values().index)\n",
    "    cluster_results.reset_index(inplace=True, drop=True)\n",
    "    cluster_results['Cluster_num'] = cluster_results['Cluster_num'].map({'6h_feh_singlepeak': 'FEH'}).fillna(cluster_results['Cluster_num'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d6402",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6facf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create path to the folder\n",
    "path = \"Outputs/Data/{}Profiles/{}/\".format(methods_key, catchment_name)\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path)\n",
    "# Create a new directory because it does not exist\n",
    "if not isExist:\n",
    "    os.makedirs(path)\n",
    "# # Save\n",
    "cluster_results.to_csv(path + \"{}allclusters_summary_notwetlands.csv\".format(region), index=False)\n",
    "\n",
    "# Save\n",
    "each_cells_value.to_csv(path + \"{}individual_cell_values_notwetlands.csv\".format(region), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2e4ae80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_id</th>\n",
       "      <th>Water_class</th>\n",
       "      <th>urban_class</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Velocity</th>\n",
       "      <th>Hazard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299545</th>\n",
       "      <td>FEH</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.128</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299546</th>\n",
       "      <td>FEH</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.129</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305745</th>\n",
       "      <td>FEH</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.125</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305746</th>\n",
       "      <td>FEH</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.122</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305747</th>\n",
       "      <td>FEH</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.121</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472881</th>\n",
       "      <td>6h_c15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36479082</th>\n",
       "      <td>6h_c15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36485283</th>\n",
       "      <td>6h_c15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36485284</th>\n",
       "      <td>6h_c15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36491485</th>\n",
       "      <td>6h_c15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15953005 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         short_id  Water_class  urban_class  Depth  Velocity  Hazard\n",
       "299545        FEH         15.0         16.0  0.107     0.128     2.0\n",
       "299546        FEH         15.0         16.0  0.106     0.129     2.0\n",
       "305745        FEH         15.0         16.0  0.257     0.125     3.0\n",
       "305746        FEH         15.0         16.0  0.215     0.122     2.0\n",
       "305747        FEH         15.0         16.0  0.212     0.121     2.0\n",
       "...           ...          ...          ...    ...       ...     ...\n",
       "36472881   6h_c15         15.0         16.0  0.245     0.016     NaN\n",
       "36479082   6h_c15         15.0         16.0  0.159     0.015     NaN\n",
       "36485283   6h_c15         15.0         16.0  0.105     0.011     NaN\n",
       "36485284   6h_c15         15.0         16.0  0.186     0.013     NaN\n",
       "36491485   6h_c15         15.0         16.0  0.106     0.010     NaN\n",
       "\n",
       "[15953005 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_cells_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
