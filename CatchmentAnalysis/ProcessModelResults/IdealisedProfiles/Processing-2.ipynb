{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1491398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from my_functions_idealisedprofiles import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29431f3",
   "metadata": {},
   "source": [
    "### Get version of landcover array with just 'urban' and 'rural' categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b7c8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "landcover, out_meta = prepare_rainfall_scenario_raster(model_directory + \"LandCover_clipped.tif\", True)\n",
    "# Convert the 1 and 6 values to 10 (for urban) and the rest to 11 (for non-urban).  \n",
    "landcover_mod =  np.where(landcover==1, 10, landcover)\n",
    "landcover_mod =  np.where(landcover_mod==6, 10, landcover_mod)\n",
    "# Convert the rest of the classes to 11\n",
    "for i in [1,2,3,4,5,7,8,9]:\n",
    "    landcover_mod =  np.where(landcover_mod==i, 11, landcover_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ab40f",
   "metadata": {},
   "source": [
    "### Define the names of the method (shorter and longer versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "276042a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods =['6h_feh_sp', '6h_sp_fl_0.1', '6h_sp_fl_0.2', '6h_sp_fl_0.3', '6h_sp_fl_0.4', '6h_sp_c_0.5',\n",
    "          '6h_sp_bl_0.6','6h_sp_bl_0.7','6h_sp_bl_0.8','6h_sp_bl_0.9']\n",
    "short_ids = ['6h_feh_sp', '6h_sp_fl_0.1', '6h_sp_fl_0.2', '6h_sp_fl_0.3', '6h_sp_fl_0.4', '6h_sp_c_0.5',\n",
    "          '6h_sp_bl_0.6','6h_sp_bl_0.7','6h_sp_bl_0.8','6h_sp_bl_0.9']   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792fabc1",
   "metadata": {},
   "source": [
    "### Find maximum intensity for each method and minute in which it occurs (to use in sorting results analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2b24edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = []\n",
    "min_of_maxs = []\n",
    "\n",
    "# Add FEH data\n",
    "feh_precip=pd.read_csv(\"../../CreateSyntheticRainfallEvents/ReFH2_singlepeak/6hr_100yrRP/PostLossRemoval/6h_feh_singlepeak_urban.csv\")\n",
    "maxs.append(feh_precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].max())\n",
    "min_of_maxs.append(feh_precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].idxmax())\n",
    "\n",
    "for method in methods[1:]:\n",
    "#     if method == '6h_single-peak':\n",
    "#         precip=pd.read_csv(\"../../CreateSyntheticRainfallEvents/SyntheticProfiles/6hr_100yrRP/PostLossRemoval/{}_urban.csv\".format(method))\n",
    "#     else:\n",
    "    precip=pd.read_csv(\"../../CreateSyntheticRainfallEvents/IdealisedProfiles/6hr_100yrRP/PostLossRemoval/{}_urban.csv\".format(method))\n",
    "    maxs.append(precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].max())\n",
    "    min_of_maxs.append(precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea22f7",
   "metadata": {},
   "source": [
    "### Create versions of lists of methods, in order based on max intensity and the the timing of the max intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c0354d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_ids_by_loading=  pd.DataFrame({\"min\": min_of_maxs, 'method_name': short_ids}).sort_values('min')[\"method_name\"].tolist()\n",
    "short_ids_by_loading.remove('6h_feh_sp')\n",
    "short_ids_by_loading = ['6h_feh_sp']+short_ids_by_loading\n",
    "\n",
    "short_ids_by_intensity = pd.DataFrame({\"min\": maxs, 'method_name': short_ids}).sort_values('min', ascending = False)[\"method_name\"].tolist()\n",
    "short_ids_by_intensity.remove('6h_feh_sp')\n",
    "short_ids_by_intensity = ['6h_feh_sp']+short_ids_by_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c5273",
   "metadata": {},
   "source": [
    "### Create dataframe of colours for each cluster (based on their loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "677e0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ['black'] + ['darkblue']*2 + ['paleturquoise']*2 + ['grey']+  ['indianred']*2 + ['darkred']*2\n",
    "loadings = ['FEH'] + ['F2']*2 + ['F1']*2 + ['C']+  ['B1']*2 + ['B2']*2\n",
    "colours_df = pd.DataFrame({ 'short_id': short_ids_by_loading, \"colour\": colours, 'loading':loadings})\n",
    "colours_df = colours_df.reindex(colours_df['short_id'].map(dict(zip(short_ids, range(len(short_ids))))).sort_values().index)\n",
    "colours_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4c1a3093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colours_df (short_ids_by_loading, short_ids):\n",
    "    colours = ['black'] + ['darkblue']*2 + ['paleturquoise']*2 + ['grey']+  ['indianred']*2 + ['darkred']*2\n",
    "    loadings = ['FEH'] + ['F2']*2 + ['F1']*2 + ['C']+  ['B1']*2 + ['B2']*2\n",
    "    colours_df = pd.DataFrame({ 'short_id': short_ids_by_loading, \"colour\": colours, 'loading':loadings})\n",
    "    colours_df = colours_df.reindex(colours_df['short_id'].map(dict(zip(short_ids, range(len(short_ids))))).sort_values().index)\n",
    "    colours_df.reset_index(inplace=True, drop=True)\n",
    "    return colours_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "80b2acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours_df = create_colours_df(short_ids_by_loading, short_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748b25b",
   "metadata": {},
   "source": [
    "### Create list of filepaths, formatted to be used for either depth or velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f847f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = []\n",
    "for method_num, short_id in enumerate(short_ids):\n",
    "    fp = model_directory + \"{}/{} (Max).Resampled.Terrain.tif\".format(short_id, '{}')\n",
    "    fps.append(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa5f30",
   "metadata": {},
   "source": [
    "### Define breaks for categorising velocity and depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c3abe3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define breaks to split the depths/velocities on\n",
    "breaks_depths = np.array([0, 0.3, 0.6, 1.2, 100])  \n",
    "labels_depth = ['<=0.3m', '0.3-0.6m', '0.6-1.2m', '>1.2m']\n",
    "breaks_velocity = np.array([0,0.25,0.5,2,100])\n",
    "labels_velocity = [\"<=0.25m/s\", \"0.25-0.5m/s\", \"0.5-2m/s\", \">2m/s\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979ec44",
   "metadata": {},
   "source": [
    "# <u> Flood extent </u>\n",
    "To examine whether the rainfall's temporal distribution influences the total extent of flooding, the number of flooded cells and the total flooded area in km2 (incl. only cells with depth >0.1m) is compared between the profile with a single peak, and the three methods for producing multi-peaked rainfall events. b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130fbb2",
   "metadata": {},
   "source": [
    "### Create dataframes containing the (total/urban) flooded area in each depth/velocity bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f612502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binned_counts_and_props(fps, variable_name, breaks, labels, remove_little_values):\n",
    "    # Create dataframes to populate with values\n",
    "    counts_df = pd.DataFrame()\n",
    "    proportions_df = pd.DataFrame()        \n",
    "\n",
    "    # Loop through each rainfall scenario\n",
    "    # Get the raster containing its values, and count the number of each unique value, and construct into a dataframe\n",
    "    for fp in fps  :\n",
    "        # Classify depth/velocity rasters into depth/velocity bins\n",
    "        raster = prepare_rainfall_scenario_raster(fp.format(variable_name), remove_little_values)[0]\n",
    "        unique, counts = np.unique(raster, return_counts=True)\n",
    "        df = pd.DataFrame({'values': unique, 'counts':counts})\n",
    "\n",
    "        # Add a new column specifying the bin which each value falls within\n",
    "        df['bins']= pd.cut(unique, bins=breaks, right=False)\n",
    "\n",
    "        # Create a new dataframe showing the number of cells in each of the bins\n",
    "        groups = df.groupby(['bins']).sum()\n",
    "        groups  = groups.reset_index()\n",
    "\n",
    "        # Find the total number of cells\n",
    "        total_n_cells = groups ['counts'].sum()\n",
    "        # Find the number of cells in each group as a proportion of the total\n",
    "        groups['Proportion'] = round((groups['counts']/total_n_cells) *100,1)\n",
    "\n",
    "        # Add values to dataframes\n",
    "        method_name = re.search('{}(.*)/'.format(model_directory), fp).group(1)\n",
    "        counts_df[method_name] = groups['counts']\n",
    "        proportions_df[method_name] = groups['Proportion']\n",
    "\n",
    "    # Reset index to show the groups\n",
    "    counts_df.reset_index(inplace=True)\n",
    "    proportions_df.reset_index(inplace=True)\n",
    "\n",
    "    # Set index values\n",
    "    counts_df['index'] = labels\n",
    "    proportions_df['index'] = labels\n",
    "\n",
    "    return counts_df, proportions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c743664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binned_counts_and_props(fps, variable_name, breaks, labels, remove_little_values):\n",
    "    # Create dataframes to populate with values\n",
    "    counts_df = pd.DataFrame()\n",
    "    proportions_df = pd.DataFrame()        \n",
    "\n",
    "    # Loop through each rainfall scenario\n",
    "    # Get the raster containing its values, and count the number of each unique value, and construct into a dataframe\n",
    "    for fp in fps  :\n",
    "        if fp == '../../../../FloodModelling/MeganModel_New/6h_sp_c_0.5/{} (Max).Resampled.Terrain.tif':\n",
    "            fp = '../../../../FloodModelling/MeganModel_New//6h_sp/(Max).Resampled.Terrain.tif'\n",
    "        else:   \n",
    "            # Classify depth/velocity rasters into depth/velocity bins\n",
    "            raster = prepare_rainfall_scenario_raster(fp.format(variable_name), remove_little_values)[0]\n",
    "            unique, counts = np.unique(raster, return_counts=True)\n",
    "            df = pd.DataFrame({'values': unique, 'counts':counts})\n",
    "\n",
    "            # Add a new column specifying the bin which each value falls within\n",
    "            df['bins']= pd.cut(unique, bins=breaks, right=False)\n",
    "\n",
    "            # Create a new dataframe showing the number of cells in each of the bins\n",
    "            groups = df.groupby(['bins']).sum()\n",
    "            groups  = groups.reset_index()\n",
    "\n",
    "            # Find the total number of cells\n",
    "            total_n_cells = groups ['counts'].sum()\n",
    "            # Find the number of cells in each group as a proportion of the total\n",
    "            groups['Proportion'] = round((groups['counts']/total_n_cells) *100,1)\n",
    "\n",
    "            # Add values to dataframes\n",
    "            method_name = re.search('{}(.*)/'.format(model_directory), fp).group(1)\n",
    "            counts_df[method_name] = groups['counts']\n",
    "            proportions_df[method_name] = groups['Proportion']\n",
    "\n",
    "    # Reset index to show the groups\n",
    "    counts_df.reset_index(inplace=True)\n",
    "    proportions_df.reset_index(inplace=True)\n",
    "\n",
    "    # Set index values\n",
    "    counts_df['index'] = labels\n",
    "    proportions_df['index'] = labels\n",
    "\n",
    "    return counts_df, proportions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9af59db8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": "../../../../FloodModelling/MeganModel_New/6h_sp_c_0.5/Velocity (Max).Resampled.Terrain.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mrasterio/_base.pyx:307\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_base.pyx:218\u001b[0m, in \u001b[0;36mrasterio._base.open_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:221\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: ../../../../FloodModelling/MeganModel_New/6h_sp_c_0.5/Velocity (Max).Resampled.Terrain.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [82], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m velocity_counts, velocity_props \u001b[38;5;241m=\u001b[39m create_binned_counts_and_props(fps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVelocity\u001b[39m\u001b[38;5;124m'\u001b[39m, breaks_velocity, labels_velocity, remove_little_values)\n\u001b[1;32m      2\u001b[0m depth_counts, depth_props \u001b[38;5;241m=\u001b[39m create_binned_counts_and_props(fps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepth\u001b[39m\u001b[38;5;124m'\u001b[39m, breaks_depths, labels_depth, remove_little_values)\n\u001b[0;32m----> 4\u001b[0m velocity_counts_urban, velocity_props_urban \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_binned_counts_and_props_urban\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVelocity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbreaks_velocity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_velocity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_little_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlandcover_mod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m depth_counts_urban, depth_props_urban \u001b[38;5;241m=\u001b[39m create_binned_counts_and_props_urban(fps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepth\u001b[39m\u001b[38;5;124m'\u001b[39m, breaks_depths, labels_depth, remove_little_values, landcover_mod)\n",
      "File \u001b[0;32m/nfs/a319/gy17m2a/PhD/Scripts/CatchmentAnalysis/ProcessModelResults/IdealisedProfiles/my_functions_idealisedprofiles.py:176\u001b[0m, in \u001b[0;36mcreate_binned_counts_and_props_urban\u001b[0;34m(fps, variable_name, breaks, labels, remove_little_values, landcover_mod)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Loop through each rainfall scenario\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Get the raster containing its values, and count the number of each unique value, and construct into a dataframe\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fp \u001b[38;5;129;01min\u001b[39;00m fps:\n\u001b[0;32m--> 176\u001b[0m     raster \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_rainfall_scenario_raster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_little_values\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# Create a dataframe with each row relating to a cell and its landcover and depth/velocity value\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     raster_and_landcover \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcovercategory\u001b[39m\u001b[38;5;124m'\u001b[39m:  landcover_mod\u001b[38;5;241m.\u001b[39mflatten(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: raster\u001b[38;5;241m.\u001b[39mflatten()})\n",
      "File \u001b[0;32m/nfs/a319/gy17m2a/PhD/Scripts/CatchmentAnalysis/ProcessModelResults/IdealisedProfiles/my_functions_idealisedprofiles.py:307\u001b[0m, in \u001b[0;36mprepare_rainfall_scenario_raster\u001b[0;34m(input_raster_fp, remove_little_values)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_rainfall_scenario_raster\u001b[39m(input_raster_fp, remove_little_values):\n\u001b[1;32m    304\u001b[0m     \n\u001b[1;32m    305\u001b[0m     \u001b[38;5;66;03m# Clip the raster files to the extent of the catchment boundary\u001b[39;00m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;66;03m# Also return out_meta which contains..\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m     raster, out_meta \u001b[38;5;241m=\u001b[39m \u001b[43mopen_and_clip\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_raster_fp\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    309\u001b[0m     \u001b[38;5;66;03m# If looking at velocity, then also read in depth raster as this is needed to filter out cells where \u001b[39;00m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# the depth is below 0.1m   \u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# Set cell values to Null in cells which have a value <0.1 in the depth raster\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remove_little_values \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/nfs/a319/gy17m2a/PhD/Scripts/CatchmentAnalysis/ProcessModelResults/IdealisedProfiles/my_functions_idealisedprofiles.py:265\u001b[0m, in \u001b[0;36mopen_and_clip\u001b[0;34m(input_raster_fp)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_and_clip\u001b[39m(input_raster_fp):\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# Read in data as array\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mrasterio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_raster_fp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# Create a bounding box \u001b[39;00m\n\u001b[1;32m    267\u001b[0m     minx, miny \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m437000\u001b[39m,  \u001b[38;5;241m426500\u001b[39m\n",
      "File \u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/pygeospatial/lib/python3.9/site-packages/rasterio/env.py:444\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    441\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/pygeospatial/lib/python3.9/site-packages/rasterio/__init__.py:304\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m path \u001b[38;5;241m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    306\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m get_writer_for_path(path, driver\u001b[38;5;241m=\u001b[39mdriver)(\n\u001b[1;32m    307\u001b[0m         path, mode, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    308\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_base.pyx:309\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: ../../../../FloodModelling/MeganModel_New/6h_sp_c_0.5/Velocity (Max).Resampled.Terrain.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "velocity_counts, velocity_props = create_binned_counts_and_props(fps, 'Velocity', breaks_velocity, labels_velocity, remove_little_values)\n",
    "depth_counts, depth_props = create_binned_counts_and_props(fps, 'Depth', breaks_depths, labels_depth, remove_little_values)\n",
    "\n",
    "velocity_counts_urban, velocity_props_urban = create_binned_counts_and_props_urban(fps, 'Velocity', breaks_velocity, labels_velocity, remove_little_values, landcover_mod)\n",
    "depth_counts_urban, depth_props_urban = create_binned_counts_and_props_urban(fps, 'Depth', breaks_depths, labels_depth, remove_little_values, landcover_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d7ca3a",
   "metadata": {},
   "source": [
    "### Create dataframes containing the (total/urban) flooded area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_df = create_totals_df(velocity_counts)\n",
    "totals_df_urban = create_totals_df(velocity_counts_urban)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cf9b7",
   "metadata": {},
   "source": [
    "### Create dataframes containing the % diff in the flooded area between single peak and each other method  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd99a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_diffs_df = find_percentage_diff (totals_df, fps) \n",
    "percent_diffs_df_urban = find_percentage_diff (totals_df_urban, fps)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcb2a6",
   "metadata": {},
   "source": [
    "## Find number of cells in which each method leads to the worst flooding (depth/velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48368b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of flooded cells with the worst flooding for each method\n",
    "worst_case_method_depth = find_worst_case_method(fps, short_ids, 'Depth')\n",
    "worst_case_method_velocity = find_worst_case_method(fps, short_ids,  'Velocity') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cf63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove multiple matches and nan\n",
    "worst_case_method_depth = worst_case_method_depth[~worst_case_method_depth['values'].isin(['multiple matches','nan'])]\n",
    "worst_case_method_velocity = worst_case_method_velocity[~worst_case_method_velocity['values'].isin(['multiple matches','nan'])]\n",
    "\n",
    "# # Reorder (and also add in the methods that are missing)\n",
    "worst_case_method_depth = pd.merge(worst_case_method_depth,  pd.DataFrame({'values': short_ids}), how=\"outer\")\n",
    "worst_case_method_depth = worst_case_method_depth.reindex(worst_case_method_depth['values'].map(dict(zip(short_ids, range(len(short_ids))))).sort_values().index)\n",
    "worst_case_method_depth.reset_index(inplace=True,drop=True)\n",
    "\n",
    "worst_case_method_velocity = pd.merge(worst_case_method_velocity,  pd.DataFrame({'values': short_ids}), how=\"outer\")\n",
    "worst_case_method_velocity = worst_case_method_velocity.reindex(worst_case_method_velocity['values'].map(dict(zip(short_ids, range(len(short_ids))))).sort_values().index)\n",
    "worst_case_method_velocity.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b76f8",
   "metadata": {},
   "source": [
    "## Find number of cells with each hazard rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60e1722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binned_counts_and_props_hazard(fps):\n",
    "\n",
    "    # Create dataframes to populate with values\n",
    "    counts_df = pd.DataFrame()\n",
    "    proportions_df = pd.DataFrame()      \n",
    "\n",
    "    for fp in fps:\n",
    "        # Define filepath\n",
    "        fp = '../../../../FloodModelling/MeganModel_New/{}/hazard_classified.tif'.format(fp.split('New/')[1].split('/{}')[0])\n",
    "        # Read in data\n",
    "        hazard = prepare_rainfall_scenario_raster(fp, remove_little_values)[0]\n",
    "        # Count the number of each value\n",
    "        unique, counts = np.unique(hazard, return_counts=True)\n",
    "        df = pd.DataFrame({'values': unique, 'counts':counts})\n",
    "        # Remove Nan values\n",
    "        df = df.dropna()\n",
    "\n",
    "        # Find the total number of cells\n",
    "        total_n_cells = df ['counts'].sum()\n",
    "        # Find the number of cells in each group as a proportion of the total\n",
    "        df['Proportion'] = round((df['counts']/total_n_cells) *100,1)\n",
    "        \n",
    "        # Add values to dataframes\n",
    "        method_name = re.search('{}(.*)/'.format(model_directory), fp).group(1)\n",
    "        counts_df[method_name] = df['counts']\n",
    "        proportions_df[method_name] = df['Proportion']\n",
    "\n",
    "    # Reset index to show the groups\n",
    "    counts_df.reset_index(inplace=True)\n",
    "    proportions_df.reset_index(inplace=True)\n",
    "\n",
    "    # Set index values\n",
    "    labels_hazard = ['Low hazard', 'Moderate hazard', 'Significant hazard', 'Extreme hazard']\n",
    "    counts_df['index'] = labels_hazard\n",
    "    proportions_df['index'] = labels_hazard\n",
    "    return counts_df, proportions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc775ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_counts, hazard_props = create_binned_counts_and_props_hazard(fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9253a1",
   "metadata": {},
   "source": [
    "## Find number of cells which have moved between hazard categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be350fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binned_counts_and_props_hazard_cat_change(fps):\n",
    "    # Create dataframes to populate with values\n",
    "    counts_df = pd.DataFrame(columns = [\"values\"])\n",
    "    proportions_df = pd.DataFrame(columns = [\"values\"]) \n",
    "\n",
    "    for fp in fps[1:]:\n",
    "        # Add values to dataframes\n",
    "        method_name = re.search('{}(.*)/'.format(model_directory), fp).group(1)\n",
    "        # Read in hazard data \n",
    "        fp = '../../../../FloodModelling/MeganModel_New/{}/hazard_cat_difference.tif'.format(fp.split('New/')[1].split('/{}')[0])\n",
    "        hazard = prepare_rainfall_scenario_raster(fp, False)[0]\n",
    "        unique, counts = np.unique(hazard, return_counts=True)\n",
    "        df = pd.DataFrame({'values': unique, method_name:counts})\n",
    "        # Remove NA columns\n",
    "        df = df.dropna()\n",
    "\n",
    "        # Add to dataframes\n",
    "        counts_df= counts_df.merge(df[['values', method_name]], on = 'values', how = 'outer')\n",
    "\n",
    "        # Find the total number of cells\n",
    "        total_n_cells = df [method_name].sum()\n",
    "        # Find the number of cells in each group as a proportion of the total\n",
    "        df[method_name] = round((df[method_name]/total_n_cells) *100,1)\n",
    "\n",
    "       # Add to dataframes\n",
    "        proportions_df= proportions_df.merge(df[['values', method_name]], on = 'values', how = 'outer')\n",
    "\n",
    "        # Order intoi ascending order\n",
    "        proportions_df = proportions_df.sort_values(by='values')\n",
    "        counts_df = counts_df.sort_values(by='values')\n",
    "\n",
    "    # Join the two dataframes together and reformat\n",
    "    both_dfs = pd.DataFrame(columns = [\"Cluster_num\"])  \n",
    "    for num, df in enumerate([counts_df,proportions_df]):\n",
    "        # Some categories might be missing which causes this to throw an error\n",
    "        df['Cluster_num']= ['Hazard_2CatsLower', 'Hazard_1CatsLower', 'Hazard_SameCat', 'Hazard_1CatsHigher', 'Hazard_2CatsHigher', 'Hazard_3CatsHigher']\n",
    "        del df['values']\n",
    "        df = df.set_index('Cluster_num').T\n",
    "        if num == 0:\n",
    "            df = df.add_suffix('_countcells')\n",
    "        else:\n",
    "            df = df.add_suffix('_propcells')\n",
    "        df['Cluster_num'] = df.index\n",
    "        both_dfs = pd.merge(both_dfs, df,  how=\"outer\", on = 'Cluster_num')\n",
    "    \n",
    "    return both_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b165cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard_cat_changes = create_binned_counts_and_props_hazard_cat_change(fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46068d8",
   "metadata": {},
   "source": [
    "### Create a dataframe containing all the info on each of the scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "884a8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results = pd.DataFrame({'Cluster_num': short_ids, \"MaxRainfallIntensity\": maxs,  \n",
    "    \"MaxRainfallIntensityMinute\": min_of_maxs,\n",
    "   'TotalFloodedArea':totals_df['FloodedArea'],'%Diff_FloodedArea_fromSP':percent_diffs_df['percent_diffs'],\n",
    "    '%Diff_FloodedArea_fromSP_formatted':percent_diffs_df['percent_diff_formatted'],\n",
    "    'Abs%Diff_FloodedArea_fromSP':percent_diffs_df['percent_diffs_abs'],'UrbanFloodedArea':totals_df_urban['FloodedArea'],\n",
    "  '%Diff_UrbanFloodedArea_fromSP':percent_diffs_df_urban['percent_diffs'] ,\n",
    "  '%Diff_UrbanFloodedArea_fromSP_formatted':percent_diffs_df_urban['percent_diff_formatted'],\n",
    "    'Abs%Diff_UrbanFloodedArea_fromSP':percent_diffs_df_urban['percent_diffs_abs'], \n",
    "    'WorstCaseDepth_ncells': worst_case_method_depth['counts'].tolist(),\n",
    "    'WorstCaseVelocity_ncells': worst_case_method_velocity['counts'].tolist(), 'colour':colours_df['colour']}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681011fa",
   "metadata": {},
   "source": [
    "### Add the depth/velocity category breakdowns and hazard categories to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d03d47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [velocity_props, depth_props, velocity_props_urban, depth_props_urban, velocity_counts, depth_counts,\n",
    "          velocity_counts_urban, depth_counts_urban,hazard_counts, hazard_props]\n",
    "suffixes = ['_propcells', '_propcells','_propcells_urban','_propcells_urban','_countcells','_countcells','_countcells_urban','_countcells_urban',\n",
    "'_numcells', '_propcells']\n",
    "\n",
    "for num, df in enumerate(dfs):\n",
    "    # Reformat the dataframe\n",
    "    df = df.set_index('index').T\n",
    "    # Add the correct suffix to the column names\n",
    "    df = df.add_suffix(suffixes[num]) \n",
    "    # Add Cluster_num column for joining\n",
    "    df['Cluster_num'] = df.index#\n",
    "    # Join to cluster results dataframe\n",
    "    cluster_results = pd.merge(cluster_results,  df, how=\"outer\", on = 'Cluster_num')\n",
    "    \n",
    "cluster_results = pd.merge(cluster_results, hazard_cat_changes,  how=\"outer\", on = 'Cluster_num')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d6402",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6facf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results.to_csv(\"Data/allclusters_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb09f824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster_num</th>\n",
       "      <th>MaxRainfallIntensity</th>\n",
       "      <th>MaxRainfallIntensityMinute</th>\n",
       "      <th>TotalFloodedArea</th>\n",
       "      <th>%Diff_FloodedArea_fromSP</th>\n",
       "      <th>%Diff_FloodedArea_fromSP_formatted</th>\n",
       "      <th>Abs%Diff_FloodedArea_fromSP</th>\n",
       "      <th>UrbanFloodedArea</th>\n",
       "      <th>%Diff_UrbanFloodedArea_fromSP</th>\n",
       "      <th>%Diff_UrbanFloodedArea_fromSP_formatted</th>\n",
       "      <th>...</th>\n",
       "      <th>Hazard_SameCat_countcells</th>\n",
       "      <th>Hazard_1CatsHigher_countcells</th>\n",
       "      <th>Hazard_2CatsHigher_countcells</th>\n",
       "      <th>Hazard_3CatsHigher_countcells</th>\n",
       "      <th>Hazard_2CatsLower_propcells</th>\n",
       "      <th>Hazard_1CatsLower_propcells</th>\n",
       "      <th>Hazard_SameCat_propcells</th>\n",
       "      <th>Hazard_1CatsHigher_propcells</th>\n",
       "      <th>Hazard_2CatsHigher_propcells</th>\n",
       "      <th>Hazard_3CatsHigher_propcells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6h_feh_sp</td>\n",
       "      <td>0.201255</td>\n",
       "      <td>180</td>\n",
       "      <td>1.701144</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.575595</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6h_sp_fl_0.1</td>\n",
       "      <td>0.232031</td>\n",
       "      <td>36</td>\n",
       "      <td>1.636911</td>\n",
       "      <td>-3.78</td>\n",
       "      <td>-3.78%</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.540120</td>\n",
       "      <td>-6.16</td>\n",
       "      <td>-6.16%</td>\n",
       "      <td>...</td>\n",
       "      <td>1519965.0</td>\n",
       "      <td>61215.0</td>\n",
       "      <td>3774.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6h_sp_fl_0.2</td>\n",
       "      <td>0.243904</td>\n",
       "      <td>72</td>\n",
       "      <td>1.635671</td>\n",
       "      <td>-3.85</td>\n",
       "      <td>-3.85%</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.514048</td>\n",
       "      <td>-10.69</td>\n",
       "      <td>-10.69%</td>\n",
       "      <td>...</td>\n",
       "      <td>1500827.0</td>\n",
       "      <td>58382.0</td>\n",
       "      <td>3824.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>93.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6h_sp_fl_0.3</td>\n",
       "      <td>0.254309</td>\n",
       "      <td>108</td>\n",
       "      <td>1.654627</td>\n",
       "      <td>-2.73</td>\n",
       "      <td>-2.73%</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.523471</td>\n",
       "      <td>-9.06</td>\n",
       "      <td>-9.06%</td>\n",
       "      <td>...</td>\n",
       "      <td>1526429.0</td>\n",
       "      <td>47659.0</td>\n",
       "      <td>2657.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6h_sp_fl_0.4</td>\n",
       "      <td>0.262907</td>\n",
       "      <td>144</td>\n",
       "      <td>1.678387</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-1.34%</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.532838</td>\n",
       "      <td>-7.43</td>\n",
       "      <td>-7.43%</td>\n",
       "      <td>...</td>\n",
       "      <td>1548240.0</td>\n",
       "      <td>37617.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6h_sp_bl_0.6</td>\n",
       "      <td>0.292262</td>\n",
       "      <td>215</td>\n",
       "      <td>1.729529</td>\n",
       "      <td>1.67</td>\n",
       "      <td>+1.67%</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.551026</td>\n",
       "      <td>-4.27</td>\n",
       "      <td>-4.27%</td>\n",
       "      <td>...</td>\n",
       "      <td>1568533.0</td>\n",
       "      <td>24623.0</td>\n",
       "      <td>761.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6h_sp_bl_0.7</td>\n",
       "      <td>0.317888</td>\n",
       "      <td>251</td>\n",
       "      <td>1.746964</td>\n",
       "      <td>2.69</td>\n",
       "      <td>+2.69%</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.559568</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>-2.78%</td>\n",
       "      <td>...</td>\n",
       "      <td>1564776.0</td>\n",
       "      <td>25369.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>93.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6h_sp_bl_0.8</td>\n",
       "      <td>0.343370</td>\n",
       "      <td>287</td>\n",
       "      <td>1.764415</td>\n",
       "      <td>3.72</td>\n",
       "      <td>+3.72%</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.567784</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.36%</td>\n",
       "      <td>...</td>\n",
       "      <td>1549395.0</td>\n",
       "      <td>33993.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>92.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6h_sp_bl_0.9</td>\n",
       "      <td>0.368805</td>\n",
       "      <td>323</td>\n",
       "      <td>1.775070</td>\n",
       "      <td>4.35</td>\n",
       "      <td>+4.35%</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.574021</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.27%</td>\n",
       "      <td>...</td>\n",
       "      <td>1522536.0</td>\n",
       "      <td>53425.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cluster_num  MaxRainfallIntensity  MaxRainfallIntensityMinute  \\\n",
       "0     6h_feh_sp              0.201255                         180   \n",
       "1  6h_sp_fl_0.1              0.232031                          36   \n",
       "2  6h_sp_fl_0.2              0.243904                          72   \n",
       "3  6h_sp_fl_0.3              0.254309                         108   \n",
       "4  6h_sp_fl_0.4              0.262907                         144   \n",
       "5  6h_sp_bl_0.6              0.292262                         215   \n",
       "6  6h_sp_bl_0.7              0.317888                         251   \n",
       "7  6h_sp_bl_0.8              0.343370                         287   \n",
       "8  6h_sp_bl_0.9              0.368805                         323   \n",
       "\n",
       "   TotalFloodedArea  %Diff_FloodedArea_fromSP  \\\n",
       "0          1.701144                      0.00   \n",
       "1          1.636911                     -3.78   \n",
       "2          1.635671                     -3.85   \n",
       "3          1.654627                     -2.73   \n",
       "4          1.678387                     -1.34   \n",
       "5          1.729529                      1.67   \n",
       "6          1.746964                      2.69   \n",
       "7          1.764415                      3.72   \n",
       "8          1.775070                      4.35   \n",
       "\n",
       "  %Diff_FloodedArea_fromSP_formatted  Abs%Diff_FloodedArea_fromSP  \\\n",
       "0                                                            0.00   \n",
       "1                             -3.78%                         3.78   \n",
       "2                             -3.85%                         3.85   \n",
       "3                             -2.73%                         2.73   \n",
       "4                             -1.34%                         1.34   \n",
       "5                             +1.67%                         1.67   \n",
       "6                             +2.69%                         2.69   \n",
       "7                             +3.72%                         3.72   \n",
       "8                             +4.35%                         4.35   \n",
       "\n",
       "   UrbanFloodedArea  %Diff_UrbanFloodedArea_fromSP  \\\n",
       "0          0.575595                           0.00   \n",
       "1          0.540120                          -6.16   \n",
       "2          0.514048                         -10.69   \n",
       "3          0.523471                          -9.06   \n",
       "4          0.532838                          -7.43   \n",
       "5          0.551026                          -4.27   \n",
       "6          0.559568                          -2.78   \n",
       "7          0.567784                          -1.36   \n",
       "8          0.574021                          -0.27   \n",
       "\n",
       "  %Diff_UrbanFloodedArea_fromSP_formatted  ...  Hazard_SameCat_countcells  \\\n",
       "0                                          ...                        NaN   \n",
       "1                                  -6.16%  ...                  1519965.0   \n",
       "2                                 -10.69%  ...                  1500827.0   \n",
       "3                                  -9.06%  ...                  1526429.0   \n",
       "4                                  -7.43%  ...                  1548240.0   \n",
       "5                                  -4.27%  ...                  1568533.0   \n",
       "6                                  -2.78%  ...                  1564776.0   \n",
       "7                                  -1.36%  ...                  1549395.0   \n",
       "8                                  -0.27%  ...                  1522536.0   \n",
       "\n",
       "   Hazard_1CatsHigher_countcells  Hazard_2CatsHigher_countcells  \\\n",
       "0                            NaN                            NaN   \n",
       "1                        61215.0                         3774.0   \n",
       "2                        58382.0                         3824.0   \n",
       "3                        47659.0                         2657.0   \n",
       "4                        37617.0                         1750.0   \n",
       "5                        24623.0                          761.0   \n",
       "6                        25369.0                          503.0   \n",
       "7                        33993.0                          394.0   \n",
       "8                        53425.0                          317.0   \n",
       "\n",
       "  Hazard_3CatsHigher_countcells  Hazard_2CatsLower_propcells  \\\n",
       "0                           NaN                          NaN   \n",
       "1                           3.0                          0.0   \n",
       "2                           5.0                          0.0   \n",
       "3                           3.0                          0.0   \n",
       "4                           3.0                          0.1   \n",
       "5                           3.0                          0.2   \n",
       "6                           3.0                          0.3   \n",
       "7                           2.0                          0.4   \n",
       "8                           2.0                          0.4   \n",
       "\n",
       "   Hazard_1CatsLower_propcells  Hazard_SameCat_propcells  \\\n",
       "0                          NaN                       NaN   \n",
       "1                          1.9                      94.0   \n",
       "2                          2.9                      93.2   \n",
       "3                          3.0                      93.8   \n",
       "4                          3.2                      94.3   \n",
       "5                          4.0                      94.3   \n",
       "6                          4.4                      93.8   \n",
       "7                          5.0                      92.6   \n",
       "8                          5.4                      91.0   \n",
       "\n",
       "   Hazard_1CatsHigher_propcells  Hazard_2CatsHigher_propcells  \\\n",
       "0                           NaN                           NaN   \n",
       "1                           3.8                           0.2   \n",
       "2                           3.6                           0.2   \n",
       "3                           2.9                           0.2   \n",
       "4                           2.3                           0.1   \n",
       "5                           1.5                           0.0   \n",
       "6                           1.5                           0.0   \n",
       "7                           2.0                           0.0   \n",
       "8                           3.2                           0.0   \n",
       "\n",
       "   Hazard_3CatsHigher_propcells  \n",
       "0                           NaN  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "5                           0.0  \n",
       "6                           0.0  \n",
       "7                           0.0  \n",
       "8                           0.0  \n",
       "\n",
       "[9 rows x 66 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cea586",
   "metadata": {},
   "source": [
    "### Delete tiff files (as these aren't used again and take up a lot of space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f688f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in short_ids:\n",
    "    print(method)\n",
    "    if method != '6h_feh_sp':\n",
    "        os.remove(\"../../../../FloodModelling/MeganModel_New/{}/hazard_cat_difference.tif\".format(method)) \n",
    "        os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Depth_difffromsinglepeak_classified.tif\".format(method)) \n",
    "        os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Depth_difffromsinglepeak_posneg.tif\".format(method)) \n",
    "        os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Velocity_difffromsinglepeak_classified.tif\".format(method)) \n",
    "        os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Velocity_difffromsinglepeak_posneg.tif\".format(method)) \n",
    "        \n",
    "    os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Depth_classified.tif\".format(method)) \n",
    "    os.remove(\"../../../../FloodModelling/MeganModel_New/{}/hazard_classified.tif\".format(method)) \n",
    "    os.remove(\"../../../../FloodModelling/MeganModel_New/{}/Velocity_classified.tif\".format(method)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
