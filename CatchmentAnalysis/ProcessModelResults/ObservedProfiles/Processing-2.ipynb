{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f701d789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1491398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from my_functions_new import *\n",
    "from my_plotting_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29431f3",
   "metadata": {},
   "source": [
    "### Get version of landcover array with just 'urban' and 'rural' categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7c8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "landcover, out_meta = prepare_rainfall_scenario_raster(model_directory + \"LandCover_clipped.tif\", True)\n",
    "# Convert the 1 and 6 values to 10 (for urban) and the rest to 11 (for non-urban).  \n",
    "landcover_mod =  np.where(landcover==1, 10, landcover)\n",
    "landcover_mod =  np.where(landcover_mod==6, 10, landcover_mod)\n",
    "# Convert the rest of the classes to 11\n",
    "for i in [1,2,3,4,5,7,8,9]:\n",
    "    landcover_mod =  np.where(landcover_mod==i, 11, landcover_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ab40f",
   "metadata": {},
   "source": [
    "### Define the names of the method (shorter and longer versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "276042a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_ids = ['6h_sp','6h_c1','6h_c2','6h_c3','6h_c4', '6h_c5', '6h_c6','6h_c7',\n",
    "            '6h_c8','6h_c9', '6h_c10', '6h_c11','6h_c12','6h_c13','6h_c14', '6h_c15']   \n",
    "methods = ['6h_single-peak', 'Cluster1', 'Cluster2', 'Cluster3', 'Cluster4', 'Cluster5', 'Cluster6', 'Cluster7', 'Cluster8',\n",
    "           'Cluster9','Cluster10', 'Cluster11',  'Cluster12','Cluster13', 'Cluster14', 'Cluster15']  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792fabc1",
   "metadata": {},
   "source": [
    "### Find maximum intensity for each method and minute in which it occurs (to use in sorting results analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2b24edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = []\n",
    "min_of_maxs = []\n",
    "\n",
    "# Add FEH data\n",
    "feh_precip=pd.read_csv(\"../../CreateSyntheticRainfallEvents/ReFH2_singlepeak/6hr_100yrRP/PostLossRemoval/6h_feh_singlepeak.csv\")\n",
    "maxs.append(feh_precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].max())\n",
    "min_of_maxs.append(feh_precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].idxmax())\n",
    "\n",
    "#Add observed profile data\n",
    "for cluster_num in range(1,16):\n",
    "    precip=pd.read_csv(\"../../CreateSyntheticRainfallEvents/ObservedProfiles/6hr_100yrRP/PostLossRemoval/cluster{}_urban_summer.csv\".format(cluster_num))\n",
    "    maxs.append(precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].max())\n",
    "    min_of_maxs.append(precip[\"Total net rain mm (Observed rainfall - 01/08/2022) - urbanised model\"].idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea22f7",
   "metadata": {},
   "source": [
    "### Create versions of lists of methods, in order based on max intensity and the the timing of the max intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0354d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_ids_by_loading=  pd.DataFrame({\"min\": min_of_maxs, 'cluster_num': short_ids}).sort_values('min')[\"cluster_num\"].tolist()\n",
    "short_ids_by_loading.remove('6h_sp')\n",
    "short_ids_by_loading = ['6h_sp']+short_ids_by_loading\n",
    "\n",
    "short_ids_by_intensity = pd.DataFrame({\"min\": maxs, 'cluster_num': short_ids}).sort_values('min', ascending = False)[\"cluster_num\"].tolist()\n",
    "short_ids_by_intensity.remove('6h_sp')\n",
    "short_ids_by_intensity = ['6h_sp']+short_ids_by_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fba7f1",
   "metadata": {},
   "source": [
    "### Create dataframe of colours for each cluster (based on their loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d90119a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours_df = create_colours_df(short_ids_by_loading, short_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748b25b",
   "metadata": {},
   "source": [
    "### Create list of filepaths, formatted to be used for either depth or velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f847f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = []\n",
    "for method_num, short_id in enumerate(short_ids):\n",
    "    fp = model_directory + \"{}/{} (Max).Resampled.Terrain.tif\".format(short_id, '{}')\n",
    "    fps.append(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa5f30",
   "metadata": {},
   "source": [
    "### Define breaks for categorising velocity and depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3abe3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define breaks to split the depths/velocities on\n",
    "breaks_depths = np.array([0, 0.3, 0.6, 1.2, 100])  \n",
    "labels_depth = ['<=0.3m', '0.3-0.6m', '0.6-1.2m', '>1.2m']\n",
    "breaks_velocity = np.array([0,0.25,0.5,2,100])\n",
    "labels_velocity = [\"<=0.25m/s\", \"0.25-0.5m/s\", \"0.5-2m/s\", \">2m/s\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979ec44",
   "metadata": {},
   "source": [
    "# <u> Flood extent </u>\n",
    "To examine whether the rainfall's temporal distribution influences the total extent of flooding, the number of flooded cells and the total flooded area in km2 (incl. only cells with depth >0.1m) is compared between the profile with a single peak, and the three methods for producing multi-peaked rainfall events. b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130fbb2",
   "metadata": {},
   "source": [
    "### Create dataframes containing the (total/urban) flooded area in each depth/velocity bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2c8c9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>6h_sp</th>\n",
       "      <th>6h_c1</th>\n",
       "      <th>6h_c2</th>\n",
       "      <th>6h_c3</th>\n",
       "      <th>6h_c4</th>\n",
       "      <th>6h_c5</th>\n",
       "      <th>6h_c6</th>\n",
       "      <th>6h_c7</th>\n",
       "      <th>6h_c8</th>\n",
       "      <th>6h_c9</th>\n",
       "      <th>6h_c10</th>\n",
       "      <th>6h_c11</th>\n",
       "      <th>6h_c12</th>\n",
       "      <th>6h_c13</th>\n",
       "      <th>6h_c14</th>\n",
       "      <th>6h_c15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=0.25m/s</td>\n",
       "      <td>1526698</td>\n",
       "      <td>1533290</td>\n",
       "      <td>1507219</td>\n",
       "      <td>1525779</td>\n",
       "      <td>1505505</td>\n",
       "      <td>1574655</td>\n",
       "      <td>1499783</td>\n",
       "      <td>1536365</td>\n",
       "      <td>1445882</td>\n",
       "      <td>1499783</td>\n",
       "      <td>1506071</td>\n",
       "      <td>1506071</td>\n",
       "      <td>1492781</td>\n",
       "      <td>1503696</td>\n",
       "      <td>1529235</td>\n",
       "      <td>1511427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25-0.5m/s</td>\n",
       "      <td>139555</td>\n",
       "      <td>170174</td>\n",
       "      <td>124550</td>\n",
       "      <td>141010</td>\n",
       "      <td>119018</td>\n",
       "      <td>186790</td>\n",
       "      <td>125314</td>\n",
       "      <td>142445</td>\n",
       "      <td>98531</td>\n",
       "      <td>125314</td>\n",
       "      <td>127117</td>\n",
       "      <td>127117</td>\n",
       "      <td>114546</td>\n",
       "      <td>120595</td>\n",
       "      <td>146457</td>\n",
       "      <td>138847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5-2m/s</td>\n",
       "      <td>61698</td>\n",
       "      <td>70859</td>\n",
       "      <td>56334</td>\n",
       "      <td>60852</td>\n",
       "      <td>53369</td>\n",
       "      <td>99572</td>\n",
       "      <td>53863</td>\n",
       "      <td>69831</td>\n",
       "      <td>33615</td>\n",
       "      <td>53863</td>\n",
       "      <td>52339</td>\n",
       "      <td>52339</td>\n",
       "      <td>49080</td>\n",
       "      <td>50075</td>\n",
       "      <td>71381</td>\n",
       "      <td>56300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;2m/s</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index    6h_sp    6h_c1    6h_c2    6h_c3    6h_c4    6h_c5    6h_c6  \\\n",
       "0    <=0.25m/s  1526698  1533290  1507219  1525779  1505505  1574655  1499783   \n",
       "1  0.25-0.5m/s   139555   170174   124550   141010   119018   186790   125314   \n",
       "2     0.5-2m/s    61698    70859    56334    60852    53369    99572    53863   \n",
       "3        >2m/s        1        0        1        0        0        8        1   \n",
       "\n",
       "     6h_c7    6h_c8    6h_c9   6h_c10   6h_c11   6h_c12   6h_c13   6h_c14  \\\n",
       "0  1536365  1445882  1499783  1506071  1506071  1492781  1503696  1529235   \n",
       "1   142445    98531   125314   127117   127117   114546   120595   146457   \n",
       "2    69831    33615    53863    52339    52339    49080    50075    71381   \n",
       "3        1        0        1        0        0        0        0        2   \n",
       "\n",
       "    6h_c15  \n",
       "0  1511427  \n",
       "1   138847  \n",
       "2    56300  \n",
       "3        0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velocity_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9af59db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_counts, velocity_props = create_binned_counts_and_props(fps, 'Velocity', breaks_velocity, labels_velocity, remove_little_values)\n",
    "depth_counts, depth_props = create_binned_counts_and_props(fps, 'Depth', breaks_depths, labels_depth, remove_little_values)\n",
    "\n",
    "velocity_counts_urban, velocity_props_urban = create_binned_counts_and_props_urban(fps, 'Velocity', breaks_velocity, labels_velocity, remove_little_values, landcover_mod)\n",
    "depth_counts_urban, depth_props_urban = create_binned_counts_and_props_urban(fps, 'Depth', breaks_depths, labels_depth, remove_little_values, landcover_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d7ca3a",
   "metadata": {},
   "source": [
    "### Create dataframes containing the (total/urban) flooded area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d51a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_df = create_totals_df(velocity_counts)\n",
    "totals_df_urban = create_totals_df(velocity_counts_urban)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cf9b7",
   "metadata": {},
   "source": [
    "### Create dataframes containing the % diff in the flooded area between single peak and each other method  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd99a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_diffs_df = find_percentage_diff (totals_df, fps) \n",
    "percent_diffs_df_urban = find_percentage_diff (totals_df_urban, fps)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcb2a6",
   "metadata": {},
   "source": [
    "## Find number of cells in which each method leads to the worst flooding (depth/velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f48368b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of flooded cells with the worst flooding for each method\n",
    "worst_case_method_depth = find_worst_case_method(fps, short_ids, 'Depth')\n",
    "worst_case_method_velocity = find_worst_case_method(fps, short_ids,  'Velocity') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d31cf63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove multiple matches and nan\n",
    "worst_case_method_depth = worst_case_method_depth[~worst_case_method_depth['values'].isin(['multiple matches','nan'])]\n",
    "worst_case_method_velocity = worst_case_method_velocity[~worst_case_method_velocity['values'].isin(['multiple matches','nan'])]\n",
    "\n",
    "# # Reorder (and also add in the methods that are missing)\n",
    "worst_case_method_depth = pd.merge(worst_case_method_depth,  pd.DataFrame({'values': short_ids}), how=\"outer\")\n",
    "worst_case_method_depth = worst_case_method_depth.reindex(worst_case_method_depth['values'].map(dict(zip(short_ids, range(len(short_ids))))).sort_values().index)\n",
    "worst_case_method_depth.reset_index(inplace=True,drop=True)\n",
    "\n",
    "worst_case_method_velocity = pd.merge(worst_case_method_velocity,  pd.DataFrame({'values': short_ids}), how=\"outer\")\n",
    "worst_case_method_velocity = worst_case_method_velocity.reindex(worst_case_method_velocity['values'].map(dict(zip(short_ids, range(len(short_ids))))).sort_values().index)\n",
    "worst_case_method_velocity.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=1, ncols=2, figsize = (20,7))\n",
    "# worst_case_method_depth.plot(ax= axs[0], kind ='bar',width=  0.9, rot =45, ylabel = 'Number of cells')      \n",
    "# worst_case_method_velocity.plot(ax= axs[1], kind ='bar',width=  0.9, rot =45, ylabel = 'Number of cells')  ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46068d8",
   "metadata": {},
   "source": [
    "### Create a dataframe containing all the info on each of the scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "884a8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results = pd.DataFrame({'Cluster_num': short_ids, \"MaxRainfallIntensity\": maxs,  \n",
    "    \"MaxRainfallIntensityMinute\": min_of_maxs,\n",
    "   'TotalFloodedArea':totals_df['FloodedArea'],'%Diff_FloodedArea_fromSP':percent_diffs_df['percent_diffs'],\n",
    "    '%Diff_FloodedArea_fromSP_formatted':percent_diffs_df['percent_diff_formatted'],\n",
    "    'Abs%Diff_FloodedArea_fromSP':percent_diffs_df['percent_diffs_abs'],'UrbanFloodedArea':totals_df_urban['FloodedArea'],\n",
    "  '%Diff_UrbanFloodedArea_fromSP':percent_diffs_df_urban['percent_diffs'],\n",
    "  '%Diff_UrbanFloodedArea_fromSP_formatted':percent_diffs_df_urban['percent_diff_formatted'],\n",
    "    'Abs%Diff_UrbanFloodedArea_fromSP':percent_diffs_df_urban['percent_diffs_abs'], \n",
    "    'WorstCaseDepth_ncells': worst_case_method_depth['counts'].tolist(),\n",
    "    'WorstCaseVelocity_ncells': worst_case_method_velocity['counts'].tolist(), 'colour':colours_df['colour']}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d03d47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [velocity_props, depth_props ]:\n",
    "    df = df.set_index('index').T\n",
    "    df = df.add_suffix('_propcells')\n",
    "    df['Cluster_num'] = df.index\n",
    "    cluster_results = pd.merge(cluster_results,  df, how=\"outer\", on = 'Cluster_num')\n",
    "\n",
    "\n",
    "for df in [velocity_props_urban, depth_props_urban ]:\n",
    "    df = df.set_index('index').T\n",
    "    df = df.add_suffix('_propcells_urban')\n",
    "    df['Cluster_num'] = df.index\n",
    "    cluster_results = pd.merge(cluster_results,  df, how=\"outer\", on = 'Cluster_num')    \n",
    "    \n",
    "for df in [velocity_counts, depth_counts]:\n",
    "    df = df.set_index('index').T\n",
    "    df = df.add_suffix('_countcells') \n",
    "    df['Cluster_num'] = df.index\n",
    "    cluster_results = pd.merge(cluster_results,  df, how=\"outer\", on = 'Cluster_num')\n",
    "    \n",
    "for df in [velocity_counts_urban, depth_counts_urban]:\n",
    "    df = df.set_index('index').T\n",
    "    df = df.add_suffix('_countcells_urban') \n",
    "    df['Cluster_num'] = df.index\n",
    "    cluster_results = pd.merge(cluster_results,  df, how=\"outer\", on = 'Cluster_num')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d6402",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f6facf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results.to_csv(\"allclusters_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
