{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92549457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pyproj/crs/crs.py:68: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pyproj/crs/crs.py:68: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pyproj/crs/crs.py:68: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pyproj/crs/crs.py:306: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  projstring = _prepare_from_string(\" \".join((projstring, projkwargs)))\n",
      "/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pyproj/crs/crs.py:68: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pyproj/crs/crs.py:306: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  projstring = _prepare_from_string(\" \".join((projstring, projkwargs)))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import iris\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "from Identify_Events_Functions import *\n",
    "from Prepare_Data_Functions import *\n",
    "\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def filtered_cube (cube, filter_above):\n",
    "    # cube = cube.copy()\n",
    "    cube.data = np.where(cube.data < 0, np.nan, cube.data)\n",
    "    cube.data = np.where(cube.data > filter_above, np.nan, cube.data)\n",
    "    return cube \n",
    "\n",
    "######################################################\n",
    "### Define which rainfall data we are looking for events in\n",
    "######################################################\n",
    "dataset_name = 'filtered_100'\n",
    "dataset_path_pattern = '/nfs/a161/gy17m2a/PhD/datadir/NIMROD/5mins/OriginalFormat_1km/{year}/*'\n",
    "\n",
    "######################################################\n",
    "### Define data for finding the indepedent events at each gauge\n",
    "######################################################\n",
    "yr = 2006\n",
    "\n",
    "# Get Tb0 values at each gauge\n",
    "tbo_vals = pd.read_csv('/nfs/a319/gy17m2a/PhD/datadir/RainGauge/interarrival_thresholds_CDD_noMissing.txt')\n",
    "# Read in a sample cube for finding the location of gauge in grid\n",
    "sample_cube = iris.load(f'/nfs/a161/gy17m2a/PhD/datadir/NIMROD/5mins/OriginalFormat_1km/{yr}/metoffice-c-band-rain-radar_uk_{yr}0602.nc')[0][1,:,:]\n",
    "\n",
    "######################################################\n",
    "### Get all the 5 minute data for one year, into one cube\n",
    "# (if it already exists in a pickle file, then load it from there)\n",
    "######################################################\n",
    "general_filename = dataset_path_pattern.format(year=yr)\n",
    "pickle_file_filepath = f\"/nfs/a319/gy17m2a/PhD/datadir/cache/nimrod_5mins/unfiltered/WholeYear/cube_{yr}.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d4d90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  a.iris {\n",
       "      text-decoration: none !important;\n",
       "  }\n",
       "  table.iris {\n",
       "      white-space: pre;\n",
       "      border: 1px solid;\n",
       "      border-color: #9c9c9c;\n",
       "      font-family: monaco, monospace;\n",
       "  }\n",
       "  th.iris {\n",
       "      background: #303f3f;\n",
       "      color: #e0e0e0;\n",
       "      border-left: 1px solid;\n",
       "      border-color: #9c9c9c;\n",
       "      font-size: 1.05em;\n",
       "      min-width: 50px;\n",
       "      max-width: 125px;\n",
       "  }\n",
       "  tr.iris :first-child {\n",
       "      border-right: 1px solid #9c9c9c !important;\n",
       "  }\n",
       "  td.iris-title {\n",
       "      background: #d5dcdf;\n",
       "      border-top: 1px solid #9c9c9c;\n",
       "      font-weight: bold;\n",
       "  }\n",
       "  .iris-word-cell {\n",
       "      text-align: left !important;\n",
       "      white-space: pre;\n",
       "  }\n",
       "  .iris-subheading-cell {\n",
       "      padding-left: 2em !important;\n",
       "  }\n",
       "  .iris-inclusion-cell {\n",
       "      padding-right: 1em !important;\n",
       "  }\n",
       "  .iris-panel-body {\n",
       "      padding-top: 0px;\n",
       "  }\n",
       "  .iris-panel-title {\n",
       "      padding-left: 3em;\n",
       "  }\n",
       "  .iris-panel-title {\n",
       "      margin-top: 7px;\n",
       "  }\n",
       "</style>\n",
       "<table class=\"iris\" id=\"140327462424912\">\n",
       "    <tr class=\"iris\">\n",
       "<th class=\"iris iris-word-cell\">Rain Rate Composite (mm/hr)</th>\n",
       "<th class=\"iris iris-word-cell\">projection_y_coordinate</th>\n",
       "<th class=\"iris iris-word-cell\">projection_x_coordinate</th>\n",
       "</tr>\n",
       "    <tr class=\"iris\">\n",
       "<td class=\"iris-word-cell iris-subheading-cell\">Shape</td>\n",
       "<td class=\"iris iris-inclusion-cell\">2175</td>\n",
       "<td class=\"iris iris-inclusion-cell\">1725</td>\n",
       "</tr>\n",
       "    <tr class=\"iris\">\n",
       "    <td class=\"iris-title iris-word-cell\">Dimension coordinates</td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tprojection_y_coordinate</td>\n",
       "    <td class=\"iris-inclusion-cell\">x</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tprojection_x_coordinate</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">x</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-title iris-word-cell\">Scalar coordinates</td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"><br>forecast_period             0 second</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tforecast_reference_time     2006-06-02 00</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"2\">5:00</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\ttime                        2006-06-02 00</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"2\">5:00</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-title iris-word-cell\">Attributes</td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"><br>Conventions                 CF-1.7<br>field_code                  213<br>institution                 Met Office<br>nimrod_version              2<br>probability_period_of_event 0<br>source                      1km Single Site Radars<br>title                       Unknown</td>\n",
       "</tr>\n",
       "</table>\n",
       "        "
      ],
      "text/plain": [
       "<iris 'Cube' of Rain rate Composite / (mm/hr) (projection_y_coordinate: 2175; projection_x_coordinate: 1725)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c79d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file exists, so loading that\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(pickle_file_filepath):\n",
    "    print(\"Pickle file exists, so loading that\")\n",
    "    full_year_cube = load_cube_from_picklefile(pickle_file_filepath)\n",
    "else:\n",
    "    print(\"Pickle file doesnt exist, so creating and then saving that\")\n",
    "    \n",
    "    ### Get the data filepaths\n",
    "    print(f\"Loading data for year {yr}\")\n",
    "    \n",
    "    # Create cube list\n",
    "    cubes = load_files_to_cubelist(yr, general_filename)\n",
    "    \n",
    "    # Clean cubes of things which are problematic for concatenation\n",
    "    cubes = clean_cubes(cubes)\n",
    "    \n",
    "    # Join them into one (with error handling to deal with times which are wrong)\n",
    "    try:\n",
    "        full_year_cube = cubes.concatenate_cube()\n",
    "        print(\"Concatenation successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Initial concatenation failed: {str(e)}\")\n",
    "\n",
    "        # If initial concatenation fails, remove problematic cubes and try again\n",
    "        try:\n",
    "            full_year_cube = remove_problematic_cubes(cubes)\n",
    "            print(\"Concatenation successful after removing problematic cubes!\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Concatenation failed after removing problematic cubes: {str(e)}\")               \n",
    "    save_cube_as_pickle_file(full_year_cube, pickle_file_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a10f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825, 891)\n",
      "Time to load data is 0.3 seconds\n"
     ]
    }
   ],
   "source": [
    "gauge_num=1\n",
    "# Find the Tb0 and index of this gauge\n",
    "Tb0, idx_2d = find_gauge_Tb0_and_location_in_grid(tbo_vals, gauge_num, sample_cube)\n",
    "\n",
    "# Extract data for the specified indices\n",
    "start= time.time()\n",
    "one_location_cube = full_year_cube[1:10, idx_2d[0], idx_2d[1]]\n",
    "data = one_location_cube.data\n",
    "end=time.time()\n",
    "print(f\"Time to load data is {round(end-start,2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4110827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reloading data\n",
      "max value is 0.0625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>precipitation (mm/hr)</th>\n",
       "      <th>precipitation (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01 00:05:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-01 00:10:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-01 00:15:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-01 00:20:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-01 00:25:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006-01-01 00:30:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006-01-01 00:35:00</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2006-01-01 00:40:00</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2006-01-01 00:45:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                times  precipitation (mm/hr)  precipitation (mm)\n",
       "0 2006-01-01 00:05:00                  0.000               0.000\n",
       "1 2006-01-01 00:10:00                  0.000               0.000\n",
       "2 2006-01-01 00:15:00                  0.000               0.000\n",
       "3 2006-01-01 00:20:00                  0.000               0.000\n",
       "4 2006-01-01 00:25:00                  0.000               0.000\n",
       "5 2006-01-01 00:30:00                  0.000               0.000\n",
       "6 2006-01-01 00:35:00                  0.062               0.031\n",
       "7 2006-01-01 00:40:00                  0.062               0.031\n",
       "8 2006-01-01 00:45:00                  0.000               0.000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtering_key =100\n",
    "# Create cube with filterings applied\n",
    "cube = filtered_cube(one_location_cube,  filter_above=filtering_key)\n",
    "print(\"reloading data\")\n",
    "data = cube.data\n",
    "print(f\"max value is {np.nanmax(cube.data)}\")\n",
    "# Convert to dataframe\n",
    "df = create_df_with_gaps_filled_in(cube, data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236cbbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Find events at each gauge\n",
    "######################################################\n",
    "failed_gauges = []\n",
    "gauge_nums = range(0,1263)\n",
    "# Function to process each gauge\n",
    "for gauge_num in gauge_nums:\n",
    "    if not gauge_num in [423, 444, 827, 888]:\n",
    "            print(f\"gauge num is {gauge_num}\")\n",
    "            \n",
    "            ######################################################\n",
    "            ## Check if any files are missing, across the 3 filtering options\n",
    "            # If there are: code will continue to run\n",
    "            # If not: code will move to next gauge\n",
    "            ######################################################\n",
    "            for dataset_name in ['unfiltered', 'filtered_100', 'filtered_300']:\n",
    "                # Create a flag to record whether we are missing any of the files we need\n",
    "                missing_files = False\n",
    "                # Define directory filepath which will store results\n",
    "                base_dir = f\"/nfs/a161/gy17m2a/PhD/ProcessedData/IndependentEvents/NIMROD_5mins/NIMROD_1km_{dataset_name}/{gauge_num}/WholeYear\"\n",
    "                # Create the directory if it doesnt exist\n",
    "                if not os.path.isdir(base_dir):\n",
    "                    os.makedirs(base_dir)\n",
    "                # Check if we are missing any of the files, and if so, change the flag to True\n",
    "                if not any(os.path.exists(f\"{base_dir}/{duration}hrs_{yr}_v2_part0.csv\") for duration in [0.5, 1, 2, 3, 6, 12, 24]):\n",
    "                    missing_files = True\n",
    "                \n",
    "            # If we are missing some files then get the data for the grid cell, \n",
    "            if missing_files:\n",
    "                # Find the Tb0 and index of this gauge\n",
    "                Tb0, idx_2d = find_gauge_Tb0_and_location_in_grid(tbo_vals, gauge_num, sample_cube)\n",
    "\n",
    "                # Extract data for the specified indices\n",
    "                start= time.time()\n",
    "                one_location_cube = full_year_cube[:, idx_2d[0], idx_2d[1]]\n",
    "                data = one_location_cube.data\n",
    "                end=time.time()\n",
    "                print(f\"Time to load data is {round(end-start,2)} seconds\")\n",
    "\n",
    "                ##### Filter cube according to different options\n",
    "                # Find events with filtered cubes\n",
    "                filtering_dict = {1000000:'unfiltered', 300:'filtered_300',100:'filtered_100'}\n",
    "                for filtering_key, dataset_name in filtering_dict.items():\n",
    "                    print(f\"running for {dataset_name}\")\n",
    "                    # Create cube with filterings applied\n",
    "                    cube = filtered_cube(one_location_cube,  filter_above=filtering_key)\n",
    "                    print(\"reloading data\")\n",
    "                    data = cube.data\n",
    "                    print(f\"max value is {np.nanmax(cube.data)}\")\n",
    "                    # Convert to dataframe\n",
    "                    df = create_df_with_gaps_filled_in(cube, data)\n",
    "                    # Search dataframe for events corresponding to durations\n",
    "                    for duration in [0.5, 1, 2, 3, 6, 12, 24]:\n",
    "                        base_dir = f\"/nfs/a161/gy17m2a/PhD/ProcessedData/IndependentEvents/NIMROD_5mins/NIMROD_1km_{dataset_name}/{gauge_num}/WholeYear\"\n",
    "\n",
    "                        filename =  f\"{base_dir}/{duration}hrs_{yr}_v2_part0.csv\"\n",
    "                        if not os.path.exists(filename):\n",
    "                            print(f\"Finding the AMAX for {duration}hr events for gauge {gauge_num} in year {yr} for {dataset_name}\")\n",
    "                            # Find events\n",
    "                            events_v2 = search_for_valid_events(df, duration=duration, Tb0=Tb0)\n",
    "\n",
    "                            # Save events to CSV\n",
    "                            for num, event in enumerate(events_v2):\n",
    "                                if len(event) > 1:\n",
    "                                        event.to_csv(f\"{base_dir}/{duration}hrs_{yr}_v2_part{num}.csv\")\n",
    "                                        if event['precipitation (mm/hr)'].isna().any():\n",
    "                                            print(\"NANs in this event\")\n",
    "                        else:\n",
    "                            print(f\"already exists{filename}\")\n",
    "                            pass   \n",
    "\n",
    "print(f\"failed gauges are: {failed_gauges}\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686c6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
