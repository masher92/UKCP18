{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8670b863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file exists, so loading that\n",
      "2015\n",
      "gauge num is 300\n",
      "gauge num is 301\n",
      "gauge num is 302\n",
      "gauge num is 303\n",
      "gauge num is 304\n",
      "gauge num is 305\n",
      "gauge num is 306\n",
      "gauge num is 307\n",
      "gauge num is 308\n",
      "gauge num is 309\n",
      "gauge num is 310\n",
      "gauge num is 311\n",
      "gauge num is 312\n",
      "gauge num is 313\n",
      "gauge num is 314\n",
      "gauge num is 315\n",
      "gauge num is 316\n",
      "gauge num is 317\n",
      "gauge num is 318\n",
      "gauge num is 319\n",
      "failed gauges are: []\n",
      "2016\n",
      "gauge num is 300\n",
      "gauge num is 301\n",
      "gauge num is 302\n",
      "gauge num is 303\n",
      "gauge num is 304\n",
      "gauge num is 305\n",
      "gauge num is 306\n",
      "gauge num is 307\n",
      "gauge num is 308\n",
      "gauge num is 309\n",
      "gauge num is 310\n",
      "gauge num is 311\n",
      "gauge num is 312\n",
      "gauge num is 313\n",
      "gauge num is 314\n",
      "gauge num is 315\n",
      "gauge num is 316\n",
      "gauge num is 317\n",
      "gauge num is 318\n",
      "gauge num is 319\n",
      "failed gauges are: []\n",
      "2017\n",
      "gauge num is 300\n",
      "gauge num is 301\n",
      "gauge num is 302\n",
      "gauge num is 303\n",
      "gauge num is 304\n",
      "gauge num is 305\n",
      "gauge num is 306\n",
      "gauge num is 307\n",
      "gauge num is 308\n",
      "gauge num is 309\n",
      "gauge num is 310\n",
      "gauge num is 311\n",
      "gauge num is 312\n",
      "gauge num is 313\n",
      "gauge num is 314\n",
      "gauge num is 315\n",
      "(798, 851)\n",
      "Time to load data is 434.3 seconds\n",
      "running for unfiltered\n",
      "reloading data\n",
      "max value is 58.0625\n",
      "Finding the AMAX for 0.5hr events for gauge 315 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 1hr events for gauge 315 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 2hr events for gauge 315 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 3hr events for gauge 315 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 6hr events for gauge 315 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 8.78125\n",
      "Finding the AMAX for 12hr events for gauge 315 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 15.716146469116211\n",
      "Finding the AMAX for 24hr events for gauge 315 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 15.716146469116211\n",
      "running for filtered_300\n",
      "reloading data\n",
      "max value is 58.0625\n",
      "Finding the AMAX for 0.5hr events for gauge 315 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 1hr events for gauge 315 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 2hr events for gauge 315 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 3hr events for gauge 315 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 6hr events for gauge 315 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 8.78125\n",
      "Finding the AMAX for 12hr events for gauge 315 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 15.716146469116211\n",
      "Finding the AMAX for 24hr events for gauge 315 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 15.716146469116211\n",
      "running for filtered_100\n",
      "reloading data\n",
      "max value is 58.0625\n",
      "Finding the AMAX for 0.5hr events for gauge 315 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 1hr events for gauge 315 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 2hr events for gauge 315 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 3hr events for gauge 315 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 8.6796875\n",
      "Finding the AMAX for 6hr events for gauge 315 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 8.78125\n",
      "Finding the AMAX for 12hr events for gauge 315 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 15.716146469116211\n",
      "Finding the AMAX for 24hr events for gauge 315 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 15.716146469116211\n",
      "gauge num is 316\n",
      "(785, 858)\n",
      "Time to load data is 534.62 seconds\n",
      "running for unfiltered\n",
      "reloading data\n",
      "max value is 60.28125\n",
      "Finding the AMAX for 0.5hr events for gauge 316 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 1hr events for gauge 316 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 2hr events for gauge 316 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 3hr events for gauge 316 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 6hr events for gauge 316 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 11.091145515441895\n",
      "Finding the AMAX for 12hr events for gauge 316 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 24hr events for gauge 316 in year 2017 for unfiltered\n",
      "Event contains NAN, total event precip is 20.79166603088379\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "running for filtered_300\n",
      "reloading data\n",
      "max value is 60.28125\n",
      "Finding the AMAX for 0.5hr events for gauge 316 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 1hr events for gauge 316 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 2hr events for gauge 316 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 3hr events for gauge 316 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 6hr events for gauge 316 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 11.091145515441895\n",
      "Finding the AMAX for 12hr events for gauge 316 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 24hr events for gauge 316 in year 2017 for filtered_300\n",
      "Event contains NAN, total event precip is 20.79166603088379\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "running for filtered_100\n",
      "reloading data\n",
      "max value is 60.28125\n",
      "Finding the AMAX for 0.5hr events for gauge 316 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 1hr events for gauge 316 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 2hr events for gauge 316 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 3hr events for gauge 316 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 6hr events for gauge 316 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 11.091145515441895\n",
      "Finding the AMAX for 12hr events for gauge 316 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "Finding the AMAX for 24hr events for gauge 316 in year 2017 for filtered_100\n",
      "Event contains NAN, total event precip is 20.79166603088379\n",
      "Event doesnt contain NAN, total event precip is 17.505207061767578\n",
      "gauge num is 317\n",
      "(780, 872)\n",
      "Time to load data is 555.95 seconds\n",
      "running for unfiltered\n",
      "reloading data\n",
      "max value is 50.0\n",
      "Finding the AMAX for 0.5hr events for gauge 317 in year 2017 for unfiltered\n",
      "Event contains NAN, total event precip is 27.591144561767578\n",
      "Event doesnt contain NAN, total event precip is 15.955730438232422\n",
      "Finding the AMAX for 1hr events for gauge 317 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 15.955730438232422\n",
      "Finding the AMAX for 2hr events for gauge 317 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 16.460939407348633\n",
      "Finding the AMAX for 3hr events for gauge 317 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 15.955730438232422\n",
      "Finding the AMAX for 6hr events for gauge 317 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 22.127605438232422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the AMAX for 12hr events for gauge 317 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 22.127605438232422\n",
      "Finding the AMAX for 24hr events for gauge 317 in year 2017 for unfiltered\n",
      "Event doesnt contain NAN, total event precip is 22.127605438232422\n",
      "running for filtered_300\n",
      "reloading data\n",
      "max value is 50.0\n",
      "Finding the AMAX for 0.5hr events for gauge 317 in year 2017 for filtered_300\n",
      "Event contains NAN, total event precip is 27.591144561767578\n",
      "Event doesnt contain NAN, total event precip is 15.955730438232422\n",
      "Finding the AMAX for 1hr events for gauge 317 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 15.955730438232422\n",
      "Finding the AMAX for 2hr events for gauge 317 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 16.460939407348633\n",
      "Finding the AMAX for 3hr events for gauge 317 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 15.955730438232422\n",
      "Finding the AMAX for 6hr events for gauge 317 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 22.127605438232422\n",
      "Finding the AMAX for 12hr events for gauge 317 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 22.127605438232422\n",
      "Finding the AMAX for 24hr events for gauge 317 in year 2017 for filtered_300\n",
      "Event doesnt contain NAN, total event precip is 22.127605438232422\n",
      "running for filtered_100\n",
      "reloading data\n",
      "max value is 50.0\n",
      "Finding the AMAX for 0.5hr events for gauge 317 in year 2017 for filtered_100\n",
      "Event contains NAN, total event precip is 27.591144561767578\n",
      "Event doesnt contain NAN, total event precip is 15.955730438232422\n",
      "Finding the AMAX for 1hr events for gauge 317 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 15.955730438232422\n",
      "Finding the AMAX for 2hr events for gauge 317 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 16.460939407348633\n",
      "Finding the AMAX for 3hr events for gauge 317 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 15.955730438232422\n",
      "Finding the AMAX for 6hr events for gauge 317 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 22.127605438232422\n",
      "Finding the AMAX for 12hr events for gauge 317 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 22.127605438232422\n",
      "Finding the AMAX for 24hr events for gauge 317 in year 2017 for filtered_100\n",
      "Event doesnt contain NAN, total event precip is 22.127605438232422\n",
      "gauge num is 318\n",
      "(784, 891)\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: b'/nfs/a161/gy17m2a/PhD/datadir/NIMROD/5mins/OriginalFormat_1km/2006/metoffice-c-band-rain-radar_uk_20060602.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85090/630133747.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmissing_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0;31m# Find the Tb0 and index of this gauge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mTb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_gauge_Tb0_and_location_in_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtbo_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgauge_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_cube\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0;31m# Extract data for the specified indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a319/gy17m2a/PhD/Scripts/FindIndependentRainfallEvents/FindingEvents/Identify_Events_Functions.py\u001b[0m in \u001b[0;36mfind_gauge_Tb0_and_location_in_grid\u001b[0;34m(tbo_vals, gauge_num, sample_cube)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mgauge1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtbo_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgauge_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mTb0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauge1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Critical_interarrival_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mclosest_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_position_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_cube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgauge1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgauge1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_radius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a319/gy17m2a/PhD/Scripts/FindIndependentRainfallEvents/FindingEvents/Identify_Events_Functions.py\u001b[0m in \u001b[0;36mfind_position_obs\u001b[0;34m(concat_cube, rain_gauge_lat, rain_gauge_lon, plot_radius, plot)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;31m# Check if the selected index is masked and find a nearby valid index if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_masked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_cube\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yep its masked\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/cube.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2168\u001b[0m         \"\"\"\n\u001b[0;32m-> 2169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/_data_manager.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;31m# Realise the lazy data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_concrete_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0;31m# Assign the realised result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_real_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/_lazy_data.py\u001b[0m in \u001b[0;36mas_concrete_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_lazy_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_co_realise_lazy_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/_lazy_data.py\u001b[0m in \u001b[0;36m_co_realise_lazy_arrays\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \"\"\"\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mcomputed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlazy_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_out\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputed_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/dask/threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mget_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mpack_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpack_exception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                             \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Re-execute locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                             \u001b[0mraise_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m                     \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cache\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/dask/local.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/dask/core.py\u001b[0m in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# temporaries by their reference count and can execute certain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# operations in-place.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mishashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(a, b, asarray, lock)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;31m# Below we special-case `np.matrix` to force a conversion to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# `np.ndarray` and preserve original Dask behavior for `getter`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/iris/fileformats/netcdf.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: b'/nfs/a161/gy17m2a/PhD/datadir/NIMROD/5mins/OriginalFormat_1km/2006/metoffice-c-band-rain-radar_uk_20060602.nc'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import iris\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "from Identify_Events_Functions import *\n",
    "from Prepare_Data_Functions import *\n",
    "\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*'+init=<authority>:<code>' syntax is deprecated.*\")\n",
    "\n",
    "######################################################\n",
    "### Define which rainfall data we are looking for events in\n",
    "######################################################\n",
    "dataset_name = 'filtered_100'\n",
    "dataset_path_pattern = '/nfs/a161/gy17m2a/PhD/datadir/NIMROD/5mins/OriginalFormat_1km/{year}/*'\n",
    "\n",
    "######################################################\n",
    "### Define data for finding the indepedent events at each gauge\n",
    "######################################################\n",
    "\n",
    "# Get Tb0 values at each gauge\n",
    "tbo_vals = pd.read_csv('/nfs/a319/gy17m2a/PhD/datadir/RainGauge/interarrival_thresholds_CDD_noMissing.txt')\n",
    "# Read in a sample cube for finding the location of gauge in grid\n",
    "yr=2006\n",
    "sample_cube = iris.load(f'/nfs/a161/gy17m2a/PhD/datadir/NIMROD/5mins/OriginalFormat_1km/{yr}/metoffice-c-band-rain-radar_uk_{yr}0602.nc')[0][1,:,:]\n",
    "\n",
    "######################################################\n",
    "### Get all the 5 minute data for one year, into one cube\n",
    "# (if it already exists in a pickle file, then load it from there)\n",
    "######################################################\n",
    "general_filename = dataset_path_pattern.format(year=yr)\n",
    "pickle_file_filepath = f\"/nfs/a319/gy17m2a/PhD/datadir/cache/nimrod_5mins/unfiltered/WholeYear/cube_{yr}.pkl\"\n",
    "\n",
    "if os.path.exists(pickle_file_filepath):\n",
    "    print(\"Pickle file exists, so loading that\")\n",
    "    full_year_cube = load_cube_from_picklefile(pickle_file_filepath)\n",
    "else:\n",
    "    print(\"Pickle file doesnt exist, so creating and then saving that\")\n",
    "    \n",
    "    ### Get the data filepaths\n",
    "    print(f\"Loading data for year {yr}\")\n",
    "    \n",
    "    # Create cube list\n",
    "    cubes = load_files_to_cubelist(yr, general_filename)\n",
    "    \n",
    "    # Clean cubes of things which are problematic for concatenation\n",
    "    cubes = clean_cubes(cubes)\n",
    "    \n",
    "    # Join them into one (with error handling to deal with times which are wrong)\n",
    "    try:\n",
    "        full_year_cube = cubes.concatenate_cube()\n",
    "        print(\"Concatenation successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Initial concatenation failed: {str(e)}\")\n",
    "\n",
    "        # If initial concatenation fails, remove problematic cubes and try again\n",
    "        try:\n",
    "            full_year_cube = remove_problematic_cubes(cubes)\n",
    "            print(\"Concatenation successful after removing problematic cubes!\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Concatenation failed after removing problematic cubes: {str(e)}\")               \n",
    "    save_cube_as_pickle_file(full_year_cube, pickle_file_filepath)\n",
    "\n",
    "######################################################\n",
    "# Find events at each gauge\n",
    "######################################################\n",
    "failed_gauges = []\n",
    "for yr in range(2015,2020):\n",
    "    print(yr)\n",
    "    gauge_nums = range(300,320)\n",
    "    # Function to process each gauge\n",
    "    for gauge_num in gauge_nums:\n",
    "        if not gauge_num in [423, 444, 827, 888]:\n",
    "                print(f\"gauge num is {gauge_num}\")\n",
    "\n",
    "                ######################################################\n",
    "                ## Check if any files are missing, across the 3 filtering options\n",
    "                # If there are: code will continue to run\n",
    "                # If not: code will move to next gauge\n",
    "                ######################################################\n",
    "                for dataset_name in ['unfiltered', 'filtered_100', 'filtered_300']:\n",
    "                    # Create a flag to record whether we are missing any of the files we need\n",
    "                    missing_files = False\n",
    "                    # Define directory filepath which will store results\n",
    "                    base_dir = f\"/nfs/a161/gy17m2a/PhD/ProcessedData/IndependentEvents/NIMROD_5mins/NIMROD_1km_{dataset_name}/{gauge_num}/WholeYear\"\n",
    "                    # Create the directory if it doesnt exist\n",
    "                    if not os.path.isdir(base_dir):\n",
    "                        os.makedirs(base_dir)\n",
    "                    # Check if we are missing any of the files, and if so, change the flag to True\n",
    "                    if not any(os.path.exists(f\"{base_dir}/{duration}hrs_{yr}_v2_part0.csv\") for duration in [0.5, 1, 2, 3, 6, 12, 24]):\n",
    "                        missing_files = True\n",
    "\n",
    "                # If we are missing some files then get the data for the grid cell, \n",
    "                if missing_files:\n",
    "                    # Find the Tb0 and index of this gauge\n",
    "                    Tb0, idx_2d = find_gauge_Tb0_and_location_in_grid(tbo_vals, gauge_num, sample_cube)\n",
    "\n",
    "                    # Extract data for the specified indices\n",
    "                    start= time.time()\n",
    "                    one_location_cube = full_year_cube[:, idx_2d[0], idx_2d[1]]\n",
    "                    data = one_location_cube.data\n",
    "                    end=time.time()\n",
    "                    print(f\"Time to load data is {round(end-start,2)} seconds\")\n",
    "\n",
    "                    ##### Filter cube according to different options\n",
    "                    # Find events with filtered cubes\n",
    "                    filtering_dict = {1000000:'unfiltered', 300:'filtered_300',100:'filtered_100'}\n",
    "                    for filtering_key, dataset_name in filtering_dict.items():\n",
    "                        print(f\"running for {dataset_name}\")\n",
    "                        # Create cube with filterings applied\n",
    "                        cube = filtered_cube(one_location_cube,  filter_above=filtering_key)\n",
    "                        print(\"reloading data\")\n",
    "                        data = cube.data\n",
    "                        print(f\"max value is {np.nanmax(cube.data)}\")\n",
    "                        # Convert to dataframe\n",
    "                        df = create_df_with_gaps_filled_in(cube, data, time_resolution = 5)\n",
    "                        # Search dataframe for events corresponding to durations\n",
    "                        for duration in [0.5, 1, 2, 3, 6, 12, 24]:\n",
    "                            base_dir = f\"/nfs/a161/gy17m2a/PhD/ProcessedData/IndependentEvents/NIMROD_5mins/NIMROD_1km_{dataset_name}/{gauge_num}/WholeYear\"\n",
    "\n",
    "                            filename =  f\"{base_dir}/{duration}hrs_{yr}_v2_part0.csv\"\n",
    "                            if not os.path.exists(filename):\n",
    "                                print(f\"Finding the AMAX for {duration}hr events for gauge {gauge_num} in year {yr} for {dataset_name}\")\n",
    "                                # Find events\n",
    "                                events_v2 = search_for_valid_events(df, duration=duration, Tb0=Tb0)\n",
    "\n",
    "                                # Save events to CSV\n",
    "                                for num, event in enumerate(events_v2):\n",
    "                                    if len(event) > 1:\n",
    "                                            event.to_csv(f\"{base_dir}/{duration}hrs_{yr}_v2_part{num}.csv\")\n",
    "                                            if event['precipitation (mm/hr)'].isna().any():\n",
    "                                                print(\"NANs in this event\")\n",
    "                            else:\n",
    "                                print(f\"already exists{filename}\")\n",
    "                                pass   \n",
    "\n",
    "    print(f\"failed gauges are: {failed_gauges}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef5687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
