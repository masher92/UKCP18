{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a034e669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbfeaa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from ProcessEventsFunctions import *\n",
    "# from Convert_to_Profiles_Functions import *\n",
    "# from Get_Events_Functions import *\n",
    "\n",
    "sys.path.insert(1, 'Old')\n",
    "from Steef_Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161cbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/nfs/a319/gy17m2a/PhD/'\n",
    "home_dir2 = '/nfs/a161/gy17m2a/PhD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "412d55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "quintile_mapping = {1: 'F2', 2: 'F1', 3: 'C', 4: 'B1', 5: 'B2'}\n",
    "quintile_mapping_thirds = {1: 'F', 2: 'C', 3: 'B'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285aba0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ME', 'SE', 'NE', 'NW', 'SW', ''], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbo_vals = pd.read_csv(home_dir + 'datadir/RainGauge/interarrival_thresholds_CDD_noMissing.txt')\n",
    "# tbo_vals = tbo_vals[tbo_vals['Lon']!=-999.0]\n",
    "# Check if the points are within the areas\n",
    "tbo_vals = check_for_gauge_in_areas(tbo_vals, home_dir, ['NW', 'NE', 'ME', 'SE', 'SW'])\n",
    "tbo_vals.loc[tbo_vals['within_area'] == 'NW, C', 'within_area'] = 'NW'\n",
    "tbo_vals.loc[tbo_vals['within_area'] == 'ME, SE', 'within_area'] = 'ME'\n",
    "tbo_vals['within_area'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7004fdf9",
   "metadata": {},
   "source": [
    "### Get events (considering one set of AMAX producing events (with duplicates deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c4db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_14256/3539429331.py\", line 2, in <module>\n",
      "    events_dict_nimrod, event_props_dict_nimrod, event_profiles_dict_nimrod = process_events_alltogether_nimrod(home_dir2, tbo_vals)\n",
      "  File \"/nfs/a319/gy17m2a/PhD/Scripts/FindIndependentRainfallEvents/ProcessEvents/ProcessEventsFunctions.py\", line 257, in process_events_alltogether_nimrod\n",
      "    this_event = read_event(gauge_num, fp)\n",
      "  File \"/nfs/a319/gy17m2a/PhD/Scripts/FindIndependentRainfallEvents/ProcessEvents/ProcessEventsFunctions.py\", line 74, in read_event\n",
      "    test = pd.read_csv(fp)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/readers.py\", line 488, in _read\n",
      "    return parser.read(nrows)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/readers.py\", line 1047, in read\n",
      "    index, columns, col_dict = self._engine.read(nrows)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 223, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 801, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"pandas/_libs/parsers.pyx\", line 857, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 843, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 1925, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ParserError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_14256/3539429331.py\", line 2, in <module>\n",
      "    events_dict_nimrod, event_props_dict_nimrod, event_profiles_dict_nimrod = process_events_alltogether_nimrod(home_dir2, tbo_vals)\n",
      "  File \"/nfs/a319/gy17m2a/PhD/Scripts/FindIndependentRainfallEvents/ProcessEvents/ProcessEventsFunctions.py\", line 257, in process_events_alltogether_nimrod\n",
      "    this_event = read_event(gauge_num, fp)\n",
      "  File \"/nfs/a319/gy17m2a/PhD/Scripts/FindIndependentRainfallEvents/ProcessEvents/ProcessEventsFunctions.py\", line 74, in read_event\n",
      "    test = pd.read_csv(fp)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/readers.py\", line 488, in _read\n",
      "    return parser.read(nrows)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/readers.py\", line 1047, in read\n",
      "    index, columns, col_dict = self._engine.read(nrows)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 223, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 801, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"pandas/_libs/parsers.pyx\", line 857, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 843, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 1925, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ParserError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_14256/3539429331.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now you can callevents_dict_present_nimrod, event_props_dict_present_nimrod, event_profiles_dict_present_nimrod = process_events_alltogether_nimrod(home_dir2, 'Present', tbo_vals)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevents_dict_nimrod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_props_dict_nimrod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_profiles_dict_nimrod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_events_alltogether_nimrod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_dir2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtbo_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/nfs/a319/gy17m2a/PhD/Scripts/FindIndependentRainfallEvents/ProcessEvents/ProcessEventsFunctions.py\u001b[0m in \u001b[0;36mprocess_events_alltogether_nimrod\u001b[0;34m(home_dir, tb0_vals)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;31m# Get event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                 \u001b[0mthis_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauge_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a319/gy17m2a/PhD/Scripts/FindIndependentRainfallEvents/ProcessEvents/ProcessEventsFunctions.py\u001b[0m in \u001b[0;36mread_event\u001b[0;34m(gauge_num, fp)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauge_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'times'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2076\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ParserError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3376\u001b[0m                         \u001b[0masy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3377\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3378\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2080\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2076\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple)\u001b[0m\n\u001b[1;32m   3184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3185\u001b[0m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0;32m-> 3186\u001b[0;31m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[0m\u001b[1;32m   3187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3188\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_succeeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3394\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3395\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3396\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2080\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0;32m-> 1143\u001b[0;31m                                                                      chained_exceptions_tb_offset)\n\u001b[0m\u001b[1;32m   1144\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/a321/gy17m2a/anaconda_install/anaconda3/envs/ukcp18/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Now you can callevents_dict_present_nimrod, event_props_dict_present_nimrod, event_profiles_dict_present_nimrod = process_events_alltogether_nimrod(home_dir2, 'Present', tbo_vals)\n",
    "events_dict_nimrod, event_props_dict_nimrod, event_profiles_dict_nimrod = process_events_alltogether_nimrod(home_dir2, tbo_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c0c5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(home_dir + f\"ProcessedData/AMAX_Events/NIMROD_30mins/events_dict_nimrod.pickle\", 'wb') as handle:\n",
    "#     pickle.dump(events_dict_nimrod, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open(home_dir + f\"ProcessedData/AMAX_Events/NIMROD_30mins/event_profiles_dict_nimrod\", 'wb') as handle:\n",
    "#     pickle.dump(event_profiles_dict_nimrod, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# with open(home_dir + f\"ProcessedData/AMAX_Events/NIMROD_30mins/event_props_dict_nimrod.pickle\", 'wb') as handle:\n",
    "#     pickle.dump(event_props_dict_nimrod, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c89f0",
   "metadata": {},
   "source": [
    "## Get events for each duration (there'll be cross over in events present for each duration)\n",
    "By duration here we mean the duration for which the AMAX are associated, rather than the actual duration of the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e63c1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007\n"
     ]
    }
   ],
   "source": [
    "home_dir = home_dir2\n",
    "tb0_vals = tbo_vals\n",
    "\n",
    "events_dict = {duration: {} for duration in valid_durations}\n",
    "event_props_dict = {duration: {} for duration in valid_durations}\n",
    "event_profiles_dict = {duration: {} for duration in valid_durations}\n",
    "\n",
    "for gauge_num in range(1007, 1008):\n",
    "    if gauge_num not in [444, 827, 888]:\n",
    "        print(gauge_num)\n",
    "        if gauge_num % 100 == 0:\n",
    "            print(f\"Processing gauge {gauge_num}\")\n",
    "\n",
    "            indy_events_fp = home_dir + f\"ProcessedData/IndependentEvents/NIMROD_30mins/NIMROD_2.2km_filtered_100/{gauge_num}/WholeYear/EventSet/\"\n",
    "\n",
    "            files = [f for f in os.listdir(indy_events_fp) if f.endswith('.csv')]\n",
    "            files = np.sort(files)\n",
    "\n",
    "            for event_num, file in enumerate(files):\n",
    "                fp = indy_events_fp + f\"{file}\"\n",
    "                if '2080' in fp:\n",
    "                    continue\n",
    "\n",
    "                # Get duration for this event\n",
    "                duration_of_this_event = get_dur_for_which_this_is_amax(fp)\n",
    "                if duration_of_this_event not in valid_durations:\n",
    "                    continue  # Skip if not in the list of valid durations\n",
    "\n",
    "                # print(f\"Processing event file: {file} with duration: {duration_of_this_event}\")\n",
    "\n",
    "                # Get event\n",
    "                this_event = read_event(gauge_num, fp)\n",
    "\n",
    "                # Get times and precipitation values\n",
    "                event_times = this_event['times']\n",
    "                event_precip = this_event['precipitation (mm)']\n",
    "\n",
    "                # Apply the function to adjust the dates in the 'times' column\n",
    "                event_times_fixed = event_times.apply(adjust_feb_dates)\n",
    "\n",
    "                # Create the DataFrame with corrected times\n",
    "                event_df = pd.DataFrame({'precipitation (mm)': event_precip, 'times': event_times_fixed})\n",
    "\n",
    "                # Create characteristics dictionary\n",
    "                event_props = create_event_characteristics_dict(event_df)\n",
    "\n",
    "                # Add the duration\n",
    "                event_props['dur_for_which_this_is_amax'] = duration_of_this_event\n",
    "                # Add gauge number and ensemble member\n",
    "                event_props['gauge_num'] = gauge_num\n",
    "                event_props['area'] = tb0_vals.iloc[gauge_num]['within_area']\n",
    "                event_props['filename'] = file\n",
    "\n",
    "                # Store results in corresponding duration category\n",
    "                events_dict[f\"nimrod, {gauge_num}, {event_num}\"] = event_df\n",
    "                event_props_dict[duration_of_this_event][f\"nimrod, {gauge_num}, {event_num}\"] = event_props\n",
    "                event_profiles_dict[f\"nimrod, {gauge_num}, {event_num}\"] = create_profiles_dict(event_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "188b356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "gauge 1007 encountered problem\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "gauge 1293 encountered problem\n"
     ]
    }
   ],
   "source": [
    "# List of desired durations\n",
    "valid_durations = [\"0.5\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"]\n",
    "\n",
    "# Process events for both time periods\n",
    "results_nimrod = process_events_by_duration_nimrod(home_dir2, valid_durations, tbo_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "449b0cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "gauge 1007 encountered problem\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "gauge 1293 encountered problem\n"
     ]
    }
   ],
   "source": [
    "# List of desired durations\n",
    "valid_durations = [\"0.5\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"]\n",
    "\n",
    "# Process events for both time periods\n",
    "results_nimrod = process_events_by_duration_nimrod(home_dir2, valid_durations, tbo_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26b135d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_nimrod_events_dict, dur_nimrod_event_props_dict, dur_nimrod_event_profiles_dict = results_nimrod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0238ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir + f\"ProcessedData/AMAX_Events/NIMROD_30mins/results_each_dur_nimrod.pickle\", 'wb') as handle:\n",
    "    pickle.dump(results_nimrod, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80729dcf",
   "metadata": {},
   "source": [
    "## Do we have the same number of results for each duration?\n",
    "I believe that longer durations have more events because of compound annual maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c060f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 2964\n",
      "1 2964\n",
      "2 2964\n",
      "3 2964\n",
      "6 2966\n",
      "12 3022\n",
      "24 3449\n"
     ]
    }
   ],
   "source": [
    "for duration in valid_durations:\n",
    "    print(duration, len(dur_present_event_props_dict[duration].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46e892c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc005\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc006\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc007\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc009\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc010\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc011\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc012\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc013\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc015\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc016\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc017\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc018\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb189\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb192\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb195\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb198\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb201\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb204\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb208\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb211\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb216\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb219\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb222\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb225\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n"
     ]
    }
   ],
   "source": [
    "# List of desired durations\n",
    "duration_bins = ['<4hr', '4-12hr', '12hr+']\n",
    "\n",
    "def process_events_by_duration(home_dir, time_period, duration_bins, ems, tb0_vals):\n",
    "    events_dict = {duration: {} for duration in duration_bins}\n",
    "    event_props_dict = {duration: {} for duration in duration_bins}\n",
    "    event_profiles_dict = {duration: {} for duration in duration_bins}\n",
    "    for em in ems:  # You can add more ensemble members as needed\n",
    "        print(em)\n",
    "        for gauge_num in range(0, 1293):\n",
    "            if gauge_num not in [444, 827, 888]:\n",
    "                if gauge_num % 100 == 0:\n",
    "                    print(f\"Processing gauge {gauge_num}\")\n",
    "                    indy_events_fp = home_dir + f\"ProcessedData/IndependentEvents/UKCP18_30mins/{time_period}/{em}/{gauge_num}/WholeYear/EventSet/\"\n",
    "\n",
    "                    files = [f for f in os.listdir(indy_events_fp) if f.endswith('.csv')]\n",
    "                    files = np.sort(files)\n",
    "\n",
    "                    for event_num, file in enumerate(files):\n",
    "                        fp = indy_events_fp + f\"{file}\"\n",
    "                        if '2080' in fp:\n",
    "                            continue\n",
    "\n",
    "                        # Get event\n",
    "                        this_event = read_event(gauge_num, fp)\n",
    "\n",
    "                        # Get times and precipitation values\n",
    "                        event_times = this_event['times']\n",
    "                        event_precip = this_event['precipitation (mm)']\n",
    "\n",
    "                        # Apply the function to adjust the dates in the 'times' column\n",
    "                        event_times_fixed = event_times.apply(adjust_feb_dates)\n",
    "\n",
    "                        # Create the DataFrame with corrected times\n",
    "                        event_df = pd.DataFrame({'precipitation (mm)': event_precip, 'times': event_times_fixed})\n",
    "\n",
    "                        # Create characteristics dictionary\n",
    "                        event_props = create_event_characteristics_dict(event_df)\n",
    "                        \n",
    "                        # Add the duration\n",
    "                        event_props['dur_for_which_this_is_amax'] = get_dur_for_which_this_is_amax(fp)\n",
    "                        # Add gauge number and ensemble member\n",
    "                        event_props['gauge_num'] = gauge_num\n",
    "                        event_props['area'] = tb0_vals.iloc[gauge_num]['within_area']\n",
    "                        event_props['em'] = em\n",
    "                        event_props['filename'] = file\n",
    "\n",
    "                        duration_category_of_this_event = event_props['DurationRange_simple']\n",
    "                        # Store results in corresponding duration category\n",
    "                        events_dict[duration_category_of_this_event][f\"{em}, {gauge_num}, {event_num}\"] = event_df\n",
    "                        event_props_dict[duration_category_of_this_event][f\"{em}, {gauge_num}, {event_num}\"] = event_props\n",
    "                        event_profiles_dict[duration_category_of_this_event][f\"{em}, {gauge_num}, {event_num}\"] = create_profiles_dict(event_df)\n",
    "\n",
    "    return events_dict, event_props_dict, event_profiles_dict\n",
    "\n",
    "# Process events for both time periods\n",
    "results_present_dur_categories_simple = process_events_by_duration(home_dir2, 'Present', duration_bins, ems_present, tbo_vals)\n",
    "results_future_dur_categories_simple = process_events_by_duration(home_dir2, 'Future', duration_bins, ems_future, tbo_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a38ee9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/results_present_dur_categories_simple.pickle\", 'wb') as handle:\n",
    "    pickle.dump(results_present_dur_categories_simple, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/results_future_dur_categories_simple.pickle\", 'wb') as handle:\n",
    "    pickle.dump(results_future_dur_categories_simple, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
