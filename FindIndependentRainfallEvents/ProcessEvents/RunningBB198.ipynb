{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a8f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ran for eveything now with excluding the gauges that we don't want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3871500",
   "metadata": {},
   "source": [
    "# Create a set of dimensionless profiles\n",
    "Read in all of the events, for all durations, for all gauges, for all ensemble members.  \n",
    "Convert them to dimensionless profiles, with 12 values between 0 and 1.  \n",
    "Each value is a dimensionless, cumulative rainfall value (cumulative rainfall at this timestep, normalised by the total event rainfall):\n",
    "- 0 means no rainfall has occurred, and \n",
    "- 1 means the total event rainfall has been reached.  \n",
    "\n",
    "If there are less than 12 values, then these are filled in with interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a902314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from Create_Profiles_Functions import *\n",
    "\n",
    "quintile_mapping = {1: 'F2', 2: 'F1', 3: 'C', 4: 'B1', 5: 'B2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "685d13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_part_with_most_rain(array, n, plot=False, ax=False):\n",
    "    if array is None:\n",
    "        return None\n",
    "    else:\n",
    "\n",
    "        # Compute differences\n",
    "        # Split the array into 5 equal parts\n",
    "        splits = np.array_split(array, n)\n",
    "\n",
    "        max_array_rainfall = 0\n",
    "        max_array_num = None\n",
    "\n",
    "        total_precipitations = []  # To store total precipitation for each split\n",
    "        split_ranges = []  # To store start and end indices for each split\n",
    "\n",
    "        # Calculate total precipitation for each split\n",
    "        split_start = 0\n",
    "        for split in splits:\n",
    "            total_precipitation = split.sum()\n",
    "            total_precipitations.append(total_precipitation)\n",
    "            split_end = split_start + len(split)\n",
    "            split_ranges.append((split_start, split_end))\n",
    "            if total_precipitation > max_array_rainfall:\n",
    "                max_array_num = len(total_precipitations)\n",
    "                max_array_rainfall = total_precipitation\n",
    "            split_start = split_end\n",
    "\n",
    "        colors = ['lightblue'] * n  # Default color for all splits\n",
    "        highlight_color = 'yellow'  # Color for the split with the most rainfall\n",
    "\n",
    "        if plot:\n",
    "            # Plot the array\n",
    "            ax.plot(range(1, len(array) + 1), array, label='Precipitation', marker='o')\n",
    "\n",
    "            # Add vertical lines and shading for each split segment\n",
    "            for i, (start_index, end_index) in enumerate(split_ranges):\n",
    "                color = highlight_color if (i + 1) == max_array_num else colors[i]\n",
    "\n",
    "                # Add vertical lines at the start and end of each split\n",
    "                ax.axvline(x=start_index + 1, color=color, linestyle='--', label=f'Split {i+1} Start' if i == 0 or (i + 1) == max_array_num else \"\")\n",
    "                ax.axvline(x=end_index, color=color, linestyle='--', label=f'Split {i+1} End' if i == 0 or (i + 1) == max_array_num else \"\")\n",
    "\n",
    "                # Shade the region for the split\n",
    "                ax.fill_between(range(start_index + 1, end_index + 1), array[start_index:end_index], color=color, alpha=0.3)\n",
    "\n",
    "                # Add the total precipitation value behind the shading\n",
    "                ax.text((start_index + end_index) / 2+0.5, max(array) * 0.05,  # Adjust y-position if needed\n",
    "                        f'{total_precipitations[i]:.2f}',\n",
    "                        ha='center', va='center', fontsize=10, color='black', weight='bold', zorder=1)\n",
    "\n",
    "            ax.set_title(f'Precipitation Values with Splits Marked. Max at {max_array_num}')\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Precipitation')\n",
    "\n",
    "    return max_array_num\n",
    "\n",
    "\n",
    "def create_normalised_event(rainfall):\n",
    "    # Check if the input array is None or empty\n",
    "    if rainfall is None or len(rainfall) == 0:\n",
    "        # print(\"Input array is None or empty. Cannot normalize.\")\n",
    "        return None\n",
    "\n",
    "    # Check if the maximum value is zero to avoid division by zero\n",
    "    if np.max(rainfall) == 0:\n",
    "        print(\"Maximum rainfall is zero. Cannot normalize.\")\n",
    "        return rainfall  # Return the input as-is, or handle appropriately\n",
    "\n",
    "    # Normalize rainfall from 0 to 1 using the maximum value\n",
    "    normalized_rainfall = rainfall / np.max(rainfall)\n",
    "\n",
    "    # Debug prints to check the input and output\n",
    "    return normalized_rainfall\n",
    "\n",
    "def create_cumulative_event(rainfall):\n",
    "    \n",
    "    # Calculate cumulative rainfall\n",
    "    cumulative_rainfall = np.cumsum(rainfall)\n",
    "    \n",
    "    return cumulative_rainfall\n",
    "\n",
    "def interpolate_rainfall(rainfall, bin_number):\n",
    "    if rainfall is None or len(rainfall) < 2:\n",
    "        return None\n",
    "\n",
    "    # Define target points for bin_number bins\n",
    "    target_points = np.linspace(0, 1, bin_number)\n",
    "    \n",
    "    # Create interpolation function based on existing data points\n",
    "    rainfall_times = np.array(range(0, len(rainfall)))\n",
    "\n",
    "    # Normalize time from 0 to 1\n",
    "    normalized_time = (rainfall_times - rainfall_times[0]) / (rainfall_times[-1] - rainfall_times[0])\n",
    "    interpolation_func = interp1d(normalized_time, rainfall, kind='linear', fill_value=\"extrapolate\")\n",
    "    \n",
    "    # Interpolate values at target points\n",
    "    interpolated_values = interpolation_func(target_points)\n",
    "    \n",
    "    return interpolated_values\n",
    "\n",
    "\n",
    "def create_incremental_event(cumulative_rainfall):\n",
    "    if cumulative_rainfall is None :\n",
    "        return None\n",
    "    \n",
    "    raw_rainfall = np.diff(cumulative_rainfall, prepend=0)\n",
    "    raw_rainfall[0] = cumulative_rainfall[0]\n",
    "    return raw_rainfall\n",
    "\n",
    "def extract_year(df):\n",
    "    # Ensure the 'times' column is in datetime format\n",
    "    df['times'] = pd.to_datetime(df['times'], errors='coerce')  # errors='coerce' will handle invalid parsing\n",
    "    # Extract the year\n",
    "    return df['times'].dt.year[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f9a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_nums = range(0,1294)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f65f57f",
   "metadata": {},
   "source": [
    "# NIMROD - 30 mins\n",
    "### Make profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e002bc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gauge 0\n",
      "gauge 1\n",
      "gauge 2\n",
      "gauge 3\n",
      "gauge 4\n"
     ]
    }
   ],
   "source": [
    "# # Initialize an empty DataFrame with the desired columns\n",
    "columns = [\n",
    "    'gauge_num',  'season', 'precip', 'Volume','Year', 'times', 'duration',\n",
    "    'normalized_rainfall', 'normalized_interpolated_rainfall_12', 'normalized_interpolated_rainfall_15',\n",
    "    'max_quintile_profile_12', 'max_quintile_profile_15', 'max_quintile_normalised_rain', 'max_quintile_raw_rain']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for nimrod_option in [\"NIMROD_2.2km_filtered_100\"]:\n",
    "    for gauge_num in range(0, 1293):\n",
    "        if gauge_num not in [444, 827, 888]:\n",
    "            print(f\"gauge {gauge_num}\")\n",
    "            files = [f for f in os.listdir(f\"/nfs/a161/gy17m2a/PhD/ProcessedData/IndependentEvents/NIMROD_30mins/{nimrod_option}/{gauge_num}/WholeYear\") if f.endswith('.csv')]\n",
    "            files = np.sort(files)\n",
    "\n",
    "            for file in files:\n",
    "                fp = f\"/nfs/a161/gy17m2a/PhD/ProcessedData/IndependentEvents/NIMROD_30mins/{nimrod_option}/{gauge_num}/WholeYear/{file}\"\n",
    "                if '2080' in fp:\n",
    "                    continue\n",
    "\n",
    "                this_event = read_event(gauge_num, fp)\n",
    "                trimmed_event = remove_leading_and_trailing_zeroes(this_event)\n",
    "                real_trimmed_event, problem_events = remove_events_with_problems(trimmed_event, verbose=False)\n",
    "\n",
    "                if real_trimmed_event is not None:\n",
    "                    \n",
    "                    precip = real_trimmed_event['precipitation (mm/hr)']\n",
    "                    normalized_rainfall = create_normalised_event(real_trimmed_event['precipitation (mm/hr)'])\n",
    "                    cumulative_normalized_rainfall = create_cumulative_event(normalized_rainfall)\n",
    "                    interpolated15_cumulative_normalized_rainfall = interpolate_rainfall(cumulative_normalized_rainfall,15)\n",
    "                    interpolated12_cumulative_normalized_rainfall = interpolate_rainfall(cumulative_normalized_rainfall,12)\n",
    "                    interpolated15_incremental_normalized_rainfall = create_incremental_event(interpolated15_cumulative_normalized_rainfall)\n",
    "                    interpolated12_incremental_normalized_rainfall = create_incremental_event(interpolated12_cumulative_normalized_rainfall)\n",
    "\n",
    "                    max_quintile_profile_12 = find_part_with_most_rain(interpolated12_incremental_normalized_rainfall, 5)\n",
    "                    max_quintile_profile_15 = find_part_with_most_rain(interpolated15_incremental_normalized_rainfall, 5)\n",
    "                    max_quintile_normalised_rain = find_part_with_most_rain(normalized_rainfall, 5)\n",
    "                    max_quintile_raw_rain = find_part_with_most_rain(precip, 5)\n",
    "                    \n",
    "                    duration = len(real_trimmed_event) / 2\n",
    "                    times = trimmed_event['times']\n",
    "                    season = get_season(trimmed_event['times'][0])\n",
    "                    year=extract_year(trimmed_event)\n",
    "                    \n",
    "                else:\n",
    "                    precip=trimmed_event['precipitation (mm/hr)']\n",
    "                    normalized_rainfall = None\n",
    "                    normalized_interpolated_rainfall_12 = None\n",
    "                    normalized_interpolated_rainfall_15 = None\n",
    "                    max_quintile_profile_12 = None\n",
    "                    max_quintile_profile_15 = None\n",
    "                    max_quintile_normalised_rain = None\n",
    "                    max_quintile_raw_rain = None\n",
    "                    duration = None\n",
    "                    season = None\n",
    "                    year=None\n",
    "                    times=None\n",
    "                    \n",
    "                # Append the row to the DataFrame\n",
    "                df = df.append({\n",
    "                    'gauge_num': gauge_num,\n",
    "                    'season': season,\n",
    "                    'precip': precip.values,\n",
    "                    'Volume': sum(precip),\n",
    "                    'Year':year,\n",
    "                    'times':times, \n",
    "                    'duration': duration,\n",
    "                    'normalized_rainfall': normalized_rainfall,\n",
    "                    'normalized_interpolated_rainfall_12': interpolated12_incremental_normalized_rainfall,\n",
    "                    'normalized_interpolated_rainfall_15': interpolated15_cumulative_normalized_rainfall,\n",
    "                    'max_quintile_profile_12': max_quintile_profile_12,\n",
    "                    'max_quintile_profile_15': max_quintile_profile_15,\n",
    "                    'max_quintile_normalised_rain': max_quintile_normalised_rain,\n",
    "                    'max_quintile_raw_rain': max_quintile_raw_rain\n",
    "                }, ignore_index=True)\n",
    "                \n",
    "df['Loading_profile12'] = df['max_quintile_profile_12'].map(quintile_mapping)\n",
    "df['Loading_profile15'] = df['max_quintile_profile_15'].map(quintile_mapping)\n",
    "df['Loading_profile_normalised_rain'] = df['max_quintile_normalised_rain'].map(quintile_mapping)\n",
    "df['Loading_profile_raw_rain'] = df['max_quintile_raw_rain'].map(quintile_mapping)\n",
    "\n",
    "with open(f\"/nfs/a319/gy17m2a/PhD/ProcessedData/Profiles/NIMROD_30mins/WholeYear/{nimrod_option}_profiles_df.pkl\", 'wb') as file:\n",
    "    pickle.dump(df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991aa2df",
   "metadata": {},
   "source": [
    "# NIMROD 5 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde96374",
   "metadata": {},
   "source": [
    "# UKCP18\n",
    "### Make and pickle profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5edf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gauge 0\n",
      "gauge 1\n",
      "gauge 2\n",
      "gauge 3\n",
      "gauge 4\n",
      "gauge 5\n",
      "gauge 6\n",
      "gauge 7\n",
      "gauge 8\n",
      "gauge 9\n",
      "gauge 10\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 11\n",
      "gauge 12\n",
      "gauge 13\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 14\n",
      "gauge 15\n",
      "gauge 16\n",
      "gauge 17\n",
      "gauge 18\n",
      "gauge 19\n",
      "gauge 20\n",
      "gauge 21\n",
      "gauge 22\n",
      "gauge 23\n",
      "gauge 24\n",
      "gauge 25\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 26\n",
      "gauge 27\n",
      "gauge 28\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 29\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 30\n",
      "gauge 31\n",
      "gauge 32\n",
      "gauge 33\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 34\n",
      "gauge 35\n",
      "gauge 36\n",
      "gauge 37\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 38\n",
      "gauge 39\n",
      "gauge 40\n",
      "gauge 41\n",
      "gauge 42\n",
      "gauge 43\n",
      "gauge 44\n",
      "gauge 45\n",
      "gauge 46\n",
      "gauge 47\n",
      "gauge 48\n",
      "gauge 49\n",
      "gauge 50\n",
      "gauge 51\n",
      "gauge 52\n",
      "gauge 53\n",
      "gauge 54\n",
      "gauge 55\n",
      "gauge 56\n",
      "gauge 57\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 58\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 59\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 60\n",
      "gauge 61\n",
      "gauge 62\n",
      "gauge 63\n",
      "gauge 64\n",
      "gauge 65\n",
      "gauge 66\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 67\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 68\n",
      "gauge 69\n",
      "gauge 70\n",
      "gauge 71\n",
      "gauge 72\n",
      "gauge 73\n",
      "gauge 74\n",
      "gauge 75\n",
      "gauge 76\n",
      "gauge 77\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 78\n",
      "gauge 79\n",
      "gauge 80\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 81\n",
      "gauge 82\n",
      "gauge 83\n",
      "gauge 84\n",
      "gauge 85\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 86\n",
      "gauge 87\n",
      "gauge 88\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "gauge 89\n",
      "gauge 90\n"
     ]
    }
   ],
   "source": [
    "# # Initialize an empty DataFrame with the desired columns\n",
    "# Initialize an empty DataFrame with the desired columns\n",
    "columns = [\n",
    "    'gauge_num',  'season', 'precip', 'Volume','Year', 'times', 'duration',\n",
    "    'normalized_rainfall', 'normalized_interpolated_rainfall_12', 'normalized_interpolated_rainfall_15',\n",
    "    'max_quintile_profile_12', 'max_quintile_profile_15', 'max_quintile_normalised_rain', 'max_quintile_raw_rain']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for em in [\"bb198\"]:\n",
    "    for gauge_num in range(0, 1293):\n",
    "        if gauge_num not in [444, 827, 888]:\n",
    "            print(f\"gauge {gauge_num}\")\n",
    "            files = [f for f in os.listdir(f\"/nfs/a161/gy17m2a/PhD/ProcessedData/IndependentEvents/UKCP18_30mins/{em}/{gauge_num}/WholeYear/\") if f.endswith('.csv')]\n",
    "            files = np.sort(files)\n",
    "\n",
    "            for file in files:\n",
    "                fp = f\"/nfs/a161/gy17m2a/PhD/ProcessedData/IndependentEvents/UKCP18_30mins/{em}/{gauge_num}/WholeYear/{file}\"\n",
    "                if '2080' in fp:\n",
    "                    continue\n",
    "\n",
    "                this_event = read_event(gauge_num, fp)\n",
    "                trimmed_event = remove_leading_and_trailing_zeroes(this_event)\n",
    "                real_trimmed_event, problem_events = remove_events_with_problems(trimmed_event, verbose=False)\n",
    "\n",
    "                if real_trimmed_event is not None:\n",
    "                    \n",
    "                    precip = real_trimmed_event['precipitation (mm/hr)']\n",
    "                    normalized_rainfall = create_normalised_event(real_trimmed_event['precipitation (mm/hr)'])\n",
    "                    cumulative_normalized_rainfall = create_cumulative_event(normalized_rainfall)\n",
    "                    interpolated15_cumulative_normalized_rainfall = interpolate_rainfall(cumulative_normalized_rainfall,15)\n",
    "                    interpolated12_cumulative_normalized_rainfall = interpolate_rainfall(cumulative_normalized_rainfall,12)\n",
    "                    interpolated15_incremental_normalized_rainfall = create_incremental_event(interpolated15_cumulative_normalized_rainfall)\n",
    "                    interpolated12_incremental_normalized_rainfall = create_incremental_event(interpolated12_cumulative_normalized_rainfall)\n",
    "\n",
    "                    max_quintile_profile_12 = find_part_with_most_rain(interpolated12_incremental_normalized_rainfall, 5)\n",
    "                    max_quintile_profile_15 = find_part_with_most_rain(interpolated15_incremental_normalized_rainfall, 5)\n",
    "                    max_quintile_normalised_rain = find_part_with_most_rain(normalized_rainfall, 5)\n",
    "                    max_quintile_raw_rain = find_part_with_most_rain(precip, 5)\n",
    "                    \n",
    "                    duration = len(real_trimmed_event) / 2\n",
    "                    times = trimmed_event['times']\n",
    "                    season = get_season(trimmed_event['times'][0])\n",
    "                    year=extract_year(trimmed_event)\n",
    "                    \n",
    "                else:\n",
    "                    precip=trimmed_event['precipitation (mm/hr)']\n",
    "                    normalized_rainfall = None\n",
    "                    normalized_interpolated_rainfall_12 = None\n",
    "                    normalized_interpolated_rainfall_15 = None\n",
    "                    max_quintile_profile_12 = None\n",
    "                    max_quintile_profile_15 = None\n",
    "                    max_quintile_normalised_rain = None\n",
    "                    max_quintile_raw_rain = None\n",
    "                    duration = None\n",
    "                    season = None\n",
    "                    year=None\n",
    "                    times=None\n",
    "                    \n",
    "                # Append the row to the DataFrame\n",
    "                df = df.append({\n",
    "                    'gauge_num': gauge_num,\n",
    "                    'season': season,\n",
    "                    'precip': precip.values,\n",
    "                    'Volume': sum(precip),\n",
    "                    'Year':year,\n",
    "                    'times':times, \n",
    "                    'duration': duration,\n",
    "                    'normalized_rainfall': normalized_rainfall,\n",
    "                    'normalized_interpolated_rainfall_12': interpolated12_incremental_normalized_rainfall,\n",
    "                    'normalized_interpolated_rainfall_15': interpolated15_cumulative_normalized_rainfall,\n",
    "                    'max_quintile_profile_12': max_quintile_profile_12,\n",
    "                    'max_quintile_profile_15': max_quintile_profile_15,\n",
    "                    'max_quintile_normalised_rain': max_quintile_normalised_rain,\n",
    "                    'max_quintile_raw_rain': max_quintile_raw_rain\n",
    "                }, ignore_index=True)\n",
    "                \n",
    "df['Loading_profile12'] = df['max_quintile_profile_12'].map(quintile_mapping)\n",
    "df['Loading_profile15'] = df['max_quintile_profile_15'].map(quintile_mapping)\n",
    "df['Loading_profile_normalised_rain'] = df['max_quintile_normalised_rain'].map(quintile_mapping)\n",
    "df['Loading_profile_raw_rain'] = df['max_quintile_raw_rain'].map(quintile_mapping)\n",
    "\n",
    "with open(f\"/nfs/a319/gy17m2a/PhD/ProcessedData/Profiles/UKCP18_30mins/{em}/profiles_df.pkl\", 'wb') as file:\n",
    "    pickle.dump(df, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
