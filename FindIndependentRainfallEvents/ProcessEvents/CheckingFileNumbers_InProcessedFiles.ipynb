{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf0a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# import re\n",
    "import pickle\n",
    "# import sys\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "# from shapely.geometry import Point\n",
    "\n",
    "# sys.path.insert(1, '../../../ProcessEvents')\n",
    "# from ProcessEventsFunctions import *\n",
    "# # from Convert_to_Profiles_Functions import *\n",
    "# # from Get_Events_Functions import *\n",
    "\n",
    "# Function to check for part1 in strings or lists of strings\n",
    "def does_not_contain_part0(x):\n",
    "    # Check if x is a string or a list of strings\n",
    "    if isinstance(x, str):\n",
    "        return 'part0' not in x\n",
    "    elif isinstance(x, list):\n",
    "        return any('part0' not in item for item in x)  # Ensure part1 is not in any item\n",
    "    return True  # If it's neither, we keep it\n",
    "\n",
    "\n",
    "def contains_part0(x):\n",
    "    # Check if x is a string or a list of strings\n",
    "    if isinstance(x, str):\n",
    "        return 'part0' in x\n",
    "    elif isinstance(x, list):\n",
    "        return any('part0' in item for item in x)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ac738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/nfs/a319/gy17m2a/PhD/'\n",
    "home_dir2 = '/nfs/a161/gy17m2a/PhD/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa986fc7",
   "metadata": {},
   "source": [
    "## Check number of events when combined into the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cebc838",
   "metadata": {},
   "source": [
    "### Read  the processed data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8452e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events_props_dict_present = []\n",
    "# ems_present = ['bc005', 'bc006', 'bc007', 'bc009', 'bc010', 'bc011', 'bc012', 'bc013', 'bc015', 'bc016', 'bc017', 'bc018']\n",
    "# for em in ems_present:\n",
    "#     with open(home_dir +  f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/event_props_dict_{em}.pickle\", 'rb') as handle:\n",
    "#         events_props_dict = pickle.load(handle)    \n",
    "#     events_props_dict_present = events_props_dict_present + events_props_dict\n",
    "# ## Join into one dataframe    \n",
    "# present_allevents = pd.DataFrame(events_props_dict_present)\n",
    "# present_allevents['Climate'] = 'Present'    \n",
    "\n",
    "events_props_dict_future = []\n",
    "ems_future = ['bb192', 'bb195', 'bb198', 'bb208', 'bb225','bb222', 'bb201', 'bb204', 'bb216', 'bb219', 'bb211'] # , \n",
    "for em in ems_future:\n",
    "    with open(home_dir +  f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/event_props_dict_{em}.pickle\", 'rb') as handle:\n",
    "        events_props_dict = pickle.load(handle)    \n",
    "    events_props_dict_future = events_props_dict_future + events_props_dict\n",
    "## Join into one dataframe    \n",
    "future_allevents = pd.DataFrame(events_props_dict_future)\n",
    "future_allevents['Climate'] = 'Future'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2181aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir +  f\"ProcessedData/AMAX_Events/NIMROD_30mins/event_props_dict.pickle\", 'rb') as handle:\n",
    "    events_props_dict_nimrod = pickle.load(handle)    \n",
    "    \n",
    "## Join into one dataframe    \n",
    "nimrod_allevents = pd.DataFrame(events_props_dict_nimrod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7423c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>duration</th>\n",
       "      <th>DurationRange_personalised_allems</th>\n",
       "      <th>DurationRange_notpersonalised</th>\n",
       "      <th>DurationRange_simple</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Volume</th>\n",
       "      <th>max_intensity</th>\n",
       "      <th>max_quintile_molly</th>\n",
       "      <th>...</th>\n",
       "      <th>theta</th>\n",
       "      <th>D50</th>\n",
       "      <th>D50_new</th>\n",
       "      <th>com</th>\n",
       "      <th>dur_for_which_this_is_amax</th>\n",
       "      <th>gauge_num</th>\n",
       "      <th>area</th>\n",
       "      <th>em</th>\n",
       "      <th>filename</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Winter</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.10-6.45 hr</td>\n",
       "      <td>6.45-19.25 hr</td>\n",
       "      <td>4-12hr</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>9.755217</td>\n",
       "      <td>9.419543</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6.244480</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>55.614673</td>\n",
       "      <td>0.497021</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>ME</td>\n",
       "      <td>nimrod</td>\n",
       "      <td>0.5hrs_2006_v2_part0.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summer</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.25-2.10 hr</td>\n",
       "      <td>2.10-6.45 hr</td>\n",
       "      <td>&lt;4hr</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>25.853352</td>\n",
       "      <td>20.064659</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.855602</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>43.677504</td>\n",
       "      <td>0.356900</td>\n",
       "      <td>[0.5, 3]</td>\n",
       "      <td>0</td>\n",
       "      <td>ME</td>\n",
       "      <td>nimrod</td>\n",
       "      <td>0.5hrs_2007_v2_part0.csv</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.10-6.45 hr</td>\n",
       "      <td>6.45-19.25 hr</td>\n",
       "      <td>4-12hr</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>25.296344</td>\n",
       "      <td>12.425273</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.870545</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>23.664053</td>\n",
       "      <td>0.408516</td>\n",
       "      <td>[0.5, 12]</td>\n",
       "      <td>0</td>\n",
       "      <td>ME</td>\n",
       "      <td>nimrod</td>\n",
       "      <td>0.5hrs_2008_v2_part0.csv</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summer</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.10-6.45 hr</td>\n",
       "      <td>6.45-19.25 hr</td>\n",
       "      <td>4-12hr</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>16.236685</td>\n",
       "      <td>19.789144</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.216853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.128028</td>\n",
       "      <td>0.076839</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>ME</td>\n",
       "      <td>nimrod</td>\n",
       "      <td>0.5hrs_2009_v2_part0.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summer</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25-2.10 hr</td>\n",
       "      <td>0.25-2.10 hr</td>\n",
       "      <td>&lt;4hr</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>11.776064</td>\n",
       "      <td>15.752159</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.354473</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>56.968731</td>\n",
       "      <td>0.426550</td>\n",
       "      <td>[0.5, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>ME</td>\n",
       "      <td>nimrod</td>\n",
       "      <td>0.5hrs_2010_v2_part0.csv</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78316</th>\n",
       "      <td>Winter</td>\n",
       "      <td>37.5</td>\n",
       "      <td>19.25+ hr</td>\n",
       "      <td>19.25+ hr</td>\n",
       "      <td>12hr+</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>66.916048</td>\n",
       "      <td>10.248569</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.831622</td>\n",
       "      <td>40.540541</td>\n",
       "      <td>40.519917</td>\n",
       "      <td>0.444886</td>\n",
       "      <td>3</td>\n",
       "      <td>1293</td>\n",
       "      <td>NE</td>\n",
       "      <td>nimrod</td>\n",
       "      <td>3hrs_2020_v2_part0.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78317</th>\n",
       "      <td>Summer</td>\n",
       "      <td>36.0</td>\n",
       "      <td>19.25+ hr</td>\n",
       "      <td>19.25+ hr</td>\n",
       "      <td>12hr+</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>77.264324</td>\n",
       "      <td>8.451828</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.818938</td>\n",
       "      <td>69.014085</td>\n",
       "      <td>68.525317</td>\n",
       "      <td>0.627847</td>\n",
       "      <td>6</td>\n",
       "      <td>1293</td>\n",
       "      <td>NE</td>\n",
       "      <td>nimrod</td>\n",
       "      <td>6hrs_2011_v2_part0.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78318</th>\n",
       "      <td>Winter</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.10-6.45 hr</td>\n",
       "      <td>6.45-19.25 hr</td>\n",
       "      <td>4-12hr</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>29.182340</td>\n",
       "      <td>5.629660</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.261682</td>\n",
       "      <td>57.894737</td>\n",
       "      <td>59.794080</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>6</td>\n",
       "      <td>1293</td>\n",
       "      <td>NE</td>\n",
       "      <td>nimrod</td>\n",
       "      <td>6hrs_2013_v2_part0.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78319</th>\n",
       "      <td>Winter</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.25+ hr</td>\n",
       "      <td>19.25+ hr</td>\n",
       "      <td>12hr+</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>59.670285</td>\n",
       "      <td>7.223855</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4.747869</td>\n",
       "      <td>59.574468</td>\n",
       "      <td>59.714406</td>\n",
       "      <td>0.550810</td>\n",
       "      <td>6</td>\n",
       "      <td>1293</td>\n",
       "      <td>NE</td>\n",
       "      <td>nimrod</td>\n",
       "      <td>6hrs_2014_v2_part0.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78320</th>\n",
       "      <td>Winter</td>\n",
       "      <td>66.5</td>\n",
       "      <td>19.25+ hr</td>\n",
       "      <td>19.25+ hr</td>\n",
       "      <td>12hr+</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>64.988727</td>\n",
       "      <td>4.770890</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.797217</td>\n",
       "      <td>51.515152</td>\n",
       "      <td>51.450935</td>\n",
       "      <td>0.458198</td>\n",
       "      <td>6</td>\n",
       "      <td>1293</td>\n",
       "      <td>NE</td>\n",
       "      <td>nimrod</td>\n",
       "      <td>6hrs_2015_v2_part0.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78321 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  duration DurationRange_personalised_allems  \\\n",
       "0      Winter       8.5                      2.10-6.45 hr   \n",
       "1      Summer       3.5                      0.25-2.10 hr   \n",
       "2      Summer      10.5                      2.10-6.45 hr   \n",
       "3      Summer       8.0                      2.10-6.45 hr   \n",
       "4      Summer       1.5                      0.25-2.10 hr   \n",
       "...       ...       ...                               ...   \n",
       "78316  Winter      37.5                         19.25+ hr   \n",
       "78317  Summer      36.0                         19.25+ hr   \n",
       "78318  Winter      10.0                      2.10-6.45 hr   \n",
       "78319  Winter      24.0                         19.25+ hr   \n",
       "78320  Winter      66.5                         19.25+ hr   \n",
       "\n",
       "      DurationRange_notpersonalised DurationRange_simple  year  month  \\\n",
       "0                     6.45-19.25 hr               4-12hr  2006     12   \n",
       "1                      2.10-6.45 hr                 <4hr  2007      6   \n",
       "2                     6.45-19.25 hr               4-12hr  2008      8   \n",
       "3                     6.45-19.25 hr               4-12hr  2009      7   \n",
       "4                      0.25-2.10 hr                 <4hr  2010      7   \n",
       "...                             ...                  ...   ...    ...   \n",
       "78316                     19.25+ hr                12hr+  2020     12   \n",
       "78317                     19.25+ hr                12hr+  2011      8   \n",
       "78318                 6.45-19.25 hr               4-12hr  2013     12   \n",
       "78319                     19.25+ hr                12hr+  2014     10   \n",
       "78320                     19.25+ hr                12hr+  2015     12   \n",
       "\n",
       "          Volume  max_intensity  max_quintile_molly  ...     theta        D50  \\\n",
       "0       9.755217       9.419543                   3  ...  6.244480  56.250000   \n",
       "1      25.853352      20.064659                   3  ...  2.855602  50.000000   \n",
       "2      25.296344      12.425273                   1  ...  3.870545  20.000000   \n",
       "3      16.236685      19.789144                   1  ...  3.216853   0.000000   \n",
       "4      11.776064      15.752159                   3  ...  3.354473  50.000000   \n",
       "...          ...            ...                 ...  ...       ...        ...   \n",
       "78316  66.916048      10.248569                   2  ...  5.831622  40.540541   \n",
       "78317  77.264324       8.451828                   5  ...  3.818938  69.014085   \n",
       "78318  29.182340       5.629660                   4  ...  6.261682  57.894737   \n",
       "78319  59.670285       7.223855                   4  ...  4.747869  59.574468   \n",
       "78320  64.988727       4.770890                   1  ...  5.797217  51.515152   \n",
       "\n",
       "         D50_new       com dur_for_which_this_is_amax  gauge_num  area  \\\n",
       "0      55.614673  0.497021                        0.5          0    ME   \n",
       "1      43.677504  0.356900                   [0.5, 3]          0    ME   \n",
       "2      23.664053  0.408516                  [0.5, 12]          0    ME   \n",
       "3       5.128028  0.076839                        0.5          0    ME   \n",
       "4      56.968731  0.426550                   [0.5, 2]          0    ME   \n",
       "...          ...       ...                        ...        ...   ...   \n",
       "78316  40.519917  0.444886                          3       1293    NE   \n",
       "78317  68.525317  0.627847                          6       1293    NE   \n",
       "78318  59.794080  0.561644                          6       1293    NE   \n",
       "78319  59.714406  0.550810                          6       1293    NE   \n",
       "78320  51.450935  0.458198                          6       1293    NE   \n",
       "\n",
       "           em                  filename  count  \n",
       "0      nimrod  0.5hrs_2006_v2_part0.csv      1  \n",
       "1      nimrod  0.5hrs_2007_v2_part0.csv      2  \n",
       "2      nimrod  0.5hrs_2008_v2_part0.csv      2  \n",
       "3      nimrod  0.5hrs_2009_v2_part0.csv      1  \n",
       "4      nimrod  0.5hrs_2010_v2_part0.csv      2  \n",
       "...       ...                       ...    ...  \n",
       "78316  nimrod    3hrs_2020_v2_part0.csv      1  \n",
       "78317  nimrod    6hrs_2011_v2_part0.csv      1  \n",
       "78318  nimrod    6hrs_2013_v2_part0.csv      1  \n",
       "78319  nimrod    6hrs_2014_v2_part0.csv      1  \n",
       "78320  nimrod    6hrs_2015_v2_part0.csv      1  \n",
       "\n",
       "[78321 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nimrod_allevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "556e3fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87266"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nimrod_allevents['count'] = nimrod_allevents['dur_for_which_this_is_amax'].apply(lambda x: len(x) if isinstance(x, list) else 1)\n",
    "\n",
    "# Sum up the counts to get the total number of items\n",
    "total_count = nimrod_allevents['count'].sum()\n",
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e582db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 78321 \n",
    "# 92279"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac76add",
   "metadata": {},
   "source": [
    "### Total number of events\n",
    "Different number of events each EM, because its all events, no duplicates, and number of events which are the AMAX for different durations will vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19191f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb192 89106\n",
      "bb195 89421\n",
      "bb198 92279\n",
      "bb208 89561\n",
      "bb225 90905\n",
      "bb222 92102\n",
      "bb201 89686\n",
      "bb204 91815\n",
      "bb216 89210\n",
      "bb219 89313\n",
      "bb211 91231\n"
     ]
    }
   ],
   "source": [
    "for em in ems_future:\n",
    "    # This is the TOTAL number of events\n",
    "    print(em, len([d for d in events_props_dict_future if d.get('em') == em]))\n",
    "    # This just does the same thing\n",
    "    # this_em = future_allevents[future_allevents['em']==em]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8bb15",
   "metadata": {},
   "source": [
    "## Checking the number of part0 events\n",
    "Get data for one em.  \n",
    "Get data for one duration.  \n",
    "Get data for one gauge, check if there are 19 events with part 0 in the string\n",
    "\n",
    "Part0 rows sometimes has more than one entry per year, for the same duration. This is presumably because of CAM. However it's confusing because in that case I might have expected the filename to be Part1, but its not. \n",
    "\n",
    "WE CAN NO LONGER USE FILENAME TO SORT BECAUSE IT ONLY REFERS TO ONE OF THE EVENTS REPRESENTED BY EACH ROW\n",
    "\n",
    "IF WANTED TO CHECK THIS ONCE AND FOR ALL, WOULD NEED TO IMPLEMENT SOMETHING IN PROCESSING FILE WHICH ASSIGNS THE FILENAME ROW WITH FLAGS FOR EACH DURATION AS TO WHETHER IT WAS A PART0 OR A PART1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "22839c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations =[0.5, 1,2,3,6,12,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f92af96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb195\n",
      "duration : 0.5\n",
      "24529 events for 0.5hrs\n",
      "duration : 1\n",
      "24529 events for 1hrs\n",
      "duration : 2\n",
      "24529 events for 2hrs\n",
      "duration : 3\n",
      "24529 events for 3hrs\n",
      "duration : 6\n",
      "24529 events for 6hrs\n",
      "duration : 12\n",
      "24529 events for 12hrs\n",
      "duration : 24\n",
      "24529 events for 24hrs\n"
     ]
    }
   ],
   "source": [
    "## Get data for one ensemble member\n",
    "for em in ['bb195']:\n",
    "    print(em)\n",
    "    this_em = future_allevents[future_allevents['em']==em].copy()\n",
    "    \n",
    "    ## Get data for one duration\n",
    "    for duration in durations:\n",
    "        print(f\"duration : {duration}\")\n",
    "        \n",
    "        #  Get events for just this duration\n",
    "        future_allevents_thisdur = this_em[this_em['dur_for_which_this_is_amax'].apply(\n",
    "            lambda x: isinstance(x, list) and str(duration) in x or x == str(duration))].copy()\n",
    "\n",
    "        # Convert all durations and filenames to a list, even if just one value\n",
    "        future_allevents_thisdur['filename'] = future_allevents_thisdur['filename'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "        future_allevents_thisdur['dur_for_which_this_is_amax'] = future_allevents_thisdur['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "        # Keep just the relevant filename for this duration\n",
    "        future_allevents_thisdur['index_of_this_dur'] = future_allevents_thisdur['dur_for_which_this_is_amax'].apply(\n",
    "            lambda x: x.index(str(duration)) if str(duration) in x else -1)\n",
    "        # Create a new column to extract the corresponding filename using the index\n",
    "        future_allevents_thisdur['corresponding_filename'] = future_allevents_thisdur.apply(\n",
    "            lambda row: row['filename'][row['index_of_this_dur']] if row['index_of_this_dur'] != -1 and row['index_of_this_dur'] < len(row['filename']) else None, axis=1)\n",
    "\n",
    "        ## Filter out the part1'ers\n",
    "        future_allevents_thisdur = future_allevents_thisdur[~future_allevents_thisdur['corresponding_filename'].str.contains(\"part1\", na=False)]\n",
    "        print(f\"{len(future_allevents_thisdur)} events for {duration}hrs\")\n",
    "\n",
    "        # Get data for one gauge, and find how many rows there are \n",
    "        # We would expect there to be 19\n",
    "        for gauge_num in range(0,1294):\n",
    "            if gauge_num not in [444,827,888]:\n",
    "                this_gauge= future_allevents_thisdur[future_allevents_thisdur['gauge_num']==gauge_num].copy()\n",
    "\n",
    "                if len(filtered_df) != 19:\n",
    "                    print(gauge_num, len(filtered_df))\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e0d45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Get data for one duration\n",
    "# for duration in durations:\n",
    "#     nimrod_allevents_thisdur = nimrod_allevents[nimrod_allevents['dur_for_which_this_is_amax'].apply(\n",
    "#         lambda x: isinstance(x, list) and str(duration) in x or x == str(duration))]\n",
    "#     nimrod_allevents_thisdur.sort_values(by=['gauge_num', 'year'], ascending=[True, True])\n",
    "#     print(f\"{len(nimrod_allevents_thisdur)} events for {duration}hrs\")\n",
    "\n",
    "#     # Get data for one gauge, and find how many rows there are \n",
    "#     # We would expect there to be 19\n",
    "#     for gauge_num in range(0,1294):\n",
    "#         if gauge_num not in [444,827,888]:\n",
    "#             this_gauge= nimrod_allevents_thisdur[nimrod_allevents_thisdur['gauge_num']==gauge_num]\n",
    "# #             print(gauge_num, len(this_gauge))\n",
    "#             if len(this_gauge) != 15:\n",
    "#                 print(gauge_num, len(this_gauge))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bbb67a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration = '1'\n",
    "# nimrod_allevents_thisdur = nimrod_allevents[nimrod_allevents['dur_for_which_this_is_amax'].apply(\n",
    "#     lambda x: isinstance(x, list) and str(duration) in x or x == str(duration))]\n",
    "# nimrod_allevents_thisdur.sort_values(by=['gauge_num', 'year'], ascending=[True, True])\n",
    "# gauge_num= 0\n",
    "# this_gauge= nimrod_allevents_thisdur[nimrod_allevents_thisdur['gauge_num']==gauge_num]\n",
    "# this_gauge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
