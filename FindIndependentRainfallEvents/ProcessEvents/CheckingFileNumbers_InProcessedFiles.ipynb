{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5bf0a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# import re\n",
    "import pickle\n",
    "# import sys\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "# from shapely.geometry import Point\n",
    "\n",
    "# sys.path.insert(1, '../../../ProcessEvents')\n",
    "# from ProcessEventsFunctions import *\n",
    "# # from Convert_to_Profiles_Functions import *\n",
    "# # from Get_Events_Functions import *\n",
    "\n",
    "# Function to check for part1 in strings or lists of strings\n",
    "def does_not_contain_part0(x):\n",
    "    # Check if x is a string or a list of strings\n",
    "    if isinstance(x, str):\n",
    "        return 'part0' not in x\n",
    "    elif isinstance(x, list):\n",
    "        return any('part0' not in item for item in x)  # Ensure part1 is not in any item\n",
    "    return True  # If it's neither, we keep it\n",
    "\n",
    "\n",
    "def contains_part0(x):\n",
    "    # Check if x is a string or a list of strings\n",
    "    if isinstance(x, str):\n",
    "        return 'part0' in x\n",
    "    elif isinstance(x, list):\n",
    "        return any('part0' in item for item in x)\n",
    "    return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23ac738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/nfs/a319/gy17m2a/PhD/'\n",
    "home_dir2 = '/nfs/a161/gy17m2a/PhD/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa986fc7",
   "metadata": {},
   "source": [
    "## Check number of events when combined into the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cebc838",
   "metadata": {},
   "source": [
    "### Read  the processed data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a8452e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events_props_dict_present = []\n",
    "# ems_present = ['bc005', 'bc006', 'bc007', 'bc009', 'bc010', 'bc011', 'bc012', 'bc013', 'bc015', 'bc016', 'bc017', 'bc018']\n",
    "# for em in ems_present:\n",
    "#     with open(home_dir +  f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/event_props_dict_{em}.pickle\", 'rb') as handle:\n",
    "#         events_props_dict = pickle.load(handle)    \n",
    "#     events_props_dict_present = events_props_dict_present + events_props_dict\n",
    "# ## Join into one dataframe    \n",
    "# present_allevents = pd.DataFrame(events_props_dict_present)\n",
    "# present_allevents['Climate'] = 'Present'    \n",
    "\n",
    "events_props_dict_future = []\n",
    "ems_future = ['bb195'] # ['bb192', 'bb195', 'bb198', 'bb208', 'bb225','bb222', 'bb201', 'bb204', 'bb216', 'bb219', 'bb211'] # , \n",
    "for em in ems_future:\n",
    "    with open(home_dir +  f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/event_props_dict_{em}_new.pickle\", 'rb') as handle:\n",
    "        events_props_dict = pickle.load(handle)    \n",
    "    events_props_dict_future = events_props_dict_future + events_props_dict\n",
    "## Join into one dataframe    \n",
    "future_allevents = pd.DataFrame(events_props_dict_future)\n",
    "future_allevents['Climate'] = 'Future'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2181aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir +  f\"ProcessedData/AMAX_Events/NIMROD_30mins/event_props_dict.pickle\", 'rb') as handle:\n",
    "    events_props_dict_nimrod = pickle.load(handle)    \n",
    "    \n",
    "## Join into one dataframe    \n",
    "nimrod_allevents = pd.DataFrame(events_props_dict_nimrod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac76add",
   "metadata": {},
   "source": [
    "### Total number of events\n",
    "Different number of events each EM, because its all events, no duplicates, and number of events which are the AMAX for different durations will vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19191f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb198 92279\n"
     ]
    }
   ],
   "source": [
    "for em in ems_future:\n",
    "    # This is the TOTAL number of events\n",
    "    print(em, len([d for d in events_props_dict_future if d.get('em') == em]))\n",
    "    # This just does the same thing\n",
    "    # this_em = future_allevents[future_allevents['em']==em]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8bb15",
   "metadata": {},
   "source": [
    "## Checking the number of part0 events\n",
    "Get data for one em.  \n",
    "Get data for one duration.  \n",
    "Get data for one gauge, check if there are 19 events with part 0 in the string\n",
    "\n",
    "Part0 rows sometimes has more than one entry per year, for the same duration. This is presumably because of CAM. However it's confusing because in that case I might have expected the filename to be Part1, but its not. \n",
    "\n",
    "WE CAN NO LONGER USE FILENAME TO SORT BECAUSE IT ONLY REFERS TO ONE OF THE EVENTS REPRESENTED BY EACH ROW\n",
    "\n",
    "IF WANTED TO CHECK THIS ONCE AND FOR ALL, WOULD NEED TO IMPLEMENT SOMETHING IN PROCESSING FILE WHICH ASSIGNS THE FILENAME ROW WITH FLAGS FOR EACH DURATION AS TO WHETHER IT WAS A PART0 OR A PART1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "22839c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations =[0.5, 1,2,3,6,12,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f92af96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb195\n",
      "duration : 0.5\n",
      "24529 events for 0.5hrs\n",
      "duration : 1\n",
      "24529 events for 1hrs\n",
      "duration : 2\n",
      "24529 events for 2hrs\n",
      "duration : 3\n",
      "24529 events for 3hrs\n",
      "duration : 6\n",
      "24529 events for 6hrs\n",
      "duration : 12\n",
      "24529 events for 12hrs\n",
      "duration : 24\n",
      "24529 events for 24hrs\n"
     ]
    }
   ],
   "source": [
    "## Get data for one ensemble member\n",
    "for em in ['bb195']:\n",
    "    print(em)\n",
    "    this_em = future_allevents[future_allevents['em']==em].copy()\n",
    "    \n",
    "    ## Get data for one duration\n",
    "    for duration in durations:\n",
    "        print(f\"duration : {duration}\")\n",
    "        \n",
    "        #  Get events for just this duration\n",
    "        future_allevents_thisdur = this_em[this_em['dur_for_which_this_is_amax'].apply(\n",
    "            lambda x: isinstance(x, list) and str(duration) in x or x == str(duration))].copy()\n",
    "\n",
    "        # Convert all durations and filenames to a list, even if just one value\n",
    "        future_allevents_thisdur['filename'] = future_allevents_thisdur['filename'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "        future_allevents_thisdur['dur_for_which_this_is_amax'] = future_allevents_thisdur['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "        # Keep just the relevant filename for this duration\n",
    "        future_allevents_thisdur['index_of_this_dur'] = future_allevents_thisdur['dur_for_which_this_is_amax'].apply(\n",
    "            lambda x: x.index(str(duration)) if str(duration) in x else -1)\n",
    "        # Create a new column to extract the corresponding filename using the index\n",
    "        future_allevents_thisdur['corresponding_filename'] = future_allevents_thisdur.apply(\n",
    "            lambda row: row['filename'][row['index_of_this_dur']] if row['index_of_this_dur'] != -1 and row['index_of_this_dur'] < len(row['filename']) else None, axis=1)\n",
    "\n",
    "        ## Filter out the part1'ers\n",
    "        future_allevents_thisdur = future_allevents_thisdur[~future_allevents_thisdur['corresponding_filename'].str.contains(\"part1\", na=False)]\n",
    "        print(f\"{len(future_allevents_thisdur)} events for {duration}hrs\")\n",
    "\n",
    "        # Get data for one gauge, and find how many rows there are \n",
    "        # We would expect there to be 19\n",
    "        for gauge_num in range(0,1294):\n",
    "            if gauge_num not in [444,827,888]:\n",
    "                this_gauge= future_allevents_thisdur[future_allevents_thisdur['gauge_num']==gauge_num].copy()\n",
    "\n",
    "                if len(filtered_df) != 19:\n",
    "                    print(gauge_num, len(filtered_df))\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e0d45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Get data for one duration\n",
    "# for duration in durations:\n",
    "#     nimrod_allevents_thisdur = nimrod_allevents[nimrod_allevents['dur_for_which_this_is_amax'].apply(\n",
    "#         lambda x: isinstance(x, list) and str(duration) in x or x == str(duration))]\n",
    "#     nimrod_allevents_thisdur.sort_values(by=['gauge_num', 'year'], ascending=[True, True])\n",
    "#     print(f\"{len(nimrod_allevents_thisdur)} events for {duration}hrs\")\n",
    "\n",
    "#     # Get data for one gauge, and find how many rows there are \n",
    "#     # We would expect there to be 19\n",
    "#     for gauge_num in range(0,1294):\n",
    "#         if gauge_num not in [444,827,888]:\n",
    "#             this_gauge= nimrod_allevents_thisdur[nimrod_allevents_thisdur['gauge_num']==gauge_num]\n",
    "# #             print(gauge_num, len(this_gauge))\n",
    "#             if len(this_gauge) != 15:\n",
    "#                 print(gauge_num, len(this_gauge))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bbb67a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration = '1'\n",
    "# nimrod_allevents_thisdur = nimrod_allevents[nimrod_allevents['dur_for_which_this_is_amax'].apply(\n",
    "#     lambda x: isinstance(x, list) and str(duration) in x or x == str(duration))]\n",
    "# nimrod_allevents_thisdur.sort_values(by=['gauge_num', 'year'], ascending=[True, True])\n",
    "# gauge_num= 0\n",
    "# this_gauge= nimrod_allevents_thisdur[nimrod_allevents_thisdur['gauge_num']==gauge_num]\n",
    "# this_gauge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
