{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f639f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leading_and_trailing_zeroes(df, threshold = 0.005):\n",
    "    \n",
    "    # Identify the start and end of the event where values are above the threshold\n",
    "    event_start = df[df['precipitation (mm)'] >= threshold].index.min()\n",
    "    event_end = df[df['precipitation (mm)'] >= threshold].index.max()\n",
    "\n",
    "    # Handle cases where no values are above the threshold\n",
    "    if pd.isna(event_start) or pd.isna(event_end):\n",
    "        print(\"No events found with precipitation >= threshold.\")\n",
    "    else:\n",
    "        # Remove values < threshold from the start and end of the event\n",
    "        trimmed_test = df.loc[event_start:event_end].reset_index(drop=True)\n",
    "\n",
    "    return trimmed_test\n",
    "\n",
    "def process_events_alltogether(home_dir, time_period, ems, tb0_vals, save_dir):\n",
    "    events_dict = {}\n",
    "    event_props_ls = []\n",
    "    event_profiles_dict = {}\n",
    "\n",
    "    for em in ems:\n",
    "        print(em)\n",
    "        for gauge_num in range(0, 1294):\n",
    "            if gauge_num not in [444, 827, 888]:\n",
    "                if gauge_num % 100 == 0:\n",
    "                    print(f\"Processing gauge {gauge_num}\")\n",
    "                indy_events_fp = home_dir + f\"ProcessedData/IndependentEvents/UKCP18_30mins/{time_period}/{em}/{gauge_num}/WholeYear/EventSet/\"\n",
    "\n",
    "                files = [f for f in os.listdir(indy_events_fp) if f.endswith('.csv')]\n",
    "                files = np.sort(files)\n",
    "\n",
    "                for event_num, file in enumerate(files):\n",
    "                    fp = indy_events_fp + f\"{file}\"\n",
    "                    if '2080' in fp:\n",
    "                        continue\n",
    "\n",
    "                    # Get event\n",
    "                    this_event = read_event(gauge_num, fp)\n",
    "\n",
    "                    # Get times and precipitation values\n",
    "                    event_times = this_event['times']\n",
    "                    event_precip = this_event['precipitation (mm)']\n",
    "\n",
    "                    # Apply the function to adjust the dates in the 'times' column\n",
    "                    event_times_fixed = event_times.apply(adjust_feb_dates)\n",
    "\n",
    "                    # Create the DataFrame with corrected times\n",
    "                    event_df = pd.DataFrame({'precipitation (mm)': event_precip, 'times': event_times_fixed})\n",
    "                    # Remove leading and trailing zeroes\n",
    "                    event_df = remove_leading_and_trailing_zeroes(event_df)\n",
    "                    # Create characteristics dictionary\n",
    "                    event_props = create_event_characteristics_dict(event_df)\n",
    "\n",
    "                    # Add the duration\n",
    "                    event_props['dur_for_which_this_is_amax'] = get_dur_for_which_this_is_amax(fp)\n",
    "                    # Add gauge number and ensemble member\n",
    "                    event_props['gauge_num'] = gauge_num\n",
    "                    event_props['area'] = tb0_vals.iloc[gauge_num]['within_area']\n",
    "                    event_props['em'] = em\n",
    "                    event_props['filename'] = file\n",
    "\n",
    "                    ##########################################\n",
    "                    # Specify the keys you want to check\n",
    "                    keys_to_check = ['duration', 'year', 'gauge_num', 'month', 'Volume', 'max_intensity']\n",
    "\n",
    "                    # Extract the values for the specified keys from dict_to_check\n",
    "                    values_to_check = tuple(event_props[key] for key in keys_to_check)\n",
    "\n",
    "                    # Initialize a variable to store the found dictionary\n",
    "                    matched_dict = None\n",
    "\n",
    "                    # Check if a matching dictionary exists in the list based on the specified keys\n",
    "                    for index, d in enumerate(event_props_ls):\n",
    "                        if tuple(d[key] for key in keys_to_check) == values_to_check:\n",
    "                            matched_dict = d  # Store the matching dictionary\n",
    "                            break  # Exit the loop since we found a match\n",
    "\n",
    "                    if matched_dict:\n",
    "                        # print(\"A matching dictionary found:\", matched_dict, event_props)\n",
    "\n",
    "                        new_value = event_props['dur_for_which_this_is_amax']\n",
    "                        existing_value = matched_dict.get('dur_for_which_this_is_amax', '')\n",
    "                        # Create or update the value as a list\n",
    "                        if isinstance(existing_value, list):\n",
    "                            existing_value.append(new_value)\n",
    "                        else:\n",
    "                            existing_value = [existing_value, new_value]  # Convert existing string to list and add 'yes'\n",
    "                        matched_dict['dur_for_which_this_is_amax'] = existing_value\n",
    "\n",
    "                        event_props_ls[index]= matched_dict\n",
    "\n",
    "                    else:\n",
    "                        # print(\"No matching dictionary found in the list.\")\n",
    "\n",
    "                        ##########################################\n",
    "                        events_dict[f\"{em}, {gauge_num}, {event_num}\"] = event_df\n",
    "                        event_props_ls.append(event_props)\n",
    "                        event_profiles_dict[f\"{em}, {gauge_num}, {event_num}\"] = create_profiles_dict(event_df)\n",
    "\n",
    "        print(f\"Finished {em}\")                        \n",
    "        \n",
    "        with open(save_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/{time_period}/events_dict_{em}_newest.pickle\", 'wb') as handle:\n",
    "            pickle.dump(events_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(save_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/{time_period}/event_profiles_dict_{em}_newest.pickle\", 'wb') as handle:\n",
    "            pickle.dump(event_profiles_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(save_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/{time_period}/event_props_dict_{em}_newest.pickle\", 'wb') as handle:\n",
    "            pickle.dump(event_props_ls, handle, protocol=pickle.HIGHEST_PROTOCOL)                       \n",
    "\n",
    "    return events_dict, event_props_ls, event_profiles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbfeaa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from ProcessEventsFunctions import *\n",
    "sys.path.insert(1, 'Old')\n",
    "from Steef_Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "161cbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/nfs/a319/gy17m2a/PhD/'\n",
    "home_dir2 = '/nfs/a161/gy17m2a/PhD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412d55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "quintile_mapping = {1: 'F2', 2: 'F1', 3: 'C', 4: 'B1', 5: 'B2'}\n",
    "quintile_mapping_thirds = {1: 'F', 2: 'C', 3: 'B'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "285aba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbo_vals = pd.read_csv(home_dir + 'datadir/RainGauge/interarrival_thresholds_CDD_noMissing.txt')\n",
    "# Check if the points are within the areas\n",
    "tbo_vals = check_for_gauge_in_areas(tbo_vals, home_dir, ['NW', 'NE', 'ME', 'SE', 'SW'])\n",
    "tbo_vals.loc[tbo_vals['within_area'] == 'NW, C', 'within_area'] = 'NW'\n",
    "tbo_vals.loc[tbo_vals['within_area'] == 'ME, SE', 'within_area'] = 'ME'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d323ae47",
   "metadata": {},
   "source": [
    "### Define ensemble members for present and future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74ccd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ems_present = ['bc010']\n",
    "ems_future = ['bb189','bb192', 'bb195', 'bb198', 'bb201', 'bb204','bb208' ,'bb211','bb216', 'bb219','bb222','bb225']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7004fdf9",
   "metadata": {},
   "source": [
    "### Get events (considering one set of AMAX producing events (with duplicates deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c4db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc010\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc010\n"
     ]
    }
   ],
   "source": [
    "# # Now you can call the function for both time periods\n",
    "events_dict_present, event_props_dict_present, event_profiles_dict_present = process_events_alltogether(home_dir2, 'Present',ems_present, tbo_vals, home_dir)\n",
    "# events_dict_future, event_props_dict_future, event_profiles_dict_future = process_events_alltogether(home_dir2, 'Future', ems_future, tbo_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c0c5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/events_dict_present.pickle\", 'wb') as handle:\n",
    "    pickle.dump(events_dict_present, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/events_dict_future.pickle\", 'wb') as handle:\n",
    "    pickle.dump(events_dict_future, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/event_profiles_dict_present\", 'wb') as handle:\n",
    "    pickle.dump(event_profiles_dict_present, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/event_profiles_dict_future.pickle\", 'wb') as handle:\n",
    "    pickle.dump(event_profiles_dict_future, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/event_props_dict_present.pickle\", 'wb') as handle:\n",
    "    pickle.dump(event_props_dict_present, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/event_props_dict_future.pickle\", 'wb') as handle:\n",
    "    pickle.dump(event_props_dict_future, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c89f0",
   "metadata": {},
   "source": [
    "## Get events for each duration (there'll be cross over in events present for each duration)\n",
    "By duration here we mean the duration for which the AMAX are associated, rather than the actual duration of the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of desired durations\n",
    "valid_durations = [\"0.5\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"]\n",
    "\n",
    "# Process events for both time periods\n",
    "results_present = process_events_by_duration(home_dir2, 'Present', valid_durations, ems_present, tbo_vals)\n",
    "# results_future = process_events_by_duration('Future', valid_durations, ems_future, tbo_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26b135d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_present_events_dict, dur_present_event_props_dict, dur_present_event_profiles_dict = results_present\n",
    "# dur_future_events_dict, dur_future_event_props_dict, dur_future_event_profiles_dict = results_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0238ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/results_each_dur_present.pickle\", 'wb') as handle:\n",
    "    pickle.dump(results_present, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "# with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/results_each_dur_future.pickle\", 'wb') as handle:\n",
    "#     pickle.dump(results_future, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80729dcf",
   "metadata": {},
   "source": [
    "## Do we have the same number of results for each duration?\n",
    "I believe that longer durations have more events because of compound annual maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c060f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 2964\n",
      "1 2964\n",
      "2 2964\n",
      "3 2964\n",
      "6 2966\n",
      "12 3022\n",
      "24 3449\n"
     ]
    }
   ],
   "source": [
    "for duration in valid_durations:\n",
    "    print(duration, len(dur_present_event_props_dict[duration].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46e892c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc005\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc006\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc007\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc009\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc010\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc011\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc012\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc013\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc015\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc016\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc017\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc018\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb189\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb192\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb195\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb198\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb201\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb204\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb208\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb211\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb216\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb219\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb222\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb225\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n"
     ]
    }
   ],
   "source": [
    "# List of desired durations\n",
    "duration_bins = ['<4hr', '4-12hr', '12hr+']\n",
    "\n",
    "# Process events for both time periods\n",
    "results_present_dur_categories_simple = process_events_by_duration(home_dir2, 'Present', duration_bins, ems_present, tbo_vals)\n",
    "results_future_dur_categories_simple = process_events_by_duration(home_dir2, 'Future', duration_bins, ems_future, tbo_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a38ee9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/results_present_dur_categories_simple.pickle\", 'wb') as handle:\n",
    "    pickle.dump(results_present_dur_categories_simple, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/results_future_dur_categories_simple.pickle\", 'wb') as handle:\n",
    "    pickle.dump(results_future_dur_categories_simple, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
