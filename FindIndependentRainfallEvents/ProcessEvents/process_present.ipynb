{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69b528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from ProcessEventsFunctions import *\n",
    "# from Convert_to_Profiles_Functions import *\n",
    "# from Get_Events_Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b92481f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_events_alltogether(home_dir, time_period, ems, tb0_vals, save_dir):\n",
    "    events_dict = {}\n",
    "    event_props_ls = []\n",
    "    event_profiles_dict = {}\n",
    "\n",
    "    for em in ems:\n",
    "        print(em)\n",
    "        for gauge_num in range(0, 1293):\n",
    "            if gauge_num not in [444, 827, 888]:\n",
    "                if gauge_num % 100 == 0:\n",
    "                    print(f\"Processing gauge {gauge_num}\")\n",
    "                indy_events_fp = home_dir + f\"ProcessedData/IndependentEvents/UKCP18_30mins/{time_period}/{em}/{gauge_num}/WholeYear/\"\n",
    "\n",
    "                files = [f for f in os.listdir(indy_events_fp) if f.endswith('.csv')]\n",
    "                files = np.sort(files)\n",
    "\n",
    "                for event_num, file in enumerate(files):\n",
    "                    fp = indy_events_fp + f\"{file}\"\n",
    "                    if '2080' in fp:\n",
    "                        continue\n",
    "                    try:\n",
    "                        # Get event\n",
    "                        this_event = read_event(gauge_num, fp)\n",
    "\n",
    "                        # Get times and precipitation values\n",
    "                        event_times = this_event['times']\n",
    "                        event_precip = this_event['precipitation (mm)']\n",
    "\n",
    "                        # Apply the function to adjust the dates in the 'times' column\n",
    "                        event_times_fixed = event_times.apply(adjust_feb_dates)\n",
    "\n",
    "                        # Create the DataFrame with corrected times\n",
    "                        event_df = pd.DataFrame({'precipitation (mm)': event_precip, 'times': event_times_fixed})\n",
    "\n",
    "                        # Create characteristics dictionary\n",
    "                        event_props = create_event_characteristics_dict(event_df)\n",
    "\n",
    "                        # Add the duration\n",
    "                        event_props['dur_for_which_this_is_amax'] = get_dur_for_which_this_is_amax(fp)\n",
    "                        # Add gauge number and ensemble member\n",
    "                        event_props['gauge_num'] = gauge_num\n",
    "                        event_props['area'] = tb0_vals.iloc[gauge_num]['within_area']\n",
    "                        event_props['em'] = em\n",
    "                        event_props['filename'] = file\n",
    "\n",
    "                        event_profiles = create_profiles_dict(event_df)\n",
    "\n",
    "                        events_dict[f\"{em}, {gauge_num}, {event_num}\"] = event_df\n",
    "                        event_props_ls.append(event_props)\n",
    "                        event_profiles_dict[f\"{em}, {gauge_num}, {event_num}\"] = event_profiles\n",
    "                    except:\n",
    "                        print(fp)\n",
    "                        \n",
    "        print(f\"Finished {em}\")                        \n",
    "        \n",
    "        with open(save_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/events_dict_present.pickle\", 'wb') as handle:\n",
    "            pickle.dump(events_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(save_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/event_profiles_dict_present\", 'wb') as handle:\n",
    "            pickle.dump(event_profiles_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(save_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/event_props_dict_present.pickle\", 'wb') as handle:\n",
    "            pickle.dump(event_props_ls, handle, protocol=pickle.HIGHEST_PROTOCOL)                       \n",
    "\n",
    "    return events_dict, event_props_ls, event_profiles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd098644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc005\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc005\n",
      "bc006\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc006\n",
      "bc007\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc007\n",
      "bc009\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc009\n",
      "bc010\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc010\n",
      "bc011\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc011\n",
      "bc012\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc012\n",
      "bc013\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc013\n",
      "bc015\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc015\n",
      "bc016\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc016\n",
      "bc017\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc017\n",
      "bc018\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "Finished bc018\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19426/462649308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mevents_dict_present\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_props_dict_present\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_profiles_dict_present\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_events_alltogether\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_dir2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Present'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mems_present\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtbo_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhome_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/events_dict_present.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_dir' is not defined"
     ]
    }
   ],
   "source": [
    "sys.path.insert(1, 'Old')\n",
    "from Steef_Functions import *\n",
    "\n",
    "home_dir = '/nfs/a319/gy17m2a/PhD/'\n",
    "home_dir2 = '/nfs/a161/gy17m2a/PhD/'\n",
    "\n",
    "quintile_mapping = {1: 'F2', 2: 'F1', 3: 'C', 4: 'B1', 5: 'B2'}\n",
    "quintile_mapping_thirds = {1: 'F', 2: 'C', 3: 'B'}\n",
    "\n",
    "tbo_vals = pd.read_csv(home_dir + 'datadir/RainGauge/interarrival_thresholds_CDD_noMissing.txt')\n",
    "# tbo_vals = tbo_vals[tbo_vals['Lon']!=-999.0]\n",
    "# Check if the points are within the areas\n",
    "tbo_vals = check_for_gauge_in_areas(tbo_vals, home_dir, ['NW', 'NE', 'ME', 'SE', 'SW'])\n",
    "tbo_vals.loc[tbo_vals['within_area'] == 'NW, C', 'within_area'] = 'NW'\n",
    "tbo_vals.loc[tbo_vals['within_area'] == 'ME, SE', 'within_area'] = 'ME'\n",
    "tbo_vals['within_area'].unique()\n",
    "\n",
    "ems_present = ['bc005', 'bc006', 'bc007', 'bc009', 'bc010', 'bc011', 'bc012', 'bc013', 'bc015', 'bc016', 'bc017', 'bc018']\n",
    "\n",
    "# # Now you can call the function for both time periods\n",
    "events_dict_present, event_props_dict_present, event_profiles_dict_present = process_events_alltogether(home_dir2, 'Present',ems_present, tbo_vals, home_dir)\n",
    "\n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/events_dict_present.pickle\", 'wb') as handle:\n",
    "    pickle.dump(events_dict_present, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/event_profiles_dict_present\", 'wb') as handle:\n",
    "    pickle.dump(event_profiles_dict_present, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/event_props_dict_present.pickle\", 'wb') as handle:\n",
    "    pickle.dump(event_props_dict_present, handle, protocol=pickle.HIGHEST_PROTOCOL)            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
