{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Imports\n",
    "# =========================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Funtions\n",
    "# =========================================================\n",
    "\n",
    "class precip_time_series:\n",
    "    def __init__(self, data_path):\n",
    "\n",
    "        self.data,self.statid = self.read_raw_data_as_pandas_df(data_path)\n",
    "        \n",
    "        self.padded = False\n",
    "\n",
    "        self.events = None\n",
    "        \n",
    "        self.dimensioneless_curves = None\n",
    "        \n",
    "    def read_raw_data_as_pandas_df(self, raw_data_file_path):\n",
    "\n",
    "        # Read file with timestamp as index\n",
    "        precip = pd.read_csv(raw_data_file_path, encoding=\"ISO-8859-1\",index_col=1)\n",
    "\n",
    "        # Timestamps str -> datetime\n",
    "        precip.index = pd.to_datetime(precip.index)\n",
    "\n",
    "        # Save ID of station\n",
    "        station_id = str(precip.station.iloc[0])\n",
    "\n",
    "        # Remove column with station ID\n",
    "        precip = precip.drop(\"station\",axis=1) \n",
    "\n",
    "        return precip,station_id\n",
    "    \n",
    "    def return_specific_event(self,event_idx):\n",
    "\n",
    "        # Size of timesteps\n",
    "        time_delta = self.data.index[1] - self.data.index[0]\n",
    "        time_delta_minutes = time_delta.seconds / 60\n",
    "\n",
    "        # Extract event data\n",
    "        event = self.data.loc[self.events[event_idx][0]:self.events[event_idx][1]]\n",
    "\n",
    "        return event        \n",
    "\n",
    "    def pad_and_resample(self,freq = '5min',pad_value = 0):\n",
    "        # Resample the data to the specified frequency and pad missing values with pad_value\n",
    "        self.data = self.data.resample(freq).sum().fillna(pad_value)\n",
    "        self.padded = True\n",
    "\n",
    "    def get_events(self,threshold='11h',min_duration = 30, min_precip = 1):\n",
    "        \n",
    "        if not self.padded:\n",
    "            self.pad_and_resample()\n",
    "\n",
    "        self.init_events(threshold)\n",
    "        self.filter_events_by_length(min_duration)\n",
    "        self.filter_events_by_amount(min_precip)\n",
    "\n",
    "    def init_events(self,threshold):\n",
    "        \n",
    "        precip = self.data\n",
    "        \n",
    "        # Size of timesteps\n",
    "        time_delta = precip.index[1]-precip.index[0]\n",
    "\n",
    "        # Rolling 11 hour sum\n",
    "        precip_sum = precip.rolling(threshold).sum()\n",
    "\n",
    "        # dates with no precip last 11 hours\n",
    "        dates_w_zero_sum = precip_sum.index[(precip_sum.mask(precip_sum!=0)==precip_sum).values[:,0]]\n",
    "\n",
    "        # Add first date with rain\n",
    "        for date in precip.index:\n",
    "            if precip.loc[date].values[0] != 0:\n",
    "                start_dates = [date]\n",
    "                break\n",
    "\n",
    "        # Save start and end dates\n",
    "        end_dates   = []\n",
    "        for date in tqdm(dates_w_zero_sum):\n",
    "            if precip_sum.loc[date- time_delta].values[0]!=0:\n",
    "                end_dates += [date- pd.to_timedelta(threshold)]\n",
    "            if precip_sum.loc[date+ time_delta].values[0]!=0:\n",
    "                start_dates += [date+ time_delta]\n",
    "        \n",
    "        # Add end to last event\n",
    "        for date in reversed(precip.index):  # Iterate from last to first\n",
    "            if precip.loc[date].values[0] != 0:  # Check if value is not zero\n",
    "                end_dates += [date]\n",
    "                break  # Stop at the first nonzero value\n",
    "        \n",
    "        # Save events as list of tuples\n",
    "        events = []\n",
    "        for i in range(len(end_dates)):\n",
    "            events+=[(start_dates[i],end_dates[i])]\n",
    "\n",
    "        # update events\n",
    "        self.events = events\n",
    "\n",
    "    def filter_events_by_length(self,min_duration):\n",
    "        \n",
    "        # Remove events with duration under min duration\n",
    "        filtered_events = [event for event in self.events if event[1]-event[0]>=pd.Timedelta(minutes=min_duration)]\n",
    "\n",
    "        # Update events\n",
    "        self.events = filtered_events\n",
    "    \n",
    "    def filter_events_by_amount(self,min_precip):\n",
    "        \n",
    "        # Remove events with total precip under minimum\n",
    "        filtered_events = [event for event in self.events if self.data.loc[event[0]:event[1]].sum().values[0]>=min_precip]\n",
    "        \n",
    "        # update events\n",
    "        self.events = filtered_events\n",
    "\n",
    "    def create_dimensioneless_curves(self):\n",
    "\n",
    "        # Make sure events have been computed\n",
    "        if self.events == None:\n",
    "            self.get_events()\n",
    "        \n",
    "        # Make list of nparrays containing the values of the dimensioneless curve\n",
    "        dimensioneless_curves = [self.get_dimensioneless_curve(self.data.loc[event[0]:event[1]].values) for event in self.events]\n",
    "\n",
    "        # Assign to global value\n",
    "        self.dimensioneless_curves = dimensioneless_curves\n",
    "\n",
    "    def get_dimensioneless_curve(self,series):\n",
    "    \n",
    "        # Calculate cumulative rainfall\n",
    "        cumulative_rainfall = np.cumsum(series)\n",
    "        cumulative_rainfall = np.append([0],cumulative_rainfall)\n",
    "\n",
    "        # normalize\n",
    "        normalized_cumulative_rainfall = cumulative_rainfall/cumulative_rainfall[-1]\n",
    "\n",
    "        return normalized_cumulative_rainfall\n",
    "\n",
    "\n",
    "\n",
    "class rainfall_analysis:\n",
    "    def __init__(self,ts: precip_time_series):\n",
    "        self.ts = ts\n",
    "        self.metrics = {} \n",
    "        \n",
    "        # Prepere ts for analysis\n",
    "        if not self.ts.padded:\n",
    "            ts.pad_and_resample()\n",
    "\n",
    "        if ts.events == None:\n",
    "            ts.get_events()\n",
    "        \n",
    "        if ts.dimensioneless_curves == None:\n",
    "            ts.create_dimensioneless_curves()\n",
    "\n",
    "    def huff_quantile(self,ts):\n",
    "      \n",
    "        sums = self.split_ts_sum(ts,4)\n",
    "\n",
    "        quantile = np.argmax(sums)+1\n",
    "\n",
    "        return quantile\n",
    "\n",
    "\n",
    "    def interpolate_rainfall(self, ts, bin_number):\n",
    "        if rainfall is None or len(ts) < 2:\n",
    "            return None\n",
    "\n",
    "        # Define target points for bin_number bins\n",
    "        target_points = np.linspace(0, 1, bin_number+1)\n",
    "\n",
    "        # Create interpolation function based on existing data points\n",
    "        rainfall_times = np.array(range(0, len(ts)))\n",
    "\n",
    "        # Normalize time from 0 to 1\n",
    "        normalized_time = (rainfall_times - rainfall_times[0]) / (rainfall_times[-1] - rainfall_times[0])\n",
    "        interpolation_func = interp1d(normalized_time, ts, kind='linear', fill_value=\"extrapolate\")\n",
    "\n",
    "        # Interpolate values at target points\n",
    "        interpolated_values = interpolation_func(target_points)\n",
    "\n",
    "        return interpolated_values, target_points    \n",
    "\n",
    "    \n",
    "    def split_ts_sum(self,ts,num):\n",
    "        \n",
    "        # if list length divisible by num, equal split trivial\n",
    "        if len(ts) % num == 0:\n",
    "            splits = np.array_split(ts.values,num)\n",
    "            sums = [split.sum() for split in splits]\n",
    "            \n",
    "            return sums\n",
    "        \n",
    "        # Find temporal resolution of data\n",
    "        time_delta = ts.index[1]-ts.index[0]\n",
    "        time_delta_minuts = time_delta.seconds/60\n",
    "\n",
    "        # When does recording start and end\n",
    "        ts_start = ts.index[0]-time_delta\n",
    "        ts_end   = ts.index[-1]\n",
    "\n",
    "        # Find the num+1 timestamps between which the num equal length splits are defined\n",
    "        time_splits = pd.date_range(start=ts_start, end=ts_end, periods=num+1)\n",
    "\n",
    "        # Init list for saving splits\n",
    "        list_of_splits = []\n",
    "\n",
    "        for i in range(num+1):\n",
    "            # first and last split timestamp, is just edges of entire array and is not needed\n",
    "            if i != 0 and i!= num:\n",
    "                \n",
    "                # Find closest previous and next x-minute marks\n",
    "                prev_time = time_splits[i].floor(f\"{time_delta_minuts}min\")  \n",
    "                next_time = time_splits[i].ceil(f\"{time_delta_minuts}min\")   \n",
    "                mid_time = prev_time + pd.Timedelta(minutes=time_delta_minuts)  \n",
    "\n",
    "                # if next time = prevtime, no need to interpolate\n",
    "                if next_time == prev_time:\n",
    "                    \n",
    "                    # ts1 is the ts before split point\n",
    "                    ts1 = ts[ts.index < time_splits[i]].values\n",
    "\n",
    "                    # ts is updated by removing t1\n",
    "                    ts = ts[ts.index >= time_splits[i]]\n",
    "\n",
    "                    # List is updated\n",
    "                    list_of_splits +=[ ts1]\n",
    "                else:\n",
    "                    # Value that should be split\n",
    "                    mid_value = ts.loc[mid_time].values\n",
    "\n",
    "                    # weight of value for each split\n",
    "                    total_interval = (next_time - prev_time).total_seconds()\n",
    "                    weight_prev = (next_time - time_splits[i]).total_seconds() / total_interval\n",
    "                    weight_next = (time_splits[i] - prev_time).total_seconds() / total_interval\n",
    "\n",
    "                    # ts1 is the ts before split point\n",
    "                    ts1 = ts[ts.index < time_splits[i]]\n",
    "  \n",
    "                    # add value from folliwing timestep\n",
    "                    ts1 = np.append(ts1.values,weight_prev*mid_value)\n",
    "                    \n",
    "                    # ts is updated by removing t1\n",
    "                    ts = ts[ts.index > time_splits[i]]\n",
    "\n",
    "                    # Value beloning to previous split is removed from ts\n",
    "                    ts = ts.copy()\n",
    "                    ts.iloc[0] -= weight_prev * mid_value\n",
    "\n",
    "                    # list of splits is updated\n",
    "                    list_of_splits +=[ ts1]\n",
    "        \n",
    "        # Add last split to list\n",
    "        list_of_splits +=[ ts.values[:,0]]\n",
    "        \n",
    "        # compute sum of each split\n",
    "        sums = [split.sum() for split in list_of_splits]\n",
    "     \n",
    "        return sums\n",
    "\n",
    "\n",
    "    def get_metrics(self):\n",
    "\n",
    "        padded_precip = self.ts.data\n",
    "        events_list = self.ts.events\n",
    "\n",
    "        # resolution    \n",
    "        time_delta = padded_precip.index[1]-padded_precip.index[0]\n",
    "        time_delta_minuts = time_delta.seconds/60\n",
    "\n",
    "        #####################################\n",
    "        # Properties of Events to calculate\n",
    "        #####################################\n",
    "\n",
    "\n",
    "        #####################################\n",
    "        # Rainfall metrics\n",
    "        #####################################\n",
    "\n",
    "        # huff quantiles\n",
    "        self.metrics[\"huff_quantile\"] = np.array([[self.huff_quantile(padded_precip[event[0]:event[1]])] for event in events_list])\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Input\n",
    "# =========================================================\n",
    "\n",
    "# Path to data file\n",
    "raw_data_file =  \"/nfs/a319/gy17m2a/PhD/datadir/DanishRainData/Sample1.csv\"\n",
    "\n",
    "# =========================================================\n",
    "# Script\n",
    "# =========================================================\n",
    "\n",
    "# Load ts\n",
    "ts = precip_time_series(raw_data_file)\n",
    "\n",
    "# pad and resample \n",
    "ts.pad_and_resample('5min')\n",
    "\n",
    "# Get filtered events\n",
    "#ts.get_events()\n",
    "\n",
    "# Get dimensioneless curves\n",
    "#ts.create_dimensioneless_curves()\n",
    "\n",
    "# # Analysis\n",
    "analysis = rainfall_analysis(ts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
