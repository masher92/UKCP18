{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbfeaa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from ProcessEventsFunctions import *\n",
    "# from Convert_to_Profiles_Functions import *\n",
    "# from Get_Events_Functions import *\n",
    "\n",
    "sys.path.insert(1, 'Old')\n",
    "from Steef_Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161cbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/nfs/a319/gy17m2a/PhD/'\n",
    "home_dir2 = '/nfs/a161/gy17m2a/PhD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "412d55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "quintile_mapping = {1: 'F2', 2: 'F1', 3: 'C', 4: 'B1', 5: 'B2'}\n",
    "quintile_mapping_thirds = {1: 'F', 2: 'C', 3: 'B'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1c893081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ME', 'SE', 'NE', 'NW', 'SW'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbo_vals = pd.read_csv(home_dir + 'datadir/RainGauge/interarrival_thresholds_CDD_noMissing.txt')\n",
    "tbo_vals = tbo_vals[tbo_vals['Lon']!=-999.0]\n",
    "# Check if the points are within the areas\n",
    "tbo_vals = check_for_gauge_in_areas(tbo_vals, home_dir, ['NW', 'NE', 'ME', 'SE', 'SW'])\n",
    "tbo_vals.loc[tbo_vals['within_area'] == 'NW, C', 'within_area'] = 'NW'\n",
    "tbo_vals.loc[tbo_vals['within_area'] == 'ME, SE', 'within_area'] = 'ME'\n",
    "tbo_vals['within_area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb903ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a plot with shapes\n",
    "# fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "# # Plot the shapefiles\n",
    "# shape = gpd.read_file(home_dir + 'datadir/SpatialData/RoughExtremeRainfallRegions/SW.shp')\n",
    "# shape.plot(ax=ax, color='lightblue', edgecolor='black', label='SW')\n",
    "\n",
    "# shape2 = gpd.read_file(home_dir + 'datadir/SpatialData/RoughExtremeRainfallRegions/NW.shp')\n",
    "# shape2.plot(ax=ax, color='lightgreen', edgecolor='black', label='NW')\n",
    "\n",
    "# shape3 = gpd.read_file(home_dir + 'datadir/SpatialData/RoughExtremeRainfallRegions/SE.shp')\n",
    "# shape3.plot(ax=ax, color='lightcoral', edgecolor='black', label='SE')\n",
    "\n",
    "# shape4 = gpd.read_file(home_dir + f'datadir/SpatialData/RoughExtremeRainfallRegions/{\"ME\"}.shp')\n",
    "# shape4.plot(ax=ax)\n",
    "# shape5 = gpd.read_file(home_dir + f'datadir/SpatialData/RoughExtremeRainfallRegions/{\"NE\"}.shp')\n",
    "# shape5.plot(ax=ax)\n",
    "\n",
    "\n",
    "# # Extract the point geometry from tbo_vals\n",
    "# geom = tbo_vals.iloc[651]['geometry']\n",
    "\n",
    "# # Convert the point to a GeoDataFrame to plot it\n",
    "# point_gdf = gpd.GeoDataFrame(geometry=[geom], crs=\"EPSG:4326\")  # Assuming EPSG:4326 for lat/lon\n",
    "# point_gdf.plot(ax=ax, marker='o', color='red', markersize=50)\n",
    "\n",
    "# geom = tbo_vals.iloc[642]['geometry']\n",
    "\n",
    "# # Convert the point to a GeoDataFrame to plot it\n",
    "# point_gdf = gpd.GeoDataFrame(geometry=[geom], crs=\"EPSG:4326\")  # Assuming EPSG:4326 for lat/lon\n",
    "# point_gdf.plot(ax=ax, marker='o', color='red', markersize=50)\n",
    "\n",
    "# geom = tbo_vals.iloc[639]['geometry']\n",
    "\n",
    "# # Convert the point to a GeoDataFrame to plot it\n",
    "# point_gdf = gpd.GeoDataFrame(geometry=[geom], crs=\"EPSG:4326\")  # Assuming EPSG:4326 for lat/lon\n",
    "# point_gdf.plot(ax=ax, marker='o', color='red', markersize=50)\n",
    "\n",
    "# geom = tbo_vals.iloc[452]['geometry']\n",
    "\n",
    "# # Convert the point to a GeoDataFrame to plot it\n",
    "# point_gdf = gpd.GeoDataFrame(geometry=[geom], crs=\"EPSG:4326\")  # Assuming EPSG:4326 for lat/lon\n",
    "# point_gdf.plot(ax=ax, marker='o', color='red', markersize=50)\n",
    "\n",
    "# geom = tbo_vals.iloc[44]['geometry']\n",
    "\n",
    "# # Convert the point to a GeoDataFrame to plot it\n",
    "# point_gdf = gpd.GeoDataFrame(geometry=[geom], crs=\"EPSG:4326\")  # Assuming EPSG:4326 for lat/lon\n",
    "# point_gdf.plot(ax=ax, marker='o', color='red', markersize=50)\n",
    "\n",
    "# geom = tbo_vals.iloc[859]['geometry']\n",
    "\n",
    "# # Convert the point to a GeoDataFrame to plot it\n",
    "# point_gdf = gpd.GeoDataFrame(geometry=[geom], crs=\"EPSG:4326\")  # Assuming EPSG:4326 for lat/lon\n",
    "# point_gdf.plot(ax=ax, marker='o', color='red', markersize=50,)\n",
    "\n",
    "\n",
    "\n",
    "# # Add legend and show plot\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d323ae47",
   "metadata": {},
   "source": [
    "### Define ensemble members for present and future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b74ccd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ems_present = ['bc005', 'bc006', 'bc007', 'bc009', 'bc010', 'bc011', 'bc012', 'bc013', 'bc015', 'bc016', 'bc017', 'bc018']\n",
    "ems_future = ['bb189','bb192', 'bb195', 'bb198', 'bb201', 'bb204','bb208' ,'bb211','bb216', 'bb219','bb222','bb225']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7004fdf9",
   "metadata": {},
   "source": [
    "### Get events (considering one set of AMAX producing events (with duplicates deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe482268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(result_df['within_area'])\n",
    "# result_df[result_df['within_area'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9d0a9f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc005\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc006\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc007\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc009\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc010\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc011\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc012\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc013\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc015\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc016\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc017\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bc018\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb189\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb192\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb195\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb198\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb201\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb204\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb208\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb211\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb216\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb219\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb222\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n",
      "bb225\n",
      "Processing gauge 0\n",
      "Processing gauge 100\n",
      "Processing gauge 200\n",
      "Processing gauge 300\n",
      "Processing gauge 400\n",
      "Processing gauge 500\n",
      "Processing gauge 600\n",
      "Processing gauge 700\n",
      "Processing gauge 800\n",
      "Processing gauge 900\n",
      "Processing gauge 1000\n",
      "Processing gauge 1100\n",
      "Processing gauge 1200\n"
     ]
    }
   ],
   "source": [
    "# # Now you can call the function for both time periods\n",
    "events_dict_present, event_props_dict_present, event_profiles_dict_present = process_events_alltogether(home_dir2, 'Present',ems_present, tbo_vals)\n",
    "events_dict_future, event_props_dict_future, event_profiles_dict_future = process_events_alltogether(home_dir2, 'Future', ems_future, tbo_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "03d7f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_events =  {key: value for key, value in event_props_dict_present.items() if value['area'] == 'ME'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4c0c5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/events_dict_present.pickle\", 'wb') as handle:\n",
    "    pickle.dump(events_dict_present, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/events_dict_future.pickle\", 'wb') as handle:\n",
    "    pickle.dump(events_dict_future, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/event_profiles_dict_present\", 'wb') as handle:\n",
    "    pickle.dump(event_profiles_dict_present, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/event_profiles_dict_future.pickle\", 'wb') as handle:\n",
    "    pickle.dump(event_profiles_dict_future, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/event_props_dict_present.pickle\", 'wb') as handle:\n",
    "    pickle.dump(event_props_dict_present, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/event_props_dict_future.pickle\", 'wb') as handle:\n",
    "    pickle.dump(event_props_dict_future, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c89f0",
   "metadata": {},
   "source": [
    "### Get events for each duration (there will be some cross over in the events present for each duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "449b0cdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "process_events_by_duration() missing 1 required positional argument: 'tb0_vals'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10449/2563516747.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Process events for both time periods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresults_present\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_events_by_duration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_dir2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Present'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_durations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mems_present\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# results_future = process_events_by_duration('Future', valid_durations, ems_future)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: process_events_by_duration() missing 1 required positional argument: 'tb0_vals'"
     ]
    }
   ],
   "source": [
    "# List of desired durations\n",
    "valid_durations = [\"0.5\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"]\n",
    "\n",
    "# Process events for both time periods\n",
    "results_present = process_events_by_duration(home_dir2, 'Present', valid_durations, ems_present)\n",
    "# results_future = process_events_by_duration('Future', valid_durations, ems_future)\n",
    "\n",
    "# You can access results like this:\n",
    "# results_present[0.5]  # Events with a duration of 0.5 hours for Present\n",
    "# results_future[1]     # Events with a duration of 1 hour for Future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b135d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_present_events_dict, dur_present_event_props_dict, dur_present_event_profiles_dict = results_present\n",
    "# dur_future_events_dict, dur_future_event_props_dict, dur_future_event_profiles_dict = results_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0238ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/results_each_dur_present.pickle\", 'wb') as handle:\n",
    "    pickle.dump(results_present, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "# with open(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/results_each_dur_future.pickle\", 'wb') as handle:\n",
    "#     pickle.dump(results_future, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80729dcf",
   "metadata": {},
   "source": [
    "## Do we have the same number of results for each duration?\n",
    "I think we should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c060f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for duration in valid_durations:\n",
    "    print(duration, len(dur_present_event_props_dict[duration].keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
