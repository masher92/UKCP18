{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a8f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ran for eveything now with excluding the gauges that we don't want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3871500",
   "metadata": {},
   "source": [
    "# Create a set of dimensionless profiles\n",
    "Read in all of the events, for all durations, for all gauges, for all ensemble members.  \n",
    "Convert them to dimensionless profiles, with 12 values between 0 and 1.  \n",
    "Each value is a dimensionless, cumulative rainfall value (cumulative rainfall at this timestep, normalised by the total event rainfall):\n",
    "- 0 means no rainfall has occurred, and \n",
    "- 1 means the total event rainfall has been reached.  \n",
    "\n",
    "If there are less than 12 values, then these are filled in with interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a902314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from Create_Profiles_Functions import *\n",
    "\n",
    "quintile_mapping = {1: 'F2', 2: 'F1', 3: 'C', 4: 'B1', 5: 'B2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa7befee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalised_intensity(array_in, len_out):\n",
    "    len_in = len(array_in)\n",
    "    # Calculates the total accumulated value at each original point\n",
    "    # Adds a zero at the start of the array\n",
    "    csum = np.cumsum(np.hstack((np.array([0.0]), array_in)))\n",
    "    # Normalise accumulation to 0 to 1\n",
    "    csum = csum / csum[-1]\n",
    "    # Array going from 0 up to 1: normalised time\n",
    "    # corresponding to these points\n",
    "    normalised_time_in = np.arange(len_in + 1) / (1.0 * len_in)\n",
    "    # Array of the \"time points\" corresponding to\n",
    "    # Boundaries of output intervals\n",
    "    normalised_time_out = np.arange(len_out + 1) / (1.0 * len_out)\n",
    "    # Interpolate total accumulated value to desired output points\n",
    "    csum_out = np.interp(normalised_time_out, normalised_time_in, csum)\n",
    "    # Interpolate back to accumulations over the desired number of intervals\n",
    "    # Scale with the number of points to normalise\n",
    "    normalised_intensity = (csum_out[1:] - csum_out[:-1]) * len_out\n",
    "    return normalised_intensity\n",
    "\n",
    "def analyse_event(array_in):\n",
    "    # Remove leading/trailing zeros from array\n",
    "    # can we always do this?\n",
    "    trimmed_array = np.trim_zeros(array_in)\n",
    "    # Go from raw data directly to 12 and 5 points\n",
    "    event_curve_12 = get_normalised_intensity(trimmed_array, 12)\n",
    "    event_curve_12 = np.append([0], event_curve_12)\n",
    "    event_curve_12 = np.append(event_curve_12, [0])    \n",
    "    \n",
    "    event_curve_5 = get_normalised_intensity(trimmed_array, 5)\n",
    "    # Get the category as a number from 1 to 5\n",
    "    # add 1 as python indexing starts at 0\n",
    "    category = np.argmax(event_curve_5) + 1\n",
    "    return category, event_curve_12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc964ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_rainfall(rainfall, bin_number):\n",
    "    if rainfall is None or len(rainfall) < 2:\n",
    "        return None\n",
    "\n",
    "    # Define target points for bin_number bins\n",
    "    target_points = np.linspace(0, 1, bin_number+1)\n",
    "    \n",
    "    # Create interpolation function based on existing data points\n",
    "    rainfall_times = np.array(range(0, len(rainfall)))\n",
    "\n",
    "    # Normalize time from 0 to 1\n",
    "    normalized_time = (rainfall_times - rainfall_times[0]) / (rainfall_times[-1] - rainfall_times[0])\n",
    "    interpolation_func = interp1d(normalized_time, rainfall, kind='linear', fill_value=\"extrapolate\")\n",
    "    \n",
    "    # Interpolate values at target points\n",
    "    interpolated_values = interpolation_func(target_points)\n",
    "    \n",
    "    return interpolated_values, target_points\n",
    "\n",
    "def create_cumulative_event(rainfall, interval=0.5):\n",
    "    if rainfall is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Calculate cumulative rainfall\n",
    "    cumulative_rainfall = np.cumsum(rainfall)\n",
    "    cumulative_rainfall = [0] + cumulative_rainfall\n",
    "    \n",
    "    # Generate corresponding time points\n",
    "    time_points = np.arange(0, len(rainfall) + 1) * interval\n",
    "    \n",
    "    return  [0] + cumulative_rainfall.tolist(), time_points.tolist()\n",
    "\n",
    "def create_dimensionless_event(cumulative_rainfall, cumulative_rainfall_times):\n",
    "\n",
    "    # Step 3: Normalize the cumulative rainfall by the total event depth\n",
    "    total_event_depth = cumulative_rainfall[-1]\n",
    "    normalized_cumulative_rainfall = np.array(cumulative_rainfall) / total_event_depth\n",
    "\n",
    "    total_event_time = cumulative_rainfall_times[-1]\n",
    "    normalized_cumulative_rainfall_times = np.array(cumulative_rainfall_times) / total_event_time\n",
    "    normalized_cumulative_rainfall_times\n",
    "    \n",
    "    return normalized_cumulative_rainfall, normalized_cumulative_rainfall_times\n",
    "\n",
    "\n",
    "def find_intensity_as_proportion_of_mean_event(incremental_rainfall):\n",
    "    mean_over_event = np.mean(incremental_rainfall)\n",
    "    irain = incremental_rainfall/np.mean(incremental_rainfall)\n",
    "    return irain\n",
    "\n",
    "\n",
    "def create_incremental_event(cumulative_rainfall):\n",
    "    if cumulative_rainfall is None :\n",
    "        return None\n",
    "    raw_rainfall = np.diff(cumulative_rainfall, prepend=0)\n",
    "    return raw_rainfall[1:]\n",
    "\n",
    "\n",
    "def find_max_quintile (precip):\n",
    "    if precip is None:\n",
    "        return None\n",
    "    else:\n",
    "        cumulative_rainfall, cumulative_rainfall_times = create_cumulative_event(precip)\n",
    "        dimensionless_cumulative_rainfall, dimensionless_times =  create_dimensionless_event(cumulative_rainfall, cumulative_rainfall_times)\n",
    "        interpolated5_cumulative_rainfall, interpolated5_times = interpolate_rainfall(dimensionless_cumulative_rainfall,5)\n",
    "        interpolated5_incremental_rainfall = create_incremental_event(interpolated5_cumulative_rainfall)\n",
    "        max_quintile_profile_5 = find_part_with_most_rain(interpolated5_incremental_rainfall, 5)\n",
    "        return max_quintile_profile_5\n",
    "    \n",
    "def create_irain_profile(precip, bins =12 ):\n",
    "    cumulative_rainfall, cumulative_rainfall_times = create_cumulative_event(precip)\n",
    "    dimensionless_cumulative_rainfall, dimensionless_times =  create_dimensionless_event(cumulative_rainfall, cumulative_rainfall_times)\n",
    "    interpolated_cumulative_rainfall, interpolated_times = interpolate_rainfall(dimensionless_cumulative_rainfall,bins)\n",
    "    interpolated_incremental_rainfall = create_incremental_event(interpolated_cumulative_rainfall)\n",
    "\n",
    "    irain = find_intensity_as_proportion_of_mean_event(interpolated_incremental_rainfall)\n",
    "    irain = np.append([0], irain)\n",
    "    irain = np.append(irain, [0])    \n",
    "    \n",
    "    len_intensity = len(irain)\n",
    "    # Time points: start of event, end of event, midpoint of the intervals\n",
    "    times = np.hstack((np.array([0.0]),\n",
    "            (np.arange(len_intensity) + 0.5) / len_intensity,\n",
    "            np.array([1.0])))\n",
    "    \n",
    "    return irain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f9a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_nums = range(0,1294)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde96374",
   "metadata": {},
   "source": [
    "# UKCP18\n",
    "### Make and pickle profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae9b01d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gauge 0\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 100\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 200\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 300\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 400\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 500\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 600\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 700\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 800\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 900\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 1000\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 1100\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Processing gauge 1200\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n",
      "Some dates were invalid and have been coerced to NaT:\n"
     ]
    }
   ],
   "source": [
    "def create_dataframe_row(this_event):\n",
    "    # Trim the event and remove problematic events\n",
    "    trimmed_event = remove_leading_and_trailing_zeroes(this_event)\n",
    "    real_trimmed_event, problem_events = remove_events_with_problems(trimmed_event, verbose=False)\n",
    "    \n",
    "    if real_trimmed_event is None:\n",
    "        return {\n",
    "        'precip':None,\n",
    "        'times': None,\n",
    "        \"season\" : get_season(trimmed_event['times'][0]),\n",
    "        'duration':None,\n",
    "        \"year\":extract_year(trimmed_event),\n",
    "        'Volume': None,\n",
    "    }\n",
    "    \n",
    "    # Return only the relevant data in a dictionary\n",
    "    return {\n",
    "        'precip': real_trimmed_event['precipitation (mm)'].values,\n",
    "        'times': trimmed_event['times'].values,\n",
    "        \"season\" : get_season(trimmed_event['times'][0]),\n",
    "        'duration':len(real_trimmed_event) / 2,\n",
    "        \"year\":extract_year(trimmed_event),\n",
    "        'Volume': sum(real_trimmed_event['precipitation (mm)'].values),\n",
    "    }\n",
    "\n",
    "# Initialize an empty list to collect rows\n",
    "rows = []\n",
    "\n",
    "for em in [\"bc006\"]:\n",
    "    for gauge_num in range(0, 1293):\n",
    "        if gauge_num not in [444, 827, 888]:\n",
    "            if gauge_num % 100 == 0:\n",
    "                print(f\"Processing gauge {gauge_num}\")\n",
    "            \n",
    "            files = [f for f in os.listdir(f\"/nfs/a161/gy17m2a/PhD/ProcessedData/IndependentEvents/UKCP18_30mins/Present/{em}/{gauge_num}/WholeYear/\") if f.endswith('.csv')]\n",
    "            files = np.sort(files)\n",
    "\n",
    "            for file in files:\n",
    "                fp = f\"/nfs/a161/gy17m2a/PhD/ProcessedData/IndependentEvents/UKCP18_30mins/Present/{em}/{gauge_num}/WholeYear/{file}\"\n",
    "                if '2080' in fp:\n",
    "                    continue\n",
    "\n",
    "                this_event = read_event(gauge_num, fp)\n",
    "\n",
    "                # Create the row data with just 'precip' and 'times'\n",
    "                row_data = create_dataframe_row(this_event)\n",
    "                \n",
    "                # Only append rows that are not None\n",
    "                if row_data is not None:\n",
    "                    rows.append(row_data)\n",
    "\n",
    "# Create DataFrame from collected rows\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae81ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/nfs/a319/gy17m2a/PhD/ProcessedData/Profiles/UKCP18_30mins/Present/{em}/df.pkl\", 'wb') as file:\n",
    "    pickle.dump(df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5e5a8",
   "metadata": {},
   "source": [
    "### Create version without Nones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45e42182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withoutnulls = df[df['precip'].notnull()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71b0e2",
   "metadata": {},
   "source": [
    "### Add quintile categorisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f195c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withoutnulls['max_quintile_molly'] = df_withoutnulls['precip'].apply(find_max_quintile)\n",
    "df_withoutnulls['max_quintile_steef'] = df_withoutnulls['precip'].apply(analyse_event)\n",
    "df_withoutnulls['max_quintile_raw_rain'] = df_withoutnulls['precip'].apply(lambda x: find_part_with_most_rain(x, 5))\n",
    "df_withoutnulls[['max_quintile_steef', 'irain_profile_12_Steef']] = df_withoutnulls['precip'].apply(lambda x: pd.Series(analyse_event(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb78d4b",
   "metadata": {},
   "source": [
    "### Add loading categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "29a64bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withoutnulls['Loading_profile_raw_rain'] = df_withoutnulls['max_quintile_raw_rain'].map(quintile_mapping)\n",
    "df_withoutnulls['Loading_profile_molly'] =df_withoutnulls['max_quintile_molly'].map(quintile_mapping)\n",
    "df_withoutnulls['Loading_profile_steef'] =df_withoutnulls['max_quintile_steef'].map(quintile_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d8ce1",
   "metadata": {},
   "source": [
    "### Add profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1bb18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withoutnulls['irain_profile_12'] = df_withoutnulls['precip'].apply(lambda x: create_irain_profile(x, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0a0d5658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_withoutnulls[df_withoutnulls['max_quintile_molly']!=df_withoutnulls['max_quintile_steef']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b60024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,axs=plt.subplots(ncols=2, figsize=(12,5))\n",
    "# axs[0].plot(df_withoutnulls['irain_profile_12_Steef'][0])\n",
    "# axs[1].plot(df_withoutnulls['irain_profile_12'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e989713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/nfs/a319/gy17m2a/PhD/ProcessedData/Profiles/UKCP18_30mins/Present/{em}/df_withoutnulls.pkl\", 'wb') as file:\n",
    "    pickle.dump(df_withoutnulls, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
