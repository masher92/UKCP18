{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7dcd469",
   "metadata": {},
   "source": [
    "### Identify events which appear twice and delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c293443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75d6d3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "def copy_files(em, gauge_num, option_num):\n",
    "    # path to source directory\n",
    "    src_dir = f\"/nfs/a319/gy17m2a/PhD/ProcessedData/IndependentEvents/{em}/Gauge{gauge_num}/Option{option_num}/\" \n",
    "    # path to destination directory\n",
    "    dest_dir = f\"/nfs/a319/gy17m2a/PhD/ProcessedData/IndependentEvents/{em}/Gauge{gauge_num}/Option{option_num}/EventSet/\" \n",
    "\n",
    "    # getting all the files in the source directory\n",
    "    files = os.listdir(src_dir)\n",
    "    \n",
    "    if not os.path.isdir(dest_dir):\n",
    "        shutil.copytree(src_dir, dest_dir)\n",
    "\n",
    "def hash_dataframe(filepath, columns_to_exclude=None):\n",
    "    \"\"\"\n",
    "    Generate a hash for a DataFrame loaded from a CSV file,\n",
    "    excluding a specified column if provided.\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Drop the specified column if it exists\n",
    "    for column_to_exclude in columns_to_exclude:\n",
    "        if column_to_exclude and column_to_exclude in df.columns:\n",
    "            df = df.drop(columns=[column_to_exclude])\n",
    "    \n",
    "    # Convert DataFrame to a binary format using 'to_records' which includes data types in the hash\n",
    "    data = df.to_records(index=False)\n",
    "    return hashlib.sha256(data.tobytes()).hexdigest()\n",
    "\n",
    "def find_and_remove_duplicates(directory, column_to_exclude=None):\n",
    "    \"\"\"\n",
    "    Find and remove duplicate CSV files in a given directory,\n",
    "    excluding comparison on a specified column.\n",
    "    \"\"\"\n",
    "    hashes = {}\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "    files = np.sort(files)\n",
    "    \n",
    "    for filename in files:\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        file_hash = hash_dataframe(filepath, column_to_exclude)\n",
    "        \n",
    "        if file_hash in hashes:\n",
    "            # If hash is already in the dictionary, delete this file\n",
    "            os.remove(filepath)\n",
    "            print(f\"Deleted duplicate file: {filepath}\")\n",
    "        else:\n",
    "            # Otherwise, add the hash and file path to the dictionary\n",
    "            hashes[file_hash] = filepath\n",
    "\n",
    "# Usage\n",
    "for gauge_num in range(40,47):\n",
    "    print(gauge_num)\n",
    "    em = 'bc005'\n",
    "    copy_files(em, gauge_num, option_num =1)\n",
    "    copy_files(em, gauge_num, option_num =2)\n",
    "    directory1 = f\"/nfs/a319/gy17m2a/PhD/ProcessedData/IndependentEvents/{em}/Gauge{gauge_num}/Option1/EventSet/\" \n",
    "    directory2 = f\"/nfs/a319/gy17m2a/PhD/ProcessedData/IndependentEvents/{em}/Gauge{gauge_num}/Option2/EventSet/\" \n",
    "    column_to_exclude = 'Rolling_Sum'  # Change this to the column you want to exclude\n",
    "    find_and_remove_duplicates(directory1, column_to_exclude)\n",
    "    find_and_remove_duplicates(directory2, column_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c31f8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sequential(numbers):\n",
    "    return all(numbers[i] - numbers[i - 1] == 1 for i in range(1, len(numbers)))\n",
    "\n",
    "# Loop through gauges\n",
    "for gauge_num in [37]:\n",
    "    \n",
    "    for em in ['bc005']:\n",
    "        directory = f\"../../ProcessedData/IndependentEvents/{em}/Gauge{gauge_num}/Option2\"\n",
    "        files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "        files = np.sort(files)\n",
    "        for file in files:\n",
    "            test = pd.read_csv(directory+ '/'+ file)\n",
    "            if test['Unnamed: 0'].is_monotonic_increasing ==False:\n",
    "                print(f\"monotonic: {file}\")\n",
    "            if not is_sequential(test['Unnamed: 0']):\n",
    "                print(f\"not sequential {file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
