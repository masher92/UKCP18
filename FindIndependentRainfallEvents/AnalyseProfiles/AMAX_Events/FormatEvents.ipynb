{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e69a6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2c89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FormatEvents_Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "594c9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/nfs/a319/gy17m2a/PhD/'\n",
    "home_dir2 = '/nfs/a161/gy17m2a/PhD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "254b686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = ['0.5', '1', '2', '3', '6', '12', '24']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6eb2c",
   "metadata": {},
   "source": [
    "### UKCP18 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c4c4f",
   "metadata": {},
   "source": [
    "### Join together lists for different ensemble members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa4bb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_props_dict_present = []\n",
    "ems_present = ['bc005', 'bc006', 'bc007', 'bc009', 'bc010', 'bc011', 'bc012', 'bc013', 'bc015', 'bc016', 'bc017', 'bc018']\n",
    "for em in ems_present:\n",
    "    with open(home_dir +  f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/event_props_dict_{em}.pickle\", 'rb') as handle:\n",
    "        one_events_props_dict_present = pickle.load(handle)    \n",
    "    events_props_dict_present = events_props_dict_present + one_events_props_dict_present\n",
    "    \n",
    "## Join into one dataframe    \n",
    "present = pd.DataFrame(events_props_dict_present)\n",
    "present['Climate'] = 'Present'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec28fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_props_dict_future = []\n",
    "ems_future = ['bb195', 'bb192', 'bb198', 'bb208', 'bb225','bb222', 'bb201', 'bb204', 'bb216', 'bb219', 'bb211']\n",
    "for em in ems_future:\n",
    "    with open(home_dir +  f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/event_props_dict_{em}.pickle\", 'rb') as handle:\n",
    "        one_events_props_dict_future = pickle.load(handle)    \n",
    "    events_props_dict_future = events_props_dict_future + one_events_props_dict_future\n",
    "    \n",
    "## Join into one dataframe\n",
    "future = pd.DataFrame(events_props_dict_future)\n",
    "future['Climate'] = 'Future'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8203f5",
   "metadata": {},
   "source": [
    "## Make a check on number of files (could shift this to the checking script)\n",
    "NB - the method of searching on part1 doesnt work, because the filename only represents on of the files that is represented by that event\n",
    "\n",
    "\n",
    "24529 is 19 * 1291 and is the number we expert with no part1s for one ensemble member.  \n",
    "For 12 ems it becomes 24529 * 12 = 294348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af8ebc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = present[present['filename'].str.contains('part1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "383fbb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24     325393\n",
      "12     296965\n",
      "6      294401\n",
      "0.5    294348\n",
      "1      294348\n",
      "2      294348\n",
      "3      294348\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure that values are treated as lists. If any single numbers are not in a list, convert them to lists.\n",
    "present['dur_for_which_this_is_amax'] = present['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# Flatten the lists and count occurrences of each number\n",
    "all_numbers = [num for sublist in present['dur_for_which_this_is_amax'] for num in sublist]\n",
    "number_counts = pd.Series(all_numbers).value_counts()\n",
    "\n",
    "# Show the result\n",
    "print(number_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ec2bb",
   "metadata": {},
   "source": [
    "### Create one dataframe containing both present and future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a33225a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = pd.concat([present, future])\n",
    "\n",
    "# Add D variable (day of year) and date\n",
    "df_long['D'] = (df_long['theta'] * 365.25) / (2 * np.pi)\n",
    "df_long['date'] = df_long.apply(lambda row: date_from_D(row['D'], row['year']), axis=1)\n",
    "df_long['season'] = df_long['date'].apply(get_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be1aa28",
   "metadata": {},
   "source": [
    "### Check the number of files for each duration\n",
    "NB: Number of files for 24h duration is longer due to compound events  \n",
    "Checked this by filtering only rows with part0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13853b0",
   "metadata": {},
   "source": [
    "### Remove entries which are less than 1.5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd33065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long[df_long['duration'] >=1.5]\n",
    "present = present[present['duration'] >=1.5]\n",
    "future = future[future['duration'] >=1.5]\n",
    "# nan_rows = df_long[df_long['D50'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ffe9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/all_events_characteristics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4ce11",
   "metadata": {},
   "source": [
    "### NIMROD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2bc859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir +  f\"ProcessedData/AMAX_Events/NIMROD_30mins/event_props_dict_nimrod.pickle\", 'rb') as handle:\n",
    "    events_props_dict_nimrod = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f603319",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimrod = pd.DataFrame(events_props_dict_nimrod)\n",
    "# Add D variable (day of year) and date\n",
    "nimrod['D'] = (nimrod['theta'] * 365.25) / (2 * np.pi)\n",
    "nimrod['date'] = nimrod.apply(lambda row: date_from_D(row['D'], row['year']), axis=1)\n",
    "nimrod['season'] = nimrod['date'].apply(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4102701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24     19451\n",
      "0.5    19335\n",
      "12     14591\n",
      "6      11438\n",
      "2       8251\n",
      "1       7675\n",
      "3       6972\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure that values are treated as lists. If any single numbers are not in a list, convert them to lists.\n",
    "nimrod['dur_for_which_this_is_amax'] = nimrod['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# Flatten the lists and count occurrences of each number\n",
    "all_numbers = [num for sublist in nimrod['dur_for_which_this_is_amax'] for num in sublist]\n",
    "number_counts = pd.Series(all_numbers).value_counts()\n",
    "\n",
    "# Show the result\n",
    "print(number_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62805e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimrod.to_csv(home_dir + f\"ProcessedData/AMAX_Events/NIMROD_30mins/all_events_characteristics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db8a52",
   "metadata": {},
   "source": [
    "## Create datasets with just events for each sampling duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for duration in durations:\n",
    "    df_long_this_dur = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "        lambda x: isinstance(x, list) and str(duration) in x or x == str(duration))]\n",
    "    print(duration, len(df_long_this_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_1hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(1) in x or x == str(1))]\n",
    "\n",
    "df_long_2hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(2) in x or x == str(2))]\n",
    "\n",
    "df_long_3hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(3) in x or x == str(3))]\n",
    "\n",
    "df_long_6hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(6) in x or x == str(6))]\n",
    "\n",
    "df_long_12hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(12) in x or x == str(12))]\n",
    "\n",
    "df_long_24hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(24) in x or x == str(24))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c657ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_long_24hr, df_long_12hr, df_long_6hr, df_long_3hr, df_long_2hr, df_long_1hr, df_long_05hr]:\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(present))\n",
    "print(len(future))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc62b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, counts = np.unique(present['duration'], return_counts=True)\n",
    "my_df = pd.DataFrame({'values': vals, 'conts':counts})\n",
    "my_df.sort_values(by='conts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17285d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, counts = np.unique(future['duration'], return_counts=True)\n",
    "my_df = pd.DataFrame({'values': vals, 'conts':counts})\n",
    "my_df.sort_values(by='conts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, counts = np.unique(future['D50'], return_counts=True)\n",
    "my_df = pd.DataFrame({'values': vals, 'conts':counts})\n",
    "my_df.sort_values(by='conts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b92194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(present['D50'], bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c4341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num']\n",
    "grouped_by_gauge_allevents = group_data_calc_means(df_long, group_by_columns)\n",
    "grouped_by_gauge_allevents_changes = find_change_values_in_groups_new(grouped_by_gauge_allevents, group_by_columns, 'All')\n",
    "\n",
    "# grouped_by_gauge_allevents_changes.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_samplingdur_changes_allevents.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f45c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04471ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num', 'season']\n",
    "grouped_by_gauge_season_allevents = group_data_calc_means(df_long, group_by_columns)\n",
    "grouped_by_gauge_season_allevents_changes = find_change_values_in_groups_new(grouped_by_gauge_season_allevents, group_by_columns, 'All')\n",
    "\n",
    "grouped_by_gauge_season_allevents_changes.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_samplingdur_season_changes_allevents.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652abd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num']\n",
    "grouped_by_gauge_samplingdur_05 = group_data_calc_means(df_long_05hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_1 = group_data_calc_means(df_long_1hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_2 = group_data_calc_means(df_long_2hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_3 = group_data_calc_means(df_long_3hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_6 = group_data_calc_means(df_long_6hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_12 = group_data_calc_means(df_long_12hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_24 = group_data_calc_means(df_long_24hr, group_by_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num', 'season']\n",
    "grouped_by_gauge_samplingdur_season_05 = group_data_calc_means(df_long_05hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_1 = group_data_calc_means(df_long_1hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_2 = group_data_calc_means(df_long_2hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_3 = group_data_calc_means(df_long_3hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_6 = group_data_calc_means(df_long_6hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_12 = group_data_calc_means(df_long_12hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_24 = group_data_calc_means(df_long_24hr, group_by_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473116e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num']\n",
    "grouped_by_gauge_samplingdur_05_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_05, group_by_columns, float(0.5))\n",
    "grouped_by_gauge_samplingdur_1_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_1, group_by_columns, 1)\n",
    "grouped_by_gauge_samplingdur_2_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_2, group_by_columns, 2)\n",
    "grouped_by_gauge_samplingdur_3_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_3, group_by_columns,3)\n",
    "grouped_by_gauge_samplingdur_6_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_6, group_by_columns,6)\n",
    "grouped_by_gauge_samplingdur_12_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_12, group_by_columns, 12)\n",
    "grouped_by_gauge_samplingdur_24_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_24, group_by_columns, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f695d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num', 'season']\n",
    "grouped_by_gauge_samplingdur_season_05_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_05, group_by_columns, float(0.5))\n",
    "grouped_by_gauge_samplingdur_season_1_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_1, group_by_columns, 1)\n",
    "grouped_by_gauge_samplingdur_season_2_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_2, group_by_columns, 2)\n",
    "grouped_by_gauge_samplingdur_season_3_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_3, group_by_columns,3)\n",
    "grouped_by_gauge_samplingdur_season_6_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_6, group_by_columns,6)\n",
    "grouped_by_gauge_samplingdur_season_12_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_12, group_by_columns, 12)\n",
    "grouped_by_gauge_samplingdur_season_24_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_24, group_by_columns, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num']\n",
    "grouped_by_gauge_samplingdur_05_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_05, group_by_columns, float(0.5))\n",
    "grouped_by_gauge_samplingdur_1_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_1, group_by_columns, 1)\n",
    "grouped_by_gauge_samplingdur_2_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_2, group_by_columns, 2)\n",
    "grouped_by_gauge_samplingdur_3_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_3, group_by_columns,3)\n",
    "grouped_by_gauge_samplingdur_6_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_6, group_by_columns,6)\n",
    "grouped_by_gauge_samplingdur_12_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_12, group_by_columns, 12)\n",
    "grouped_by_gauge_samplingdur_24_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_24, group_by_columns, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a7b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([grouped_by_gauge_samplingdur_05_changes, grouped_by_gauge_samplingdur_1_changes, \n",
    "                  grouped_by_gauge_samplingdur_2_changes, grouped_by_gauge_samplingdur_3_changes,\n",
    "                  grouped_by_gauge_samplingdur_6_changes, grouped_by_gauge_samplingdur_12_changes,\n",
    "                  grouped_by_gauge_samplingdur_24_changes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ef265",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_season = pd.concat([grouped_by_gauge_samplingdur_season_05_changes, grouped_by_gauge_samplingdur_season_1_changes, \n",
    "                  grouped_by_gauge_samplingdur_season_2_changes, grouped_by_gauge_samplingdur_season_3_changes,\n",
    "                  grouped_by_gauge_samplingdur_season_6_changes, grouped_by_gauge_samplingdur_season_12_changes,\n",
    "                  grouped_by_gauge_samplingdur_season_24_changes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_by_columns = ['Climate', 'gauge_num', 'duration', 'season']\n",
    "# grouped_by_gauge_samplingdur_season = group_data_calc_means(df_long, group_by_columns)\n",
    "# grouped_by_gauge_samplingdur_season_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season, group_by_columns)\n",
    "\n",
    "# group_by_columns = ['Climate', 'gauge_num', 'duration']\n",
    "# grouped_by_gauge_samplingdur = group_data_calc_means(df_long, group_by_columns)\n",
    "# grouped_by_gauge_samplingdur_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur, group_by_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_by_gauge_samplingdur_season_changes.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_samplingdur_season_changes_new.csv\", index=False)\n",
    "total.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_samplingdur_changes_new.csv\", index=False)\n",
    "\n",
    "total_season.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_samplingdur_season_changes_new.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
