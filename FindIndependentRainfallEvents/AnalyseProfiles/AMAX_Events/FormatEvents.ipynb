{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69a6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2c89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FormatEvents_Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594c9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/nfs/a319/gy17m2a/PhD/'\n",
    "home_dir2 = '/nfs/a161/gy17m2a/PhD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254b686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = ['0.5', '1', '2', '3', '6', '12', '24']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6eb2c",
   "metadata": {},
   "source": [
    "### UKCP18 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c4c4f",
   "metadata": {},
   "source": [
    "### Join together lists for different ensemble members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa4bb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_props_dict_present = []\n",
    "ems_present = ['bc005', 'bc006', 'bc007', 'bc009', 'bc010', 'bc011', 'bc012', 'bc013', 'bc015', 'bc016', 'bc017', 'bc018']\n",
    "for em in ems_present:\n",
    "    with open(home_dir +  f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/event_props_dict_{em}.pickle\", 'rb') as handle:\n",
    "        one_events_props_dict_present = pickle.load(handle)    \n",
    "    events_props_dict_present = events_props_dict_present + one_events_props_dict_present\n",
    "    \n",
    "## Join into one dataframe    \n",
    "present = pd.DataFrame(events_props_dict_present)\n",
    "present['Climate'] = 'Present'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec28fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_props_dict_future = []\n",
    "# ems_future = ['bb195', 'bb192', 'bb198', 'bb208', 'bb225','bb222', 'bb201', 'bb204', 'bb216', 'bb219', 'bb211']\n",
    "ems_future = ['bb192', 'bb208', 'bb225','bb222', 'bb201', 'bb204', 'bb216', 'bb219', 'bb211', 'bb189'] #bb195, #bb198\n",
    "for em in ems_future:\n",
    "    with open(home_dir +  f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/event_props_dict_{em}.pickle\", 'rb') as handle:\n",
    "        one_events_props_dict_future = pickle.load(handle)    \n",
    "    events_props_dict_future = events_props_dict_future + one_events_props_dict_future\n",
    "    \n",
    "## Join into one dataframe\n",
    "future = pd.DataFrame(events_props_dict_future)\n",
    "future['Climate'] = 'Future'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8203f5",
   "metadata": {},
   "source": [
    "## Make a check on number of files (could shift this to the checking script)\n",
    "NB - the method of searching on part1 doesnt work, because the filename only represents on of the files that is represented by that event\n",
    "\n",
    "\n",
    "24529 is 19 * 1291 and is the number we expert with no part1s for one ensemble member.  \n",
    "For 12 ems it becomes 24529 * 12 = 294348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af8ebc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = present[present['filename'].str.contains('part1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383fbb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24     327523\n",
      "12     297624\n",
      "6      294422\n",
      "0.5    294348\n",
      "1      294348\n",
      "2      294348\n",
      "3      294348\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure that values are treated as lists. If any single numbers are not in a list, convert them to lists.\n",
    "present['dur_for_which_this_is_amax'] = present['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# Flatten the lists and count occurrences of each number\n",
    "all_numbers = [num for sublist in present['dur_for_which_this_is_amax'] for num in sublist]\n",
    "number_counts = pd.Series(all_numbers).value_counts()\n",
    "\n",
    "# Show the result\n",
    "print(number_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76742fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24     270114\n",
      "12     247512\n",
      "6      245335\n",
      "0.5    245290\n",
      "1      245290\n",
      "2      245290\n",
      "3      245290\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure that values are treated as lists. If any single numbers are not in a list, convert them to lists.\n",
    "future['dur_for_which_this_is_amax'] = future['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# Flatten the lists and count occurrences of each number\n",
    "all_numbers = [num for sublist in future['dur_for_which_this_is_amax'] for num in sublist]\n",
    "number_counts = pd.Series(all_numbers).value_counts()\n",
    "\n",
    "# Show the result\n",
    "print(number_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ec2bb",
   "metadata": {},
   "source": [
    "### Create one dataframe containing both present and future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a33225a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = pd.concat([present, future])\n",
    "\n",
    "# Add D variable (day of year) and date\n",
    "df_long['D'] = (df_long['theta'] * 365.25) / (2 * np.pi)\n",
    "df_long['date'] = df_long.apply(lambda row: date_from_D(row['D'], row['year']), axis=1)\n",
    "df_long['season'] = df_long['date'].apply(get_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be1aa28",
   "metadata": {},
   "source": [
    "### Check the number of files for each duration\n",
    "NB: Number of files for 24h duration is longer due to compound events  \n",
    "Checked this by filtering only rows with part0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13853b0",
   "metadata": {},
   "source": [
    "### Remove entries which are less than 1.5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "932c6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to JSON strings before saving - not doing this, messed up formatting a bit\n",
    "df_long['dur_for_which_this_is_amax'] = df_long['dur_for_which_this_is_amax'].apply(json.dumps)\n",
    "df_long.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/all_events_characteristics_shortdurationskept.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd33065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long[df_long['duration'] >=1.5]\n",
    "present = present[present['duration'] >=1.5]\n",
    "future = future[future['duration'] >=1.5]\n",
    "# nan_rows = df_long[df_long['D50'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ffe9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/all_events_characteristics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4ce11",
   "metadata": {},
   "source": [
    "### NIMROD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2bc859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir +  f\"ProcessedData/AMAX_Events/NIMROD_30mins/event_props_dict.pickle\", 'rb') as handle:\n",
    "    events_props_dict_nimrod = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f603319",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimrod = pd.DataFrame(events_props_dict_nimrod)\n",
    "# Add D variable (day of year) and date\n",
    "nimrod['D'] = (nimrod['theta'] * 365.25) / (2 * np.pi)\n",
    "nimrod['date'] = nimrod.apply(lambda row: date_from_D(row['D'], row['year']), axis=1)\n",
    "nimrod['season'] = nimrod['date'].apply(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4102701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24     19456\n",
      "0.5    19343\n",
      "12     14595\n",
      "6      11434\n",
      "2       8249\n",
      "1       7667\n",
      "3       6961\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure that values are treated as lists. If any single numbers are not in a list, convert them to lists.\n",
    "nimrod['dur_for_which_this_is_amax'] = nimrod['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# Flatten the lists and count occurrences of each number\n",
    "all_numbers = [num for sublist in nimrod['dur_for_which_this_is_amax'] for num in sublist]\n",
    "number_counts = pd.Series(all_numbers).value_counts()\n",
    "\n",
    "# Show the result\n",
    "print(number_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a27805f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24     19456\n",
      "0.5    19343\n",
      "12     14595\n",
      "6      11434\n",
      "2       8249\n",
      "1       7667\n",
      "3       6961\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure that values are treated as lists. If any single numbers are not in a list, convert them to lists.\n",
    "nimrod['dur_for_which_this_is_amax'] = nimrod['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# Flatten the lists and count occurrences of each number\n",
    "all_numbers = [num for sublist in nimrod['dur_for_which_this_is_amax'] for num in sublist]\n",
    "number_counts = pd.Series(all_numbers).value_counts()\n",
    "\n",
    "# Show the result\n",
    "print(number_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c62805e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimrod.to_csv(home_dir + f\"ProcessedData/AMAX_Events/NIMROD_30mins/all_events_characteristics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db8a52",
   "metadata": {},
   "source": [
    "## Create datasets with just events for each sampling duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f879556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for duration in durations:\n",
    "#     df_long_this_dur = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "#         lambda x: isinstance(x, list) and str(duration) in x or x == str(duration))]\n",
    "#     print(duration, len(df_long_this_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfb6cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_05hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(0.5) in x or x == str(0.5))]\n",
    "\n",
    "df_long_1hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(1) in x or x == str(1))]\n",
    "\n",
    "df_long_2hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(2) in x or x == str(2))]\n",
    "\n",
    "df_long_3hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(3) in x or x == str(3))]\n",
    "\n",
    "df_long_6hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(6) in x or x == str(6))]\n",
    "\n",
    "df_long_12hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(12) in x or x == str(12))]\n",
    "\n",
    "df_long_24hr = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "    lambda x: isinstance(x, list) and str(24) in x or x == str(24))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c657ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in [df_long_24hr, df_long_12hr, df_long_6hr, df_long_3hr, df_long_2hr, df_long_1hr, df_long_05hr]:\n",
    "#     print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "54bc62b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vals, counts = np.unique(present['duration'], return_counts=True)\n",
    "# my_df = pd.DataFrame({'values': vals, 'conts':counts})\n",
    "# my_df.sort_values(by='conts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b92194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(present['D50'], bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9c3f2d",
   "metadata": {},
   "source": [
    "# Create grouped results\n",
    "### Group by gauge, climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86c4341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num']\n",
    "grouped_by_gauge_allevents = group_data_calc_means(df_long, group_by_columns)\n",
    "grouped_by_gauge_allevents_changes = find_change_values_in_groups_new(grouped_by_gauge_allevents, group_by_columns, 'All')\n",
    "grouped_by_gauge_allevents_changes.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_changes_allevents.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521afbb8",
   "metadata": {},
   "source": [
    "### Group by season, gauge, climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04471ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num', 'season']\n",
    "grouped_by_gauge_season_allevents = group_data_calc_means(df_long, group_by_columns)\n",
    "grouped_by_gauge_season_allevents_changes = find_change_values_in_groups_new(grouped_by_gauge_season_allevents, group_by_columns, 'All')\n",
    "\n",
    "grouped_by_gauge_season_allevents_changes.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_season_changes_allevents.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0e315ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9037"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1291 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fe617dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauge_num</th>\n",
       "      <th>theta_mean_present</th>\n",
       "      <th>D_mean_present</th>\n",
       "      <th>R_present</th>\n",
       "      <th>D50_mean_present</th>\n",
       "      <th>D50_median_present</th>\n",
       "      <th>theta_mean_future</th>\n",
       "      <th>D_mean_future</th>\n",
       "      <th>R_future</th>\n",
       "      <th>D50_mean_future</th>\n",
       "      <th>D50_median_future</th>\n",
       "      <th>theta_mean_diff</th>\n",
       "      <th>D_mean_diff</th>\n",
       "      <th>R_diff</th>\n",
       "      <th>D50_mean_diff</th>\n",
       "      <th>D50_median_diff</th>\n",
       "      <th>sampling_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.492009</td>\n",
       "      <td>202.995146</td>\n",
       "      <td>0.716161</td>\n",
       "      <td>51.787231</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.652277</td>\n",
       "      <td>212.311765</td>\n",
       "      <td>0.665845</td>\n",
       "      <td>48.384561</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.160268</td>\n",
       "      <td>9.316619</td>\n",
       "      <td>-0.050316</td>\n",
       "      <td>-3.402670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.669006</td>\n",
       "      <td>213.284264</td>\n",
       "      <td>0.646034</td>\n",
       "      <td>46.225785</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4.117856</td>\n",
       "      <td>239.376471</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>49.510553</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.448849</td>\n",
       "      <td>26.092207</td>\n",
       "      <td>-0.083772</td>\n",
       "      <td>3.284768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.636411</td>\n",
       "      <td>211.389474</td>\n",
       "      <td>0.659656</td>\n",
       "      <td>49.534355</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.817106</td>\n",
       "      <td>221.893491</td>\n",
       "      <td>0.588810</td>\n",
       "      <td>49.686314</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.180695</td>\n",
       "      <td>10.504017</td>\n",
       "      <td>-0.070846</td>\n",
       "      <td>0.151959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.654827</td>\n",
       "      <td>212.460000</td>\n",
       "      <td>0.716496</td>\n",
       "      <td>47.729892</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.785144</td>\n",
       "      <td>220.035503</td>\n",
       "      <td>0.529504</td>\n",
       "      <td>49.676508</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.130317</td>\n",
       "      <td>7.575503</td>\n",
       "      <td>-0.186992</td>\n",
       "      <td>1.946617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.589481</td>\n",
       "      <td>208.661376</td>\n",
       "      <td>0.681365</td>\n",
       "      <td>44.007283</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>3.822357</td>\n",
       "      <td>222.198758</td>\n",
       "      <td>0.523637</td>\n",
       "      <td>49.619731</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.232876</td>\n",
       "      <td>13.537382</td>\n",
       "      <td>-0.157729</td>\n",
       "      <td>5.612448</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1289</td>\n",
       "      <td>4.076974</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>0.449279</td>\n",
       "      <td>49.761641</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.930137</td>\n",
       "      <td>228.464115</td>\n",
       "      <td>0.366939</td>\n",
       "      <td>51.223931</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-0.146838</td>\n",
       "      <td>-8.535885</td>\n",
       "      <td>-0.082340</td>\n",
       "      <td>1.462290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>1290</td>\n",
       "      <td>3.795601</td>\n",
       "      <td>220.643382</td>\n",
       "      <td>0.323145</td>\n",
       "      <td>51.780593</td>\n",
       "      <td>51.065760</td>\n",
       "      <td>3.680511</td>\n",
       "      <td>213.953052</td>\n",
       "      <td>0.453697</td>\n",
       "      <td>51.031805</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-0.115090</td>\n",
       "      <td>-6.690331</td>\n",
       "      <td>0.130552</td>\n",
       "      <td>-0.748788</td>\n",
       "      <td>-1.065760</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1291</td>\n",
       "      <td>3.499964</td>\n",
       "      <td>203.457627</td>\n",
       "      <td>0.324244</td>\n",
       "      <td>48.545873</td>\n",
       "      <td>48.368079</td>\n",
       "      <td>3.935950</td>\n",
       "      <td>228.802083</td>\n",
       "      <td>0.381297</td>\n",
       "      <td>46.338815</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>0.435986</td>\n",
       "      <td>25.344456</td>\n",
       "      <td>0.057053</td>\n",
       "      <td>-2.207058</td>\n",
       "      <td>-2.534746</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1292</td>\n",
       "      <td>3.759127</td>\n",
       "      <td>218.523077</td>\n",
       "      <td>0.280734</td>\n",
       "      <td>49.541361</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.821431</td>\n",
       "      <td>222.144928</td>\n",
       "      <td>0.324373</td>\n",
       "      <td>50.571090</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.062305</td>\n",
       "      <td>3.621851</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>1.029729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1293</td>\n",
       "      <td>3.704871</td>\n",
       "      <td>215.369099</td>\n",
       "      <td>0.344683</td>\n",
       "      <td>50.479278</td>\n",
       "      <td>49.019608</td>\n",
       "      <td>3.478621</td>\n",
       "      <td>202.216931</td>\n",
       "      <td>0.207393</td>\n",
       "      <td>50.176580</td>\n",
       "      <td>48.571429</td>\n",
       "      <td>-0.226249</td>\n",
       "      <td>-13.152167</td>\n",
       "      <td>-0.137290</td>\n",
       "      <td>-0.302698</td>\n",
       "      <td>-0.448179</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9037 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gauge_num  theta_mean_present  D_mean_present  R_present  \\\n",
       "0             0            3.492009      202.995146   0.716161   \n",
       "1             1            3.669006      213.284264   0.646034   \n",
       "2             2            3.636411      211.389474   0.659656   \n",
       "3             3            3.654827      212.460000   0.716496   \n",
       "4             4            3.589481      208.661376   0.681365   \n",
       "...         ...                 ...             ...        ...   \n",
       "1286       1289            4.076974      237.000000   0.449279   \n",
       "1287       1290            3.795601      220.643382   0.323145   \n",
       "1288       1291            3.499964      203.457627   0.324244   \n",
       "1289       1292            3.759127      218.523077   0.280734   \n",
       "1290       1293            3.704871      215.369099   0.344683   \n",
       "\n",
       "      D50_mean_present  D50_median_present  theta_mean_future  D_mean_future  \\\n",
       "0            51.787231           50.000000           3.652277     212.311765   \n",
       "1            46.225785           50.000000           4.117856     239.376471   \n",
       "2            49.534355           50.000000           3.817106     221.893491   \n",
       "3            47.729892           50.000000           3.785144     220.035503   \n",
       "4            44.007283           45.833333           3.822357     222.198758   \n",
       "...                ...                 ...                ...            ...   \n",
       "1286         49.761641           50.000000           3.930137     228.464115   \n",
       "1287         51.780593           51.065760           3.680511     213.953052   \n",
       "1288         48.545873           48.368079           3.935950     228.802083   \n",
       "1289         49.541361           50.000000           3.821431     222.144928   \n",
       "1290         50.479278           49.019608           3.478621     202.216931   \n",
       "\n",
       "      R_future  D50_mean_future  D50_median_future  theta_mean_diff  \\\n",
       "0     0.665845        48.384561          50.000000         0.160268   \n",
       "1     0.562262        49.510553          50.000000         0.448849   \n",
       "2     0.588810        49.686314          50.000000         0.180695   \n",
       "3     0.529504        49.676508          50.000000         0.130317   \n",
       "4     0.523637        49.619731          50.000000         0.232876   \n",
       "...        ...              ...                ...              ...   \n",
       "1286  0.366939        51.223931          50.000000        -0.146838   \n",
       "1287  0.453697        51.031805          50.000000        -0.115090   \n",
       "1288  0.381297        46.338815          45.833333         0.435986   \n",
       "1289  0.324373        50.571090          50.000000         0.062305   \n",
       "1290  0.207393        50.176580          48.571429        -0.226249   \n",
       "\n",
       "      D_mean_diff    R_diff  D50_mean_diff  D50_median_diff  sampling_duration  \n",
       "0        9.316619 -0.050316      -3.402670         0.000000           0.500000  \n",
       "1       26.092207 -0.083772       3.284768         0.000000           0.500000  \n",
       "2       10.504017 -0.070846       0.151959         0.000000           0.500000  \n",
       "3        7.575503 -0.186992       1.946617         0.000000           0.500000  \n",
       "4       13.537382 -0.157729       5.612448         4.166667           0.500000  \n",
       "...           ...       ...            ...              ...                ...  \n",
       "1286    -8.535885 -0.082340       1.462290         0.000000          24.000000  \n",
       "1287    -6.690331  0.130552      -0.748788        -1.065760          24.000000  \n",
       "1288    25.344456  0.057053      -2.207058        -2.534746          24.000000  \n",
       "1289     3.621851  0.043639       1.029729         0.000000          24.000000  \n",
       "1290   -13.152167 -0.137290      -0.302698        -0.448179          24.000000  \n",
       "\n",
       "[9037 rows x 17 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dff98b",
   "metadata": {},
   "source": [
    "## Create version of events with one event per gauge, per duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "652abd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num']\n",
    "grouped_by_gauge_samplingdur_05 = group_data_calc_means(df_long_05hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_1 = group_data_calc_means(df_long_1hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_2 = group_data_calc_means(df_long_2hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_3 = group_data_calc_means(df_long_3hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_6 = group_data_calc_means(df_long_6hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_12 = group_data_calc_means(df_long_12hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_24 = group_data_calc_means(df_long_24hr, group_by_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db8c3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num', 'season']\n",
    "grouped_by_gauge_samplingdur_season_05 = group_data_calc_means(df_long_05hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_1 = group_data_calc_means(df_long_1hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_2 = group_data_calc_means(df_long_2hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_3 = group_data_calc_means(df_long_3hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_6 = group_data_calc_means(df_long_6hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_12 = group_data_calc_means(df_long_12hr, group_by_columns)\n",
    "grouped_by_gauge_samplingdur_season_24 = group_data_calc_means(df_long_24hr, group_by_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "473116e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num']\n",
    "grouped_by_gauge_samplingdur_05_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_05, group_by_columns, float(0.5))\n",
    "grouped_by_gauge_samplingdur_1_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_1, group_by_columns, 1)\n",
    "grouped_by_gauge_samplingdur_2_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_2, group_by_columns, 2)\n",
    "grouped_by_gauge_samplingdur_3_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_3, group_by_columns,3)\n",
    "grouped_by_gauge_samplingdur_6_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_6, group_by_columns,6)\n",
    "grouped_by_gauge_samplingdur_12_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_12, group_by_columns, 12)\n",
    "grouped_by_gauge_samplingdur_24_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_24, group_by_columns, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4f695d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num', 'season']\n",
    "grouped_by_gauge_samplingdur_season_05_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_05, group_by_columns, float(0.5))\n",
    "grouped_by_gauge_samplingdur_season_1_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_1, group_by_columns, 1)\n",
    "grouped_by_gauge_samplingdur_season_2_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_2, group_by_columns, 2)\n",
    "grouped_by_gauge_samplingdur_season_3_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_3, group_by_columns,3)\n",
    "grouped_by_gauge_samplingdur_season_6_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_6, group_by_columns,6)\n",
    "grouped_by_gauge_samplingdur_season_12_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_12, group_by_columns, 12)\n",
    "grouped_by_gauge_samplingdur_season_24_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season_24, group_by_columns, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "732b40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num']\n",
    "grouped_by_gauge_samplingdur_05_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_05, group_by_columns, float(0.5))\n",
    "grouped_by_gauge_samplingdur_1_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_1, group_by_columns, 1)\n",
    "grouped_by_gauge_samplingdur_2_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_2, group_by_columns, 2)\n",
    "grouped_by_gauge_samplingdur_3_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_3, group_by_columns,3)\n",
    "grouped_by_gauge_samplingdur_6_changes  = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_6, group_by_columns,6)\n",
    "grouped_by_gauge_samplingdur_12_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_12, group_by_columns, 12)\n",
    "grouped_by_gauge_samplingdur_24_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_24, group_by_columns, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "442a7b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([grouped_by_gauge_samplingdur_05_changes, grouped_by_gauge_samplingdur_1_changes, \n",
    "                  grouped_by_gauge_samplingdur_2_changes, grouped_by_gauge_samplingdur_3_changes,\n",
    "                  grouped_by_gauge_samplingdur_6_changes, grouped_by_gauge_samplingdur_12_changes,\n",
    "                  grouped_by_gauge_samplingdur_24_changes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3d84c23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauge_num</th>\n",
       "      <th>theta_mean_present</th>\n",
       "      <th>D_mean_present</th>\n",
       "      <th>R_present</th>\n",
       "      <th>D50_mean_present</th>\n",
       "      <th>D50_median_present</th>\n",
       "      <th>theta_mean_future</th>\n",
       "      <th>D_mean_future</th>\n",
       "      <th>R_future</th>\n",
       "      <th>D50_mean_future</th>\n",
       "      <th>D50_median_future</th>\n",
       "      <th>theta_mean_diff</th>\n",
       "      <th>D_mean_diff</th>\n",
       "      <th>R_diff</th>\n",
       "      <th>D50_mean_diff</th>\n",
       "      <th>D50_median_diff</th>\n",
       "      <th>sampling_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.492009</td>\n",
       "      <td>202.995146</td>\n",
       "      <td>0.716161</td>\n",
       "      <td>51.787231</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.652277</td>\n",
       "      <td>212.311765</td>\n",
       "      <td>0.665845</td>\n",
       "      <td>48.384561</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.160268</td>\n",
       "      <td>9.316619</td>\n",
       "      <td>-0.050316</td>\n",
       "      <td>-3.402670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.669006</td>\n",
       "      <td>213.284264</td>\n",
       "      <td>0.646034</td>\n",
       "      <td>46.225785</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4.117856</td>\n",
       "      <td>239.376471</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>49.510553</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.448849</td>\n",
       "      <td>26.092207</td>\n",
       "      <td>-0.083772</td>\n",
       "      <td>3.284768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.636411</td>\n",
       "      <td>211.389474</td>\n",
       "      <td>0.659656</td>\n",
       "      <td>49.534355</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.817106</td>\n",
       "      <td>221.893491</td>\n",
       "      <td>0.588810</td>\n",
       "      <td>49.686314</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.180695</td>\n",
       "      <td>10.504017</td>\n",
       "      <td>-0.070846</td>\n",
       "      <td>0.151959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.654827</td>\n",
       "      <td>212.460000</td>\n",
       "      <td>0.716496</td>\n",
       "      <td>47.729892</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.785144</td>\n",
       "      <td>220.035503</td>\n",
       "      <td>0.529504</td>\n",
       "      <td>49.676508</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.130317</td>\n",
       "      <td>7.575503</td>\n",
       "      <td>-0.186992</td>\n",
       "      <td>1.946617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.589481</td>\n",
       "      <td>208.661376</td>\n",
       "      <td>0.681365</td>\n",
       "      <td>44.007283</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>3.822357</td>\n",
       "      <td>222.198758</td>\n",
       "      <td>0.523637</td>\n",
       "      <td>49.619731</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.232876</td>\n",
       "      <td>13.537382</td>\n",
       "      <td>-0.157729</td>\n",
       "      <td>5.612448</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1289</td>\n",
       "      <td>4.076974</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>0.449279</td>\n",
       "      <td>49.761641</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.930137</td>\n",
       "      <td>228.464115</td>\n",
       "      <td>0.366939</td>\n",
       "      <td>51.223931</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-0.146838</td>\n",
       "      <td>-8.535885</td>\n",
       "      <td>-0.082340</td>\n",
       "      <td>1.462290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>1290</td>\n",
       "      <td>3.795601</td>\n",
       "      <td>220.643382</td>\n",
       "      <td>0.323145</td>\n",
       "      <td>51.780593</td>\n",
       "      <td>51.065760</td>\n",
       "      <td>3.680511</td>\n",
       "      <td>213.953052</td>\n",
       "      <td>0.453697</td>\n",
       "      <td>51.031805</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-0.115090</td>\n",
       "      <td>-6.690331</td>\n",
       "      <td>0.130552</td>\n",
       "      <td>-0.748788</td>\n",
       "      <td>-1.065760</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1291</td>\n",
       "      <td>3.499964</td>\n",
       "      <td>203.457627</td>\n",
       "      <td>0.324244</td>\n",
       "      <td>48.545873</td>\n",
       "      <td>48.368079</td>\n",
       "      <td>3.935950</td>\n",
       "      <td>228.802083</td>\n",
       "      <td>0.381297</td>\n",
       "      <td>46.338815</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>0.435986</td>\n",
       "      <td>25.344456</td>\n",
       "      <td>0.057053</td>\n",
       "      <td>-2.207058</td>\n",
       "      <td>-2.534746</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1292</td>\n",
       "      <td>3.759127</td>\n",
       "      <td>218.523077</td>\n",
       "      <td>0.280734</td>\n",
       "      <td>49.541361</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.821431</td>\n",
       "      <td>222.144928</td>\n",
       "      <td>0.324373</td>\n",
       "      <td>50.571090</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.062305</td>\n",
       "      <td>3.621851</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>1.029729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1293</td>\n",
       "      <td>3.704871</td>\n",
       "      <td>215.369099</td>\n",
       "      <td>0.344683</td>\n",
       "      <td>50.479278</td>\n",
       "      <td>49.019608</td>\n",
       "      <td>3.478621</td>\n",
       "      <td>202.216931</td>\n",
       "      <td>0.207393</td>\n",
       "      <td>50.176580</td>\n",
       "      <td>48.571429</td>\n",
       "      <td>-0.226249</td>\n",
       "      <td>-13.152167</td>\n",
       "      <td>-0.137290</td>\n",
       "      <td>-0.302698</td>\n",
       "      <td>-0.448179</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9037 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gauge_num  theta_mean_present  D_mean_present  R_present  \\\n",
       "0             0            3.492009      202.995146   0.716161   \n",
       "1             1            3.669006      213.284264   0.646034   \n",
       "2             2            3.636411      211.389474   0.659656   \n",
       "3             3            3.654827      212.460000   0.716496   \n",
       "4             4            3.589481      208.661376   0.681365   \n",
       "...         ...                 ...             ...        ...   \n",
       "1286       1289            4.076974      237.000000   0.449279   \n",
       "1287       1290            3.795601      220.643382   0.323145   \n",
       "1288       1291            3.499964      203.457627   0.324244   \n",
       "1289       1292            3.759127      218.523077   0.280734   \n",
       "1290       1293            3.704871      215.369099   0.344683   \n",
       "\n",
       "      D50_mean_present  D50_median_present  theta_mean_future  D_mean_future  \\\n",
       "0            51.787231           50.000000           3.652277     212.311765   \n",
       "1            46.225785           50.000000           4.117856     239.376471   \n",
       "2            49.534355           50.000000           3.817106     221.893491   \n",
       "3            47.729892           50.000000           3.785144     220.035503   \n",
       "4            44.007283           45.833333           3.822357     222.198758   \n",
       "...                ...                 ...                ...            ...   \n",
       "1286         49.761641           50.000000           3.930137     228.464115   \n",
       "1287         51.780593           51.065760           3.680511     213.953052   \n",
       "1288         48.545873           48.368079           3.935950     228.802083   \n",
       "1289         49.541361           50.000000           3.821431     222.144928   \n",
       "1290         50.479278           49.019608           3.478621     202.216931   \n",
       "\n",
       "      R_future  D50_mean_future  D50_median_future  theta_mean_diff  \\\n",
       "0     0.665845        48.384561          50.000000         0.160268   \n",
       "1     0.562262        49.510553          50.000000         0.448849   \n",
       "2     0.588810        49.686314          50.000000         0.180695   \n",
       "3     0.529504        49.676508          50.000000         0.130317   \n",
       "4     0.523637        49.619731          50.000000         0.232876   \n",
       "...        ...              ...                ...              ...   \n",
       "1286  0.366939        51.223931          50.000000        -0.146838   \n",
       "1287  0.453697        51.031805          50.000000        -0.115090   \n",
       "1288  0.381297        46.338815          45.833333         0.435986   \n",
       "1289  0.324373        50.571090          50.000000         0.062305   \n",
       "1290  0.207393        50.176580          48.571429        -0.226249   \n",
       "\n",
       "      D_mean_diff    R_diff  D50_mean_diff  D50_median_diff  sampling_duration  \n",
       "0        9.316619 -0.050316      -3.402670         0.000000           0.500000  \n",
       "1       26.092207 -0.083772       3.284768         0.000000           0.500000  \n",
       "2       10.504017 -0.070846       0.151959         0.000000           0.500000  \n",
       "3        7.575503 -0.186992       1.946617         0.000000           0.500000  \n",
       "4       13.537382 -0.157729       5.612448         4.166667           0.500000  \n",
       "...           ...       ...            ...              ...                ...  \n",
       "1286    -8.535885 -0.082340       1.462290         0.000000          24.000000  \n",
       "1287    -6.690331  0.130552      -0.748788        -1.065760          24.000000  \n",
       "1288    25.344456  0.057053      -2.207058        -2.534746          24.000000  \n",
       "1289     3.621851  0.043639       1.029729         0.000000          24.000000  \n",
       "1290   -13.152167 -0.137290      -0.302698        -0.448179          24.000000  \n",
       "\n",
       "[9037 rows x 17 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "311ef265",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_season = pd.concat([grouped_by_gauge_samplingdur_season_05_changes, grouped_by_gauge_samplingdur_season_1_changes, \n",
    "                  grouped_by_gauge_samplingdur_season_2_changes, grouped_by_gauge_samplingdur_season_3_changes,\n",
    "                  grouped_by_gauge_samplingdur_season_6_changes, grouped_by_gauge_samplingdur_season_12_changes,\n",
    "                  grouped_by_gauge_samplingdur_season_24_changes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_by_columns = ['Climate', 'gauge_num', 'duration', 'season']\n",
    "# grouped_by_gauge_samplingdur_season = group_data_calc_means(df_long, group_by_columns)\n",
    "# grouped_by_gauge_samplingdur_season_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur_season, group_by_columns)\n",
    "\n",
    "# group_by_columns = ['Climate', 'gauge_num', 'duration']\n",
    "# grouped_by_gauge_samplingdur = group_data_calc_means(df_long, group_by_columns)\n",
    "# grouped_by_gauge_samplingdur_changes = find_change_values_in_groups_new(grouped_by_gauge_samplingdur, group_by_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1076036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_by_gauge_samplingdur_season_changes.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_samplingdur_season_changes_new.csv\", index=False)\n",
    "total.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_changes_bydur.csv\", index=False)\n",
    "\n",
    "total_season.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_season_changes_bydur.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
