{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e69a6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f2c89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FormatEvents_Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594c9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/nfs/a319/gy17m2a/PhD/'\n",
    "home_dir2 = '/nfs/a161/gy17m2a/PhD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254b686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = ['0.5', '1', '2', '3', '6', '12', '24']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6eb2c",
   "metadata": {},
   "source": [
    "### UKCP18 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c4c4f",
   "metadata": {},
   "source": [
    "### Join together lists for different ensemble members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4bb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_props_dict_present = []\n",
    "ems_present = ['bc005', 'bc006', 'bc007', 'bc009', 'bc010', 'bc011', 'bc012', 'bc013', 'bc015', 'bc016', 'bc017', 'bc018']\n",
    "for em in ems_present:\n",
    "    with open(home_dir +  f\"ProcessedData/AMAX_Events/UKCP18_30mins/Present/event_props_dict_{em}.pickle\", 'rb') as handle:\n",
    "        one_events_props_dict_present = pickle.load(handle)    \n",
    "    events_props_dict_present = events_props_dict_present + one_events_props_dict_present\n",
    "    \n",
    "## Join into one dataframe    \n",
    "present = pd.DataFrame(events_props_dict_present)\n",
    "present['Climate'] = 'Present'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec28fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_props_dict_future = []\n",
    "# ems_future = ['bb195', 'bb192', 'bb198', 'bb208', 'bb225','bb222', 'bb201', 'bb204', 'bb216', 'bb219', 'bb211']\n",
    "ems_future = ['bb192', 'bb208', 'bb225','bb222', 'bb201', 'bb204', 'bb216', 'bb219', 'bb211', 'bb189'] #bb195, #bb198\n",
    "for em in ems_future:\n",
    "    with open(home_dir +  f\"ProcessedData/AMAX_Events/UKCP18_30mins/Future/event_props_dict_{em}.pickle\", 'rb') as handle:\n",
    "        one_events_props_dict_future = pickle.load(handle)    \n",
    "    events_props_dict_future = events_props_dict_future + one_events_props_dict_future\n",
    "    \n",
    "## Join into one dataframe\n",
    "future = pd.DataFrame(events_props_dict_future)\n",
    "future['Climate'] = 'Future'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8203f5",
   "metadata": {},
   "source": [
    "## Make a check on number of files (could shift this to the checking script)\n",
    "NB - the method of searching on part1 doesnt work, because the filename only represents on of the files that is represented by that event\n",
    "\n",
    "\n",
    "24529 is 19 * 1291 and is the number we expert with no part1s for one ensemble member.  \n",
    "For 12 ems it becomes 24529 * 12 = 294348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c6c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot histograms for present and future D50\n",
    "# plt.hist(future['D50'], bins=30, alpha=0.5, label='Present', color='blue')\n",
    "# plt.hist(future['D50_new'], bins=30, alpha=0.5, label='Future', color='orange')\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('D50')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of D50 - Present vs Future')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show plot\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af8ebc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = present[present['filename'].str.contains('part1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f39b058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24     327523\n",
      "12     297624\n",
      "6      294422\n",
      "0.5    294348\n",
      "1      294348\n",
      "2      294348\n",
      "3      294348\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure that values are treated as lists. If any single numbers are not in a list, convert them to lists.\n",
    "present['dur_for_which_this_is_amax'] = present['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# Flatten the lists and count occurrences of each number\n",
    "all_numbers = [num for sublist in present['dur_for_which_this_is_amax'] for num in sublist]\n",
    "number_counts = pd.Series(all_numbers).value_counts()\n",
    "\n",
    "# Show the result\n",
    "print(number_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8739b153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24     270114\n",
      "12     247512\n",
      "6      245335\n",
      "0.5    245290\n",
      "1      245290\n",
      "2      245290\n",
      "3      245290\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure that values are treated as lists. If any single numbers are not in a list, convert them to lists.\n",
    "future['dur_for_which_this_is_amax'] = future['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# Flatten the lists and count occurrences of each number\n",
    "all_numbers = [num for sublist in future['dur_for_which_this_is_amax'] for num in sublist]\n",
    "number_counts = pd.Series(all_numbers).value_counts()\n",
    "\n",
    "# Show the result\n",
    "print(number_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ec2bb",
   "metadata": {},
   "source": [
    "### Create one dataframe containing both present and future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a33225a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = pd.concat([present, future])\n",
    "\n",
    "# Add D variable (day of year) and date\n",
    "df_long['D'] = (df_long['theta'] * 365.25) / (2 * np.pi)\n",
    "df_long['date'] = df_long.apply(lambda row: date_from_D(row['D'], row['year']), axis=1)\n",
    "df_long['season'] = df_long['date'].apply(get_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be1aa28",
   "metadata": {},
   "source": [
    "### Check the number of files for each duration\n",
    "NB: Number of files for 24h duration is longer due to compound events  \n",
    "Checked this by filtering only rows with part0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13853b0",
   "metadata": {},
   "source": [
    "### Remove entries which are less than 1.5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad4fd78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_with_short_durations_kept = df_long.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd33065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long[df_long['duration'] >=1.5]\n",
    "present = present[present['duration'] >=1.5]\n",
    "future = future[future['duration'] >=1.5]\n",
    "# nan_rows = df_long[df_long['D50'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4ce11",
   "metadata": {},
   "source": [
    "### NIMROD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2bc859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_dir +  f\"ProcessedData/AMAX_Events/NIMROD_30mins/event_props_dict.pickle\", 'rb') as handle:\n",
    "    events_props_dict_nimrod = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f603319",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimrod = pd.DataFrame(events_props_dict_nimrod)\n",
    "# Add D variable (day of year) and date\n",
    "nimrod['D'] = (nimrod['theta'] * 365.25) / (2 * np.pi)\n",
    "nimrod['date'] = nimrod.apply(lambda row: date_from_D(row['D'], row['year']), axis=1)\n",
    "nimrod['season'] = nimrod['date'].apply(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4102701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24     19462\n",
      "0.5    19363\n",
      "12     14560\n",
      "6      11379\n",
      "2       8136\n",
      "1       7536\n",
      "3       6830\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure that values are treated as lists. If any single numbers are not in a list, convert them to lists.\n",
    "nimrod['dur_for_which_this_is_amax'] = nimrod['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# Flatten the lists and count occurrences of each number\n",
    "all_numbers = [num for sublist in nimrod['dur_for_which_this_is_amax'] for num in sublist]\n",
    "number_counts = pd.Series(all_numbers).value_counts()\n",
    "\n",
    "# Show the result\n",
    "print(number_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a27805f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24     19462\n",
      "0.5    19363\n",
      "12     14560\n",
      "6      11379\n",
      "2       8136\n",
      "1       7536\n",
      "3       6830\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure that values are treated as lists. If any single numbers are not in a list, convert them to lists.\n",
    "nimrod['dur_for_which_this_is_amax'] = nimrod['dur_for_which_this_is_amax'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# Flatten the lists and count occurrences of each number\n",
    "all_numbers = [num for sublist in nimrod['dur_for_which_this_is_amax'] for num in sublist]\n",
    "number_counts = pd.Series(all_numbers).value_counts()\n",
    "\n",
    "# Show the result\n",
    "print(number_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c62805e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimrod.to_csv(home_dir + f\"ProcessedData/AMAX_Events/NIMROD_30mins/all_events_characteristics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9c3f2d",
   "metadata": {},
   "source": [
    "# Create grouped results, for all events (no duplicates for durations)\n",
    "### Group by gauge, climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86c4341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num']\n",
    "grouped_by_gauge_allevents = group_data_calc_means(df_long, 'D50_new', group_by_columns)\n",
    "grouped_by_gauge_allevents_changes = find_change_values_in_groups_new(grouped_by_gauge_allevents, group_by_columns, 'All')\n",
    "grouped_by_gauge_allevents_changes.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_changes_allevents.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521afbb8",
   "metadata": {},
   "source": [
    "### Group by season, gauge, climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04471ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_columns = ['Climate', 'gauge_num', 'season']\n",
    "grouped_by_gauge_season_allevents = group_data_calc_means(df_long, 'D50_new', group_by_columns)\n",
    "grouped_by_gauge_season_allevents_changes = find_change_values_in_groups_new(grouped_by_gauge_season_allevents, group_by_columns, 'All')\n",
    "grouped_by_gauge_season_allevents_changes.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_season_changes_allevents.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dff98b",
   "metadata": {},
   "source": [
    "# Create grouped results, for all events (for each duration separately)\n",
    "### Group by gauge, climate and by season, gauge, climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe0a1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "each_dur_per_climate_changes = []\n",
    "each_dur_per_climate_and_season_changes = []\n",
    "\n",
    "# For each duration in turn\n",
    "for duration in durations:\n",
    "    # Get data for just this duration\n",
    "    this_dur = df_long[df_long['dur_for_which_this_is_amax'].apply(\n",
    "        lambda x: isinstance(x, list) and str(duration) in x or x == str(duration))]\n",
    "    \n",
    "    # Summary of events at each gauge, for this duration, one for present, one for future\n",
    "    summary_per_climate = group_data_calc_means(this_dur, 'D50_new', ['Climate', 'gauge_num'])\n",
    "    # Summary of events at each gauge, for this duration, one for each season for present, one for each season for future\n",
    "    summary_per_climate_and_season = group_data_calc_means(this_dur, 'D50_new', ['Climate', 'gauge_num', 'season'])\n",
    "    # Reformat, so one row per gauge, with change between present and future in the columns\n",
    "    summary_per_climate_changes = find_change_values_in_groups_new(summary_per_climate, ['Climate', 'gauge_num'], float(duration))\n",
    "    # Reformat, so four rows (each season) per gauge, with change between present and future in the columns\n",
    "    summary_per_climate_season_changes = find_change_values_in_groups_new(summary_per_climate_and_season, ['Climate', 'gauge_num', 'season'], float(duration))\n",
    "    \n",
    "    ## Add to lists\n",
    "    each_dur_per_climate_changes.append(summary_per_climate_changes)\n",
    "    each_dur_per_climate_and_season_changes.append(summary_per_climate_season_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "442a7b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat(each_dur_per_climate_changes)\n",
    "total_season = pd.concat(each_dur_per_climate_and_season_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1076036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_changes_bydur.csv\", index=False)\n",
    "total_season.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/grouped_by_gauge_season_changes_bydur.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8904609",
   "metadata": {},
   "source": [
    "### Save original data\n",
    "Don't do this higher up, because the json.dumps thing messes up the formatting for later stages of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "560d3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy and convert lists to JSON strings before saving - not doing this, messed up formatting a bit\n",
    "df_long['dur_for_which_this_is_amax'] = df_long['dur_for_which_this_is_amax'].apply(json.dumps)\n",
    "df_long.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/all_events_characteristics.csv\", index=False)\n",
    "df_long_with_short_durations_kept['dur_for_which_this_is_amax'] = df_long_with_short_durations_kept['dur_for_which_this_is_amax'].apply(json.dumps)\n",
    "df_long_with_short_durations_kept.to_csv(home_dir + f\"ProcessedData/AMAX_Events/UKCP18_30mins/all_events_characteristics_shortdurationskept.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
