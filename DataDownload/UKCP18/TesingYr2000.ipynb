{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13e37c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "import os\n",
    "import glob as glob\n",
    "import datetime as datetime\n",
    "import iris.coord_categorisation as cat\n",
    "import sys\n",
    "import iris.plot as iplt\n",
    "\n",
    "# Set up path to root directory\n",
    "root_fp = \"/nfs/a319/gy17m2a/PhD/\"\n",
    "os.chdir(root_fp)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Create path to files containing functions\n",
    "sys.path.insert(0, root_fp + 'Scripts/GlobalFunctions')\n",
    "from Spatial_plotting_functions import *\n",
    "from Spatial_geometry_functions import *\n",
    "\n",
    "\n",
    "# ### Load necessary spatial data\n",
    "# This is a square area surrounding Leeds\n",
    "leeds_at_centre_gdf = create_leeds_at_centre_outline({'init' :'epsg:3857'})\n",
    "\n",
    "\n",
    "# ### Establish the corresponding ensemble member numbers\n",
    "em_matching_dict = {'01':'bc005', '04': 'bc006', '05': 'bc007', '06':'bc009',  '07':'bc010', \n",
    "                    '08': 'bc011', '09':'bc013', '10': 'bc015', '11': 'bc016', '12': 'bc017', '13':'bc018', '15':'bc012'}\n",
    "\n",
    "resolution = '2.2km'\n",
    "yrs_range = \"2002_2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60bfac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_1hr = '05'\n",
    "em_30mins = em_matching_dict[em_1hr]\n",
    "month_num = '07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b3975",
   "metadata": {},
   "outputs": [],
   "source": [
    "for yr in range(2002,2021):\n",
    "    for month_num in ['06', '07', '08']:\n",
    "        print(yr, month_num)\n",
    "        ####################################################### \n",
    "        #######################################################\n",
    "        ## Get one month of data - HOURLY\n",
    "        ####################################################### \n",
    "        #######################################################\n",
    "        ### Get a list of filenames for hourly data\n",
    "        general_filename_1hr = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km/{em_1hr}/{yrs_range}/pr_rcp85_land-cpm_uk_2.2km_{em_1hr}_1hr_{yr}{month_num}*'\n",
    "        filenames_1hr = []\n",
    "        for filename in glob.glob(general_filename_1hr):\n",
    "                filenames_1hr.append(filename)\n",
    "\n",
    "        # If don't find any files matching this string in the 2001_2020 folder, then check the 1980_2001\n",
    "        if len(filenames_1hr) == 0:\n",
    "            general_filename_1hr = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km/{em_1hr}/1980_2001/pr_rcp85_land-cpm_uk_2.2km_{em_1hr}_1hr_{yr}{month_num}*'\n",
    "            for filename in glob.glob(general_filename_1hr):\n",
    "                    filenames_1hr.append(filename)\n",
    "\n",
    "                \n",
    "        # ### Load in the data and remove the ensemble member dimension\n",
    "        monthly_cubes_list_1hr = iris.load(filenames_1hr)\n",
    "        cube_1hr = monthly_cubes_list_1hr[0]\n",
    "        cube_1hr = cube_1hr[0,:,:,:]\n",
    "\n",
    "        #######################################################\n",
    "        #######################################################\n",
    "        ## Get one month of data - 30mins\n",
    "        #######################################################\n",
    "        #######################################################\n",
    "        # ### Get all files for this ensemble member\n",
    "        general_filename_30mins = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_first30mins/{yrs_range}/{em_30mins}/{em_30mins}a.pr{yr}{month_num}*'\n",
    "        filenames_first30mins = []\n",
    "        for filename_30mins in glob.glob(general_filename_30mins):\n",
    "            filenames_first30mins.append(filename_30mins)\n",
    "        filenames_first30mins.sort()\n",
    "\n",
    "        # ### Load in the data \n",
    "        monthly_cubes_list_30mins = iris.load(filenames_first30mins)\n",
    "\n",
    "        # Equalise\n",
    "        for cube in monthly_cubes_list_30mins:\n",
    "            for attr in ['forecast_period', 'forecast_reference_time']:\n",
    "                if attr in cube.attributes:\n",
    "                    del cube.attributes[attr]\n",
    "\n",
    "\n",
    "        monthly_cube_30mins = monthly_cubes_list_30mins.concatenate_cube()      \n",
    "\n",
    "\n",
    "        # ### Trim to be the same shape as the hourly data\n",
    "        monthly_cube_30mins_1st = monthly_cube_30mins[:,24:-24,24:-24]\n",
    "\n",
    "        # ### Convert units of 30 mins data\n",
    "        # Check current units\n",
    "        # print(monthly_cube_30mins_1st.units)\n",
    "        # Set the units to those of the 1 hr cube\n",
    "        monthly_cube_30mins_1st.units = cube_1hr.units\n",
    "        # print(monthly_cube_30mins_1st.units)\n",
    "\n",
    "        # Convert the data to also be this unit\n",
    "        monthly_cube_30mins_1st_data = monthly_cube_30mins_1st.data\n",
    "        monthly_cube_30mins_1st_data = monthly_cube_30mins_1st_data*3600\n",
    "\n",
    "        monthly_cube_30mins_1st.data = monthly_cube_30mins_1st_data\n",
    "\n",
    "\n",
    "        #######################################################\n",
    "        #######################################################\n",
    "        ## Find the second half of the hour, using the first half of hour and hourly values\n",
    "        #######################################################\n",
    "        #######################################################\n",
    "        # get the hourly data\n",
    "        cube_1hr_data = cube_1hr.data\n",
    "        # calculate value for second half of hour\n",
    "        second_half_of_the_hour_mean_hourly_rainfall_rate_data = (2.0 *cube_1hr_data)-monthly_cube_30mins_1st_data\n",
    "        # Create a new cube for the second half of the hour (start by copying the first half of hour cube)\n",
    "        monthly_cube_30mins_2nd = monthly_cube_30mins_1st.copy()\n",
    "        # Set values as calculated\n",
    "        monthly_cube_30mins_2nd.data = second_half_of_the_hour_mean_hourly_rainfall_rate_data\n",
    "\n",
    "\n",
    "        # ### Edit the times to be 30 mins later\n",
    "        # get the times from the first half hour\n",
    "        first_half_hour_times = monthly_cube_30mins_1st.coord('time').copy()\n",
    "        # add 30 mins\n",
    "        second_half_hour_times = first_half_hour_times + 0.5\n",
    "        # for the second hald hour cube, remove the time dimension and then re-add the edited one\n",
    "        monthly_cube_30mins_2nd.remove_coord('time')\n",
    "        monthly_cube_30mins_2nd.add_dim_coord(second_half_hour_times, 0)\n",
    "\n",
    "\n",
    "        print(f\"minimum 1st half hour is {np.nanmin(monthly_cube_30mins_1st.data):.2f}\")\n",
    "        print(f\"minimum whole hour is {np.nanmin(cube_1hr.data):.2f}\")\n",
    "        print(f\"minimum 2nd half hour is {np.nanmin(monthly_cube_30mins_2nd.data):.2f}\")\n",
    "\n",
    "        print(f\"mean 1st half hour is {np.nanmean(monthly_cube_30mins_1st.data):.5f}\")\n",
    "        print(f\"mean whole hour is {np.nanmean(cube_1hr.data):.5f}\")\n",
    "        print(f\"mean 2nd half hour is {np.nanmean(monthly_cube_30mins_2nd.data):.5f}\")\n",
    "\n",
    "        print(f\"max 1st half hour is {np.nanmax(monthly_cube_30mins_1st.data):.2f}\")\n",
    "        print(f\"max whole hour is {np.nanmax(cube_1hr.data):.2f}\")\n",
    "        print(f\"max 2nd half hour is {np.nanmax(monthly_cube_30mins_2nd.data):.2f}\")\n",
    "\n",
    "        cube_1hr_flat = cube_1hr.data.data.flatten()\n",
    "        flat = second_half_of_the_hour_mean_hourly_rainfall_rate_data.data.flatten()\n",
    "        df = pd.DataFrame({'hr':cube_1hr_flat, '1st_half':monthly_cube_30mins_1st_data.flatten(), '2nd_half': flat})\n",
    "        sorted_df = df.sort_values(by='hr')\n",
    "\n",
    "        # Find instances where when there is no rain in the hourly data, there is in the 30 mins\n",
    "        hour_0 = df[df['hr'] == 0]\n",
    "        print(f\"DF of rows with a val in 1st half hour, but not in full hour {hour_0[hour_0['1st_half']>0.001]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dda2fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 1st half hour is 0.00\n",
      "minimum whole hour is 0.00\n",
      "minimum 2nd half hour is -181.00\n",
      "mean 1st half hour is 0.08368\n",
      "mean whole hour is 0.13337\n",
      "mean 2nd half hour is 0.18306\n",
      "max 1st half hour is 181.00\n",
      "max whole hour is 74.68\n",
      "max 2nd half hour is 149.35\n"
     ]
    }
   ],
   "source": [
    "month_num = '06'\n",
    "yr = 2020\n",
    "\n",
    "####################################################### \n",
    "#######################################################\n",
    "## Get one month of data - HOURLY\n",
    "####################################################### \n",
    "#######################################################\n",
    "### Get a list of filenames for hourly data\n",
    "general_filename_1hr = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km/{em_1hr}/{yrs_range}/pr_rcp85_land-cpm_uk_2.2km_{em_1hr}_1hr_{yr}{month_num}*'\n",
    "filenames_1hr = []\n",
    "for filename in glob.glob(general_filename_1hr):\n",
    "        filenames_1hr.append(filename)\n",
    "\n",
    "# If don't find any files matching this string in the 2001_2020 folder, then check the 1980_2001\n",
    "if len(filenames_1hr) == 0:\n",
    "    general_filename_1hr = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km/{em_1hr}/1980_2001/pr_rcp85_land-cpm_uk_2.2km_{em_1hr}_1hr_{yr}{month_num}*'\n",
    "    for filename in glob.glob(general_filename_1hr):\n",
    "            filenames_1hr.append(filename)\n",
    "\n",
    "\n",
    "# ### Load in the data and remove the ensemble member dimension\n",
    "monthly_cubes_list_1hr = iris.load(filenames_1hr)\n",
    "cube_1hr = monthly_cubes_list_1hr[0]\n",
    "cube_1hr = cube_1hr[0,:,:,:]\n",
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "## Get one month of data - 30mins\n",
    "#######################################################\n",
    "#######################################################\n",
    "# ### Get all files for this ensemble member\n",
    "general_filename_30mins = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_first30mins/{yrs_range}/{em_30mins}/{em_30mins}a.pr{yr}{month_num}*'\n",
    "filenames_first30mins = []\n",
    "for filename_30mins in glob.glob(general_filename_30mins):\n",
    "    filenames_first30mins.append(filename_30mins)\n",
    "filenames_first30mins.sort()\n",
    "\n",
    "# ### Load in the data \n",
    "monthly_cubes_list_30mins = iris.load(filenames_first30mins)\n",
    "\n",
    "# Equalise\n",
    "for cube in monthly_cubes_list_30mins:\n",
    "    for attr in ['forecast_period', 'forecast_reference_time']:\n",
    "        if attr in cube.attributes:\n",
    "            del cube.attributes[attr]\n",
    "\n",
    "\n",
    "monthly_cube_30mins = monthly_cubes_list_30mins.concatenate_cube()      \n",
    "\n",
    "\n",
    "# ### Trim to be the same shape as the hourly data\n",
    "monthly_cube_30mins_1st = monthly_cube_30mins[:,24:-24,24:-24]\n",
    "\n",
    "# ### Convert units of 30 mins data\n",
    "# Check current units\n",
    "# print(monthly_cube_30mins_1st.units)\n",
    "# Set the units to those of the 1 hr cube\n",
    "monthly_cube_30mins_1st.units = cube_1hr.units\n",
    "# print(monthly_cube_30mins_1st.units)\n",
    "\n",
    "# Convert the data to also be this unit\n",
    "monthly_cube_30mins_1st_data = monthly_cube_30mins_1st.data\n",
    "monthly_cube_30mins_1st_data = monthly_cube_30mins_1st_data*3600\n",
    "\n",
    "monthly_cube_30mins_1st.data = monthly_cube_30mins_1st_data\n",
    "\n",
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "## Find the second half of the hour, using the first half of hour and hourly values\n",
    "#######################################################\n",
    "#######################################################\n",
    "# get the hourly data\n",
    "cube_1hr_data = cube_1hr.data\n",
    "# calculate value for second half of hour\n",
    "second_half_of_the_hour_mean_hourly_rainfall_rate_data = (2.0 *cube_1hr_data)-monthly_cube_30mins_1st_data\n",
    "# Create a new cube for the second half of the hour (start by copying the first half of hour cube)\n",
    "monthly_cube_30mins_2nd = monthly_cube_30mins_1st.copy()\n",
    "# Set values as calculated\n",
    "monthly_cube_30mins_2nd.data = second_half_of_the_hour_mean_hourly_rainfall_rate_data\n",
    "\n",
    "\n",
    "# ### Edit the times to be 30 mins later\n",
    "# get the times from the first half hour\n",
    "first_half_hour_times = monthly_cube_30mins_1st.coord('time').copy()\n",
    "# add 30 mins\n",
    "second_half_hour_times = first_half_hour_times + 0.5\n",
    "# for the second hald hour cube, remove the time dimension and then re-add the edited one\n",
    "monthly_cube_30mins_2nd.remove_coord('time')\n",
    "monthly_cube_30mins_2nd.add_dim_coord(second_half_hour_times, 0)\n",
    "\n",
    "\n",
    "print(f\"minimum 1st half hour is {np.nanmin(monthly_cube_30mins_1st.data):.2f}\")\n",
    "print(f\"minimum whole hour is {np.nanmin(cube_1hr.data):.2f}\")\n",
    "print(f\"minimum 2nd half hour is {np.nanmin(monthly_cube_30mins_2nd.data):.2f}\")\n",
    "\n",
    "print(f\"mean 1st half hour is {np.nanmean(monthly_cube_30mins_1st.data):.5f}\")\n",
    "print(f\"mean whole hour is {np.nanmean(cube_1hr.data):.5f}\")\n",
    "print(f\"mean 2nd half hour is {np.nanmean(monthly_cube_30mins_2nd.data):.5f}\")\n",
    "\n",
    "print(f\"max 1st half hour is {np.nanmax(monthly_cube_30mins_1st.data):.2f}\")\n",
    "print(f\"max whole hour is {np.nanmax(cube_1hr.data):.2f}\")\n",
    "print(f\"max 2nd half hour is {np.nanmax(monthly_cube_30mins_2nd.data):.2f}\")\n",
    "\n",
    "# cube_1hr_flat = cube_1hr.data.data.flatten()\n",
    "# flat = second_half_of_the_hour_mean_hourly_rainfall_rate_data.data.flatten()\n",
    "# df = pd.DataFrame({'hr':cube_1hr_flat, '1st_half':monthly_cube_30mins_1st_data.flatten(), '2nd_half': flat})\n",
    "# sorted_df = df.sort_values(by='hr')\n",
    "\n",
    "# # Find instances where when there is no rain in the hourly data, there is in the 30 mins\n",
    "# hour_0 = df[df['hr'] == 0]\n",
    "# print(f\"DF of rows with a val in 1st half hour, but not in full hour {hour_0[hour_0['1st_half']>0.001]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6acaf00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum 1st half hour is 0.00\n",
      "minimum whole hour is 0.00\n",
      "minimum 2nd half hour is -117.00\n",
      "mean 1st half hour is 0.10422\n",
      "mean whole hour is 0.13337\n",
      "mean 2nd half hour is 0.16252\n",
      "max 1st half hour is 117.10\n",
      "max whole hour is 74.68\n",
      "max 2nd half hour is 149.35\n"
     ]
    }
   ],
   "source": [
    "month_num = '07'\n",
    "yr = 2020\n",
    "\n",
    "####################################################### \n",
    "#######################################################\n",
    "## Get one month of data - HOURLY\n",
    "####################################################### \n",
    "#######################################################\n",
    "### Get a list of filenames for hourly data\n",
    "general_filename_1hr = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km/{em_1hr}/{yrs_range}/pr_rcp85_land-cpm_uk_2.2km_{em_1hr}_1hr_{yr}{month_num}*'\n",
    "filenames_1hr = []\n",
    "for filename in glob.glob(general_filename_1hr):\n",
    "        filenames_1hr.append(filename)\n",
    "\n",
    "# If don't find any files matching this string in the 2001_2020 folder, then check the 1980_2001\n",
    "if len(filenames_1hr) == 0:\n",
    "    general_filename_1hr = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km/{em_1hr}/1980_2001/pr_rcp85_land-cpm_uk_2.2km_{em_1hr}_1hr_{yr}{month_num}*'\n",
    "    for filename in glob.glob(general_filename_1hr):\n",
    "            filenames_1hr.append(filename)\n",
    "\n",
    "\n",
    "# ### Load in the data and remove the ensemble member dimension\n",
    "monthly_cubes_list_1hr = iris.load(filenames_1hr)\n",
    "cube_1hr = monthly_cubes_list_1hr[0]\n",
    "cube_1hr = cube_1hr[0,:,:,:]\n",
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "## Get one month of data - 30mins\n",
    "#######################################################\n",
    "#######################################################\n",
    "# ### Get all files for this ensemble member\n",
    "general_filename_30mins = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_first30mins/{yrs_range}/{em_30mins}/{em_30mins}a.pr{yr}{month_num}*'\n",
    "filenames_first30mins = []\n",
    "for filename_30mins in glob.glob(general_filename_30mins):\n",
    "    filenames_first30mins.append(filename_30mins)\n",
    "filenames_first30mins.sort()\n",
    "\n",
    "# ### Load in the data \n",
    "monthly_cubes_list_30mins = iris.load(filenames_first30mins)\n",
    "\n",
    "# Equalise\n",
    "for cube in monthly_cubes_list_30mins:\n",
    "    for attr in ['forecast_period', 'forecast_reference_time']:\n",
    "        if attr in cube.attributes:\n",
    "            del cube.attributes[attr]\n",
    "\n",
    "\n",
    "monthly_cube_30mins = monthly_cubes_list_30mins.concatenate_cube()      \n",
    "\n",
    "\n",
    "# ### Trim to be the same shape as the hourly data\n",
    "monthly_cube_30mins_1st = monthly_cube_30mins[:,24:-24,24:-24]\n",
    "\n",
    "# ### Convert units of 30 mins data\n",
    "# Check current units\n",
    "# print(monthly_cube_30mins_1st.units)\n",
    "# Set the units to those of the 1 hr cube\n",
    "monthly_cube_30mins_1st.units = cube_1hr.units\n",
    "# print(monthly_cube_30mins_1st.units)\n",
    "\n",
    "# Convert the data to also be this unit\n",
    "monthly_cube_30mins_1st_data = monthly_cube_30mins_1st.data\n",
    "monthly_cube_30mins_1st_data = monthly_cube_30mins_1st_data*3600\n",
    "\n",
    "monthly_cube_30mins_1st.data = monthly_cube_30mins_1st_data\n",
    "\n",
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "## Find the second half of the hour, using the first half of hour and hourly values\n",
    "#######################################################\n",
    "#######################################################\n",
    "# get the hourly data\n",
    "cube_1hr_data = cube_1hr.data\n",
    "# calculate value for second half of hour\n",
    "second_half_of_the_hour_mean_hourly_rainfall_rate_data = (2.0 *cube_1hr_data)-monthly_cube_30mins_1st_data\n",
    "# Create a new cube for the second half of the hour (start by copying the first half of hour cube)\n",
    "monthly_cube_30mins_2nd = monthly_cube_30mins_1st.copy()\n",
    "# Set values as calculated\n",
    "monthly_cube_30mins_2nd.data = second_half_of_the_hour_mean_hourly_rainfall_rate_data\n",
    "\n",
    "\n",
    "# ### Edit the times to be 30 mins later\n",
    "# get the times from the first half hour\n",
    "first_half_hour_times = monthly_cube_30mins_1st.coord('time').copy()\n",
    "# add 30 mins\n",
    "second_half_hour_times = first_half_hour_times + 0.5\n",
    "# for the second hald hour cube, remove the time dimension and then re-add the edited one\n",
    "monthly_cube_30mins_2nd.remove_coord('time')\n",
    "monthly_cube_30mins_2nd.add_dim_coord(second_half_hour_times, 0)\n",
    "\n",
    "\n",
    "print(f\"minimum 1st half hour is {np.nanmin(monthly_cube_30mins_1st.data):.2f}\")\n",
    "print(f\"minimum whole hour is {np.nanmin(cube_1hr.data):.2f}\")\n",
    "print(f\"minimum 2nd half hour is {np.nanmin(monthly_cube_30mins_2nd.data):.2f}\")\n",
    "\n",
    "print(f\"mean 1st half hour is {np.nanmean(monthly_cube_30mins_1st.data):.5f}\")\n",
    "print(f\"mean whole hour is {np.nanmean(cube_1hr.data):.5f}\")\n",
    "print(f\"mean 2nd half hour is {np.nanmean(monthly_cube_30mins_2nd.data):.5f}\")\n",
    "\n",
    "print(f\"max 1st half hour is {np.nanmax(monthly_cube_30mins_1st.data):.2f}\")\n",
    "print(f\"max whole hour is {np.nanmax(cube_1hr.data):.2f}\")\n",
    "print(f\"max 2nd half hour is {np.nanmax(monthly_cube_30mins_2nd.data):.2f}\")\n",
    "\n",
    "# cube_1hr_flat = cube_1hr.data.data.flatten()\n",
    "# flat = second_half_of_the_hour_mean_hourly_rainfall_rate_data.data.flatten()\n",
    "# df = pd.DataFrame({'hr':cube_1hr_flat, '1st_half':monthly_cube_30mins_1st_data.flatten(), '2nd_half': flat})\n",
    "# sorted_df = df.sort_values(by='hr')\n",
    "\n",
    "# # Find instances where when there is no rain in the hourly data, there is in the 30 mins\n",
    "# hour_0 = df[df['hr'] == 0]\n",
    "# print(f\"DF of rows with a val in 1st half hour, but not in full hour {hour_0[hour_0['1st_half']>0.001]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
