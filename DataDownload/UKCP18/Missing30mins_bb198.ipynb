{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6315c3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em06, yr 2061, month 05\n",
      "already exists\n",
      "em06, yr 2062, month 05\n",
      "already exists\n",
      "em06, yr 2063, month 05\n",
      "already exists\n",
      "em06, yr 2064, month 05\n",
      "already exists\n",
      "em06, yr 2065, month 05\n",
      "already exists\n",
      "em06, yr 2066, month 05\n",
      "already exists\n",
      "em06, yr 2067, month 05\n",
      "already exists\n",
      "em06, yr 2068, month 05\n",
      "already exists\n",
      "em06, yr 2069, month 05\n",
      "already exists\n",
      "em06, yr 2070, month 05\n",
      "already exists\n",
      "em06, yr 2071, month 05\n",
      "already exists\n",
      "em06, yr 2072, month 05\n",
      "already exists\n",
      "em06, yr 2073, month 05\n",
      "already exists\n",
      "em06, yr 2074, month 05\n",
      "already exists\n",
      "em06, yr 2075, month 05\n",
      "already exists\n",
      "em06, yr 2076, month 05\n",
      "already exists\n",
      "em06, yr 2077, month 05\n",
      "already exists\n",
      "em06, yr 2078, month 05\n",
      "already exists\n",
      "em06, yr 2079, month 05\n",
      "already exists\n",
      "em06, yr 2080, month 05\n",
      "already exists\n"
     ]
    }
   ],
   "source": [
    "# bc018, bc016, bc015, bc011, bc010,\n",
    "\n",
    "import iris\n",
    "import os\n",
    "import glob as glob\n",
    "import datetime as datetime\n",
    "import iris.coord_categorisation as cat\n",
    "import sys\n",
    "import iris.plot as iplt\n",
    "\n",
    "# Set up path to root directory\n",
    "root_fp = \"/nfs/a319/gy17m2a/PhD/\"\n",
    "os.chdir(root_fp)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Create path to files containing functions\n",
    "sys.path.insert(0, root_fp + 'Scripts/GlobalFunctions')\n",
    "from Spatial_plotting_functions import *\n",
    "from Spatial_geometry_functions import *\n",
    "\n",
    "# ### Load necessary spatial data\n",
    "# This is a square area surrounding Leeds\n",
    "leeds_at_centre_gdf = create_leeds_at_centre_outline({'init' :'epsg:3857'})\n",
    "\n",
    "# ### Establish the corresponding ensemble member numbers\n",
    "em_matching_dict = {'01':'bc005', '04': 'bc006', '05': 'bc007', '06':'bc009',  '07':'bc010', \n",
    "                    '08': 'bc011', '09':'bc013', '10': 'bc015', '11': 'bc016', '12': 'bc017', '13':'bc018', '15':'bc012'}\n",
    "em_matching_dict = {'01': 'bb189', '06':'bb198'}\n",
    "\n",
    "resolution = '2.2km_original'\n",
    "yrs_range = \"2060_2081\" #\n",
    "\n",
    "for em_1hr in ['06']:\n",
    "    em_30mins = em_matching_dict[em_1hr]\n",
    "\n",
    "    for yr in range(2061,2081):\n",
    "        for month_num in ['05']:\n",
    "            print(f\"em{em_1hr}, yr {yr}, month {month_num}\")\n",
    "            if (os.path.isfile(f\"/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/{resolution}/{yrs_range}/{em_30mins}/{em_30mins}a.pr{yr}{month_num}.nc\")):\n",
    "                print(\"already exists\")\n",
    "            else:\n",
    "                print(f\"Running for month {month_num} in {yr}, for {em_1hr} (which equatees to {em_30mins})\")\n",
    "\n",
    "                ####################################################### \n",
    "                #######################################################\n",
    "                ## Get one month of data - HOURLY\n",
    "                ####################################################### \n",
    "                #######################################################\n",
    "                ### Get a list of filenames for hourly data\n",
    "                general_filename_1hr = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/{em_1hr}/{yrs_range}/pr_rcp85_land-cpm_uk_2.2km_{em_1hr}_1hr_{yr}{month_num}*'\n",
    "                filenames_1hr = []\n",
    "                for filename in glob.glob(general_filename_1hr):\n",
    "                        filenames_1hr.append(filename)\n",
    "\n",
    "                # ### Load in the data and remove the ensemble member dimension\n",
    "                monthly_cubes_list_1hr = iris.load(filenames_1hr)\n",
    "                cube_1hr = monthly_cubes_list_1hr[0]\n",
    "                cube_1hr = cube_1hr[0,:,:,:]\n",
    "\n",
    "                # ### Trim to Leeds\n",
    "                # cube_1hr = trim_to_bbox_of_region(cube_1hr, leeds_at_centre_gdf)\n",
    "\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                ## Get one month of data - 30mins\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                # ### Get all files for this ensemble member\n",
    "                general_filename_30mins = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_first30mins/{yrs_range}/{em_30mins}/{em_30mins}a.pr{yr}{month_num}*'\n",
    "                filenames_first30mins = []\n",
    "                for filename_30mins in glob.glob(general_filename_30mins):\n",
    "                    filenames_first30mins.append(filename_30mins)\n",
    "                filenames_first30mins.sort()\n",
    "\n",
    "                # ### Load in the data \n",
    "                monthly_cubes_list_30mins = iris.load(filenames_first30mins)\n",
    "\n",
    "                # Equalise\n",
    "                for cube in monthly_cubes_list_30mins:\n",
    "                    for attr in ['forecast_period', 'forecast_reference_time']:\n",
    "                        if attr in cube.attributes:\n",
    "                            del cube.attributes[attr]\n",
    "\n",
    "\n",
    "                monthly_cube_30mins = monthly_cubes_list_30mins.concatenate_cube()      \n",
    "\n",
    "                # ### Trim to be the same shape as the hourly data\n",
    "                # monthly_cube_30mins_1st = trim_to_bbox_of_region_30mins(monthly_cube_30mins, leeds_at_centre_gdf)\n",
    "                monthly_cube_30mins_1st = monthly_cube_30mins[:,24:-24,24:-24]\n",
    "\n",
    "                # ### Convert units of 30 mins data\n",
    "                # Check current units\n",
    "                # print(monthly_cube_30mins_1st.units)\n",
    "                # Set the units to those of the 1 hr cube\n",
    "                monthly_cube_30mins_1st.units = cube_1hr.units\n",
    "                # print(monthly_cube_30mins_1st.units)\n",
    "\n",
    "                # Convert the data to also be this unit\n",
    "                monthly_cube_30mins_1st_data = monthly_cube_30mins_1st.data\n",
    "                monthly_cube_30mins_1st_data = monthly_cube_30mins_1st_data*3600\n",
    "\n",
    "                monthly_cube_30mins_1st.data = monthly_cube_30mins_1st_data\n",
    "\n",
    "\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                ## Find the second half of the hour, using the first half of hour and hourly values\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                # get the hourly data\n",
    "                cube_1hr_data = cube_1hr.data\n",
    "                # calculate value for second half of hour\n",
    "                second_half_of_the_hour_mean_hourly_rainfall_rate_data = 2*cube_1hr_data-monthly_cube_30mins_1st_data\n",
    "                # Create a new cube for the second half of the hour (start by copying the first half of hour cube)\n",
    "                monthly_cube_30mins_2nd = monthly_cube_30mins_1st.copy()\n",
    "                # Set values as calculated\n",
    "                monthly_cube_30mins_2nd.data = second_half_of_the_hour_mean_hourly_rainfall_rate_data\n",
    "\n",
    "\n",
    "                # ### Edit the times to be 30 mins later\n",
    "                # get the times from the first half hour\n",
    "                first_half_hour_times = monthly_cube_30mins_1st.coord('time').copy()\n",
    "                # add 30 mins\n",
    "                second_half_hour_times = first_half_hour_times + 0.5\n",
    "                # for the second hald hour cube, remove the time dimension and then re-add the edited one\n",
    "                monthly_cube_30mins_2nd.remove_coord('time')\n",
    "                monthly_cube_30mins_2nd.add_dim_coord(second_half_hour_times, 0)\n",
    "\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                ## Join first half hour and second half hour into one cube\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                # ### Get a list of all the cubes in each of the monthly cubes\n",
    "                list_30mins_1st = iris.cube.CubeList(monthly_cube_30mins_1st.slices_over('time'))\n",
    "                list_30mins_2nd = iris.cube.CubeList(monthly_cube_30mins_2nd.slices_over('time'))\n",
    "                list_30mins = list_30mins_1st +  list_30mins_2nd\n",
    "\n",
    "                ### Merge back into one cube\n",
    "                monthly_cube_30mins = list_30mins.merge_cube()\n",
    "\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                ## Save\n",
    "                #######################################################\n",
    "                #######################################################\n",
    "                dir_to_save = f\"datadir/UKCP18_every30mins/{resolution}/{yrs_range}/{em_30mins}/\"\n",
    "\n",
    "                if os.path.isdir(dir_to_save):\n",
    "                    print(\"Exists\")\n",
    "                else:\n",
    "                    print(\"Doesn't exist\")\n",
    "                    os.makedirs(dir_to_save)\n",
    "                fp_to_save = f\"datadir/UKCP18_every30mins/{resolution}/{yrs_range}/{em_30mins}/{em_30mins}a.pr{yr}{month_num}.nc\" \n",
    "                print(fp_to_save)\n",
    "                print(np.nanmin(monthly_cube_30mins.data))\n",
    "                iris.save(monthly_cube_30mins, fp_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ffcd13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/2.2km_original/2060_2081/bb198/bb198a.pr208005.nc'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/{resolution}/{yrs_range}/{em_30mins}/{em_30mins}a.pr{yr}{month_num}.nc\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
