{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75a57bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em06, yr 2060, month 01\n",
      "Running for month 01 in 2060, for 06 (which equatees to bb198)\n",
      "[]\n",
      "No files for this year\n",
      "em06, yr 2060, month 02\n",
      "Running for month 02 in 2060, for 06 (which equatees to bb198)\n",
      "[]\n",
      "No files for this year\n",
      "em06, yr 2060, month 03\n",
      "Running for month 03 in 2060, for 06 (which equatees to bb198)\n",
      "[]\n",
      "No files for this year\n",
      "em06, yr 2060, month 04\n",
      "Running for month 04 in 2060, for 06 (which equatees to bb198)\n",
      "[]\n",
      "No files for this year\n",
      "em06, yr 2060, month 05\n",
      "Running for month 05 in 2060, for 06 (which equatees to bb198)\n",
      "[]\n",
      "No files for this year\n",
      "em06, yr 2060, month 09\n",
      "Running for month 09 in 2060, for 06 (which equatees to bb198)\n",
      "[]\n",
      "No files for this year\n",
      "em06, yr 2060, month 10\n",
      "Running for month 10 in 2060, for 06 (which equatees to bb198)\n",
      "[]\n",
      "No files for this year\n",
      "em06, yr 2060, month 11\n",
      "Running for month 11 in 2060, for 06 (which equatees to bb198)\n",
      "[]\n",
      "No files for this year\n",
      "em06, yr 2060, month 12\n",
      "already exists\n",
      "em06, yr 2061, month 01\n",
      "Running for month 01 in 2061, for 06 (which equatees to bb198)\n",
      "['/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/06/2060_2081/pr_rcp85_land-cpm_uk_2.2km_06_1hr_20610101-20610130.nc']\n",
      "Exists\n",
      "datadir/UKCP18_every30mins/2.2km_original/bb198/2060_2081/bb198a.pr206101.nc\n",
      "em06, yr 2061, month 02\n",
      "Running for month 02 in 2061, for 06 (which equatees to bb198)\n",
      "['/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/06/2060_2081/pr_rcp85_land-cpm_uk_2.2km_06_1hr_20610201-20610230.nc']\n",
      "Exists\n",
      "datadir/UKCP18_every30mins/2.2km_original/bb198/2060_2081/bb198a.pr206102.nc\n",
      "em06, yr 2061, month 03\n",
      "Running for month 03 in 2061, for 06 (which equatees to bb198)\n",
      "['/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/06/2060_2081/pr_rcp85_land-cpm_uk_2.2km_06_1hr_20610301-20610330.nc']\n",
      "Exists\n",
      "datadir/UKCP18_every30mins/2.2km_original/bb198/2060_2081/bb198a.pr206103.nc\n",
      "em06, yr 2061, month 04\n",
      "Running for month 04 in 2061, for 06 (which equatees to bb198)\n",
      "['/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/06/2060_2081/pr_rcp85_land-cpm_uk_2.2km_06_1hr_20610401-20610430.nc']\n",
      "Exists\n",
      "datadir/UKCP18_every30mins/2.2km_original/bb198/2060_2081/bb198a.pr206104.nc\n",
      "em06, yr 2061, month 05\n",
      "Running for month 05 in 2061, for 06 (which equatees to bb198)\n",
      "['/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/06/2060_2081/pr_rcp85_land-cpm_uk_2.2km_06_1hr_20610501-20610530.nc']\n",
      "Exists\n",
      "datadir/UKCP18_every30mins/2.2km_original/bb198/2060_2081/bb198a.pr206105.nc\n",
      "em06, yr 2061, month 09\n",
      "Running for month 09 in 2061, for 06 (which equatees to bb198)\n",
      "['/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/06/2060_2081/pr_rcp85_land-cpm_uk_2.2km_06_1hr_20610901-20610930.nc']\n",
      "Exists\n",
      "datadir/UKCP18_every30mins/2.2km_original/bb198/2060_2081/bb198a.pr206109.nc\n",
      "em06, yr 2061, month 10\n",
      "Running for month 10 in 2061, for 06 (which equatees to bb198)\n",
      "['/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/06/2060_2081/pr_rcp85_land-cpm_uk_2.2km_06_1hr_20611001-20611030.nc']\n",
      "Exists\n",
      "datadir/UKCP18_every30mins/2.2km_original/bb198/2060_2081/bb198a.pr206110.nc\n",
      "em06, yr 2061, month 11\n",
      "Running for month 11 in 2061, for 06 (which equatees to bb198)\n",
      "['/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/06/2060_2081/pr_rcp85_land-cpm_uk_2.2km_06_1hr_20611101-20611130.nc']\n",
      "Exists\n",
      "datadir/UKCP18_every30mins/2.2km_original/bb198/2060_2081/bb198a.pr206111.nc\n",
      "em06, yr 2061, month 12\n",
      "Running for month 12 in 2061, for 06 (which equatees to bb198)\n",
      "['/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/06/2060_2081/pr_rcp85_land-cpm_uk_2.2km_06_1hr_20611201-20611230.nc']\n",
      "Exists\n",
      "datadir/UKCP18_every30mins/2.2km_original/bb198/2060_2081/bb198a.pr206112.nc\n"
     ]
    }
   ],
   "source": [
    "# bc018, bc016, bc015, bc011, bc010,\n",
    "\n",
    "import iris\n",
    "import os\n",
    "import glob as glob\n",
    "import datetime as datetime\n",
    "import iris.coord_categorisation as cat\n",
    "import sys\n",
    "import iris.plot as iplt\n",
    "\n",
    "# Set up path to root directory\n",
    "root_fp = \"/nfs/a319/gy17m2a/PhD/\"\n",
    "os.chdir(root_fp)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Create path to files containing functions\n",
    "sys.path.insert(0, root_fp + 'Scripts/GlobalFunctions')\n",
    "from Spatial_plotting_functions import *\n",
    "from Spatial_geometry_functions import *\n",
    "\n",
    "# ### Load necessary spatial data\n",
    "# This is a square area surrounding Leeds\n",
    "leeds_at_centre_gdf = create_leeds_at_centre_outline({'init' :'epsg:3857'})\n",
    "\n",
    "# ### Establish the corresponding ensemble member numbers\n",
    "em_matching_dict = {'01':'bc005', '04': 'bc006', '05': 'bc007', '06':'bc009',  '07':'bc010', \n",
    "                    '08': 'bc011', '09':'bc013', '10': 'bc015', '11': 'bc016', '12': 'bc017', '13':'bc018', '15':'bc012'}\n",
    "\n",
    "em_matching_dict_future = {'01':'bb189', '04': 'bb192', '05': 'bb195', '06':'bb198',  '07':'bc010', \n",
    "                    '08': 'bc011', '09':'bc013', '10': 'bc015', '11': 'bc016', '12': 'bc017', '13':'bc018', '15':'bc012'}\n",
    "\n",
    "\n",
    "resolution = '2.2km_original'\n",
    "yrs_range = \"2060_2081\"\n",
    "# em_1hr = '05'\n",
    "# yr = 2012\n",
    "# month_num = '06'\n",
    "\n",
    "# for em_1hr in ['01', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '15']:\n",
    "for em_1hr in ['06']:\n",
    "    em_30mins = em_matching_dict_future[em_1hr]\n",
    "    for yr in range(2060,2062):\n",
    "        for month_num in ['01', '02', '03', '04', '05', '09', '10','11','12']:\n",
    "            print(f\"em{em_1hr}, yr {yr}, month {month_num}\")\n",
    "            if (os.path.isfile(f\"/nfs/a319/gy17m2a/PhD/datadir/UKCP18_every30mins/{resolution}/{em_30mins}/{yrs_range}/{em_30mins}a.pr{yr}{month_num}.nc\")):\n",
    "                print(\"already exists\")\n",
    "            else:\n",
    "                print(f\"Running for month {month_num} in {yr}, for {em_1hr} (which equatees to {em_30mins})\")\n",
    "\n",
    "                ####################################################### \n",
    "                #######################################################\n",
    "                ## Get one month of data - HOURLY\n",
    "                ####################################################### \n",
    "                #######################################################\n",
    "                ### Get a list of filenames for hourly data\n",
    "                general_filename_1hr = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/{em_1hr}/{yrs_range}/pr_rcp85_land-cpm_uk_2.2km_{em_1hr}_1hr_{yr}{month_num}*'\n",
    "                filenames_1hr = []\n",
    "                for filename in glob.glob(general_filename_1hr):\n",
    "                        filenames_1hr.append(filename)\n",
    "                        \n",
    "                # If don't find any files matching this string in the 2001_2020 folder, then check the 1980_2001\n",
    "                if len(filenames_1hr) == 0:\n",
    "                    general_filename_1hr = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_hourly/2.2km_original/{em_1hr}/1980_2001/pr_rcp85_land-cpm_uk_2.2km_{em_1hr}_1hr_{yr}{month_num}*'\n",
    "                    for filename in glob.glob(general_filename_1hr):\n",
    "                            filenames_1hr.append(filename)\n",
    "                print(filenames_1hr)\n",
    "                if len(filenames_1hr) ==0:\n",
    "                    pass\n",
    "                    print(\"No files for this year\")\n",
    "                else:\n",
    "                    # ### Load in the data and remove the ensemble member dimension\n",
    "                    monthly_cubes_list_1hr = iris.load(filenames_1hr)\n",
    "                    cube_1hr = monthly_cubes_list_1hr[0]\n",
    "                    cube_1hr = cube_1hr[0,:,:,:]\n",
    "\n",
    "                    # ### Trim to Leeds\n",
    "                    # cube_1hr = trim_to_bbox_of_region(cube_1hr, leeds_at_centre_gdf)\n",
    "\n",
    "                    #######################################################\n",
    "                    #######################################################\n",
    "                    ## Get one month of data - 30mins\n",
    "                    #######################################################\n",
    "                    #######################################################\n",
    "                    # ### Get all files for this ensemble member\n",
    "                    general_filename_30mins = f'/nfs/a319/gy17m2a/PhD/datadir/UKCP18_first30mins/{yrs_range}/{em_30mins}/{em_30mins}a.pr{yr}{month_num}*'\n",
    "                    filenames_first30mins = []\n",
    "                    for filename_30mins in glob.glob(general_filename_30mins):\n",
    "                        filenames_first30mins.append(filename_30mins)\n",
    "                    filenames_first30mins.sort()\n",
    "\n",
    "                    # ### Load in the data \n",
    "                    monthly_cubes_list_30mins = iris.load(filenames_first30mins)\n",
    "\n",
    "                    # Equalise\n",
    "                    for cube in monthly_cubes_list_30mins:\n",
    "                        for attr in ['forecast_period', 'forecast_reference_time']:\n",
    "                            if attr in cube.attributes:\n",
    "                                del cube.attributes[attr]\n",
    "\n",
    "\n",
    "                    monthly_cube_30mins = monthly_cubes_list_30mins.concatenate_cube()      \n",
    "\n",
    "                    # ### Trim to be the same shape as the hourly data\n",
    "                    # monthly_cube_30mins_1st = trim_to_bbox_of_region_30mins(monthly_cube_30mins, leeds_at_centre_gdf)\n",
    "                    monthly_cube_30mins_1st = monthly_cube_30mins[:,24:-24,24:-24]\n",
    "\n",
    "                    # ### Convert units of 30 mins data\n",
    "                    # Check current units\n",
    "                    # print(monthly_cube_30mins_1st.units)\n",
    "                    # Set the units to those of the 1 hr cube\n",
    "                    monthly_cube_30mins_1st.units = cube_1hr.units\n",
    "                    # print(monthly_cube_30mins_1st.units)\n",
    "\n",
    "                    # Convert the data to also be this unit\n",
    "                    monthly_cube_30mins_1st_data = monthly_cube_30mins_1st.data\n",
    "                    monthly_cube_30mins_1st_data = monthly_cube_30mins_1st_data*3600\n",
    "\n",
    "                    monthly_cube_30mins_1st.data = monthly_cube_30mins_1st_data\n",
    "\n",
    "\n",
    "                    #######################################################\n",
    "                    #######################################################\n",
    "                    ## Find the second half of the hour, using the first half of hour and hourly values\n",
    "                    #######################################################\n",
    "                    #######################################################\n",
    "                    # get the hourly data\n",
    "                    cube_1hr_data = cube_1hr.data\n",
    "                    # calculate value for second half of hour\n",
    "                    second_half_of_the_hour_mean_hourly_rainfall_rate_data = 2*cube_1hr_data-monthly_cube_30mins_1st_data\n",
    "                    # Create a new cube for the second half of the hour (start by copying the first half of hour cube)\n",
    "                    monthly_cube_30mins_2nd = monthly_cube_30mins_1st.copy()\n",
    "                    # Set values as calculated\n",
    "                    monthly_cube_30mins_2nd.data = second_half_of_the_hour_mean_hourly_rainfall_rate_data\n",
    "\n",
    "\n",
    "                    # ### Edit the times to be 30 mins later\n",
    "                    # get the times from the first half hour\n",
    "                    first_half_hour_times = monthly_cube_30mins_1st.coord('time').copy()\n",
    "                    # add 30 mins\n",
    "                    second_half_hour_times = first_half_hour_times + 0.5\n",
    "                    # for the second hald hour cube, remove the time dimension and then re-add the edited one\n",
    "                    monthly_cube_30mins_2nd.remove_coord('time')\n",
    "                    monthly_cube_30mins_2nd.add_dim_coord(second_half_hour_times, 0)\n",
    "\n",
    "                    #######################################################\n",
    "                    #######################################################\n",
    "                    ## Join first half hour and second half hour into one cube\n",
    "                    #######################################################\n",
    "                    #######################################################\n",
    "                    # ### Get a list of all the cubes in each of the monthly cubes\n",
    "                    list_30mins_1st = iris.cube.CubeList(monthly_cube_30mins_1st.slices_over('time'))\n",
    "                    list_30mins_2nd = iris.cube.CubeList(monthly_cube_30mins_2nd.slices_over('time'))\n",
    "                    list_30mins = list_30mins_1st +  list_30mins_2nd\n",
    "\n",
    "                    ### Merge back into one cube\n",
    "                    monthly_cube_30mins = list_30mins.merge_cube()\n",
    "\n",
    "                    #######################################################\n",
    "                    #######################################################\n",
    "                    ## Save\n",
    "                    #######################################################\n",
    "                    #######################################################\n",
    "                    dir_to_save = f\"datadir/UKCP18_every30mins/{resolution}/{em_30mins}/{yrs_range}/\"\n",
    "\n",
    "                    if os.path.isdir(dir_to_save):\n",
    "                        print(\"Exists\")\n",
    "                    else:\n",
    "                        print(\"Doesn't exist\")\n",
    "                        os.makedirs(dir_to_save)\n",
    "                    fp_to_save = f\"datadir/UKCP18_every30mins/{resolution}/{em_30mins}/{yrs_range}/{em_30mins}a.pr{yr}{month_num}.nc\" \n",
    "                    print(fp_to_save)\n",
    "                    iris.save(monthly_cube_30mins, fp_to_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
