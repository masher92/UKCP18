{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footfall data downloaded from the City of Melbourne's Open Data Website:  \n",
    "### https://data.melbourne.vic.gov.au/Transport/Pedestrian-Counting-System-Monthly-counts-per-hour/b2ak-trbp\n",
    "#### By selecting Export --> CSV\n",
    "##### Check where I downloaded the sensor location data from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:29:55.509799Z",
     "start_time": "2020-05-20T09:29:52.577608Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import pedestrian count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_counts = pd.read_csv('Data/Pedestrian_Counting_System_-_Monthly__counts_per_hour_.csv')\n",
    "sensor_locations = pd.read_csv('Data/melbourne_locations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename columns to all lowercase (to facilitate joining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_counts.rename({'Date_Time': 'datetime', 'Year': 'year', 'Month':'month', 'Mdate': 'mdate', \n",
    "                      'Day': 'day', 'Time': 'time', 'Sensor_ID': 'sensor_id', 'Hourly_Counts': 'hourly_counts'}, \n",
    "                     axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_counts.drop(['ID', 'Sensor_Name'], axis = 1, inplace = True)\n",
    "sensor_locations.drop(['sensor_description', 'sensor_name', 'installation_date', 'status', 'note', 'direction_1',\n",
    "                      'direction_2'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join two dataframes so location and count info in same place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_counts = pd.merge(sensor_locations, sensor_counts, on='sensor_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It could be useful to drop sensors that do not have as many recorded countsfor now leaving them in, but may drop in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Properly format datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_counts['datetime'] = pd.to_datetime(location_counts['datetime'], format = '%B %d, %Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order by datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_counts = location_counts.sort_values(by=['datetime'])\n",
    "location_counts.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### September, 2010 dates have problems:\n",
    "All dates have a timestamp of 00:00, presume they are in order of hour of day, for each day there are only 23 hours worth of data\n",
    "For now, in later stages just filter out 2010 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get data for just one sensor\n",
    "# one_sensor =  location_counts[location_counts.sensor_id == 4]\n",
    "# one_year = one_sensor[one_sensor.year==2010]\n",
    "# # Set the datetime as the index\n",
    "# one_sensor.set_index('datetime', inplace = True)\n",
    "# duplicates = one_sensor[one_sensor.index.duplicated()]\n",
    "# for day in duplicates.mdate.unique():\n",
    "#     one_day = duplicates[duplicates.mdate == day]\n",
    "#     print(day, len(one_day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the number of missing hours in each year of data for each sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sensor_data_completeness(sensor_number):\n",
    "    \n",
    "    # Get data for just one sensor\n",
    "    one_sensor =  location_counts[location_counts.sensor_id == sensor_number]\n",
    "\n",
    "    # Go for only years after 2010 where messed up data is\n",
    "    one_sensor = one_sensor[one_sensor.year >2010]\n",
    "    one_sensor = one_sensor.sort_values(by=['datetime'])\n",
    "    \n",
    "    # Save\n",
    "    yearly_missing_vals = {}\n",
    "    \n",
    "    # Loop through each year, find the number of hourly values there are and compare this against\n",
    "    # the number of values there should be in that year (calculated using daterange and the first and last\n",
    "    # hour in the year)\n",
    "    for year in np.sort(one_sensor.year.unique()):\n",
    "        one_year = one_sensor[one_sensor.year==year]\n",
    "        vals_this_year = len(one_year)\n",
    "        expected_vals_this_year = len(pd.date_range(date(year, 1, 1), datetime(year, 12, 31, 23), freq = 'H'))\n",
    "        yearly_missing_vals[year] = expected_vals_this_year - vals_this_year\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    yearly_missing_vals_df = pd.DataFrame.from_dict(yearly_missing_vals, orient='index', columns = [sensor_number])\n",
    "    \n",
    "    return yearly_missing_vals_df\n",
    "\n",
    "def count_number_missing_blocks(sensor_number):\n",
    "    this_sensor = []\n",
    "    for year in location_counts.year.unique()[2:]:\n",
    "        # Get data for just one sensor, in just one year (where there was just one missing value)\n",
    "        one_sensor = location_counts[location_counts.sensor_id == sensor_number].copy()\n",
    "        one_sensor_one_yr = one_sensor[one_sensor.year == year].copy()\n",
    "        one_sensor_one_yr.reset_index(inplace=True)\n",
    "\n",
    "        if len(one_sensor_one_yr) == 0:\n",
    "            this_sensor.append(np.nan)\n",
    "        else:\n",
    "            # Create a new column listing the timedifference between each row and the previous row\n",
    "            one_sensor_one_yr['timediff'] = one_sensor_one_yr['datetime'].diff().apply(lambda x: x/np.timedelta64(1, 'm')).fillna(0).astype('int64')\n",
    "\n",
    "            # Set this value for the first row using a timestamp for the first Jan\n",
    "            first_jan = datetime(year = year, month = 1, day=1, hour=0, minute=0, second=0)\n",
    "            # If the first row is the first of Jan, then set the timediff to be 60 so this doesnt flag as a mising block of data\n",
    "            if one_sensor_one_yr['datetime'].loc[0] == first_jan:\n",
    "                one_sensor_one_yr.at[one_sensor_one_yr.index[0], 'timediff'] = 60\n",
    "            # If it's not the fist_jan, then set it to how many hours are between that timestamp and the first Jan\n",
    "            else:\n",
    "                one_sensor_one_yr.at[one_sensor_one_yr.index[0], 'timediff'] = (one_sensor_one_yr['datetime'].loc[0]-first_jan).days*24                      \n",
    "\n",
    "            # Find the number rows where the time difference with the previous row doesn't equal 60 \n",
    "            number_blocks_of_rows = len(one_sensor_one_yr.loc[one_sensor_one_yr['timediff'] != 60])\n",
    "\n",
    "            # Check the last row is the 23rd hour of 31st December\n",
    "            # If its not, then add 1 to the number of missing rows of data\n",
    "            last_dec = datetime(year = year, month = 12, day=31, hour=23, minute=0, second=0)  \n",
    "            if one_sensor_one_yr['datetime'].loc[len(one_sensor_one_yr)-1] != last_dec:\n",
    "                number_blocks_of_rows+=1\n",
    "\n",
    "            # Add the number missing rows to the list for this sensor    \n",
    "            this_sensor.append(number_blocks_of_rows)\n",
    "            \n",
    "    return this_sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inititalise dataframe to store the number of missing values in each year across all sensors\n",
    "# and the number of blocks in which the missing values are located\n",
    "missing_vals_per_year_all_sensors = pd.DataFrame(None)\n",
    "missing_vals_block_sizes = pd.DataFrame(None)\n",
    "\n",
    "# Get a list of sorted sensor numbers\n",
    "sensor_numbers_sorted =  sorted(location_counts['sensor_id'].unique().tolist())\n",
    "\n",
    "# Loop through each sensor\n",
    "for sensor_number in sensor_numbers_sorted:\n",
    "    # Return dataframes containing the number of missing values/blocks of missing vals in each year\n",
    "    missing_vals_per_year_this_sensor = check_sensor_data_completeness(sensor_number)\n",
    "    missing_vals_block_sizes_this_sensor =  count_number_missing_blocks(sensor_number)\n",
    "    \n",
    "    # Add to dataframes containing values for all sensors\n",
    "    missing_vals_block_sizes[sensor_number] = missing_vals_block_sizes_this_sensor\n",
    "    missing_vals_per_year_all_sensors[sensor_number] = missing_vals_per_year_this_sensor\n",
    "    \n",
    "    # Set index to year names\n",
    "    missing_vals_block_sizes.index = location_counts.year.unique()[2:]\n",
    "    missing_vals_per_year_all_sensors.index = location_counts.year.unique()[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the number of sensors with no data in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_vals_per_year_all_sensors.isna().sum(axis = 1)\n",
    "\n",
    "# for sensor_number in sensor_numbers_sorted:\n",
    "# # missing_vals_per_year_all_sensors.loc[:,1]  \n",
    "# for sensor_number in sensor_numbers_sorted:\n",
    "#     if (missing_vals_per_year_all_sensors[sensor_number] == 0).all() == True:\n",
    "#         print(\"Full data all years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find sensors which don't have any years with absoloutly no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>8472</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2928</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5664</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1609</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2208</td>\n",
       "      <td>2184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1369</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>608</td>\n",
       "      <td>584</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>3649</td>\n",
       "      <td>3096</td>\n",
       "      <td>1</td>\n",
       "      <td>433</td>\n",
       "      <td>433</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>1</td>\n",
       "      <td>2041</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>433</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2256</td>\n",
       "      <td>1056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "      <td>802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2352</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>553</td>\n",
       "      <td>624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1224</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2928</td>\n",
       "      <td>2928</td>\n",
       "      <td>2928</td>\n",
       "      <td>5880</td>\n",
       "      <td>2928</td>\n",
       "      <td>2928</td>\n",
       "      <td>8112</td>\n",
       "      <td>2928</td>\n",
       "      <td>3191</td>\n",
       "      <td>2928</td>\n",
       "      <td>2928</td>\n",
       "      <td>2928</td>\n",
       "      <td>2928</td>\n",
       "      <td>4055</td>\n",
       "      <td>5880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2     3     4     5     6     7     8     9     10    11    12  \\\n",
       "2011  8472     0    24     0     0     0     0     0     0   432     0     0   \n",
       "2012     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2013     1     1     1     1     1     1   409     1     1     1     1  2928   \n",
       "2014  1105     1     1   337     1     1  5664     1     1     1     1     1   \n",
       "2015  1129     1     1     1     1     1  1609   193     1     1     1     1   \n",
       "2016     1     1  2208  2184     1     1  1369    19     4    11   608   584   \n",
       "2017     1     1   577  3649  3096     1   433   433     1     1   577     1   \n",
       "2018     0     0   768     0   264   433    24     0     0     0     0     0   \n",
       "2019   144   240   802     0     0     0  2352   504     0     0   336     0   \n",
       "2020     0     0   120     0     0     0     0   312     0     0     0     0   \n",
       "2021   216     0   504     0     0     1     0     0     0   120     0     0   \n",
       "2022  2928  2928  2928  5880  2928  2928  8112  2928  3191  2928  2928  2928   \n",
       "\n",
       "        14    17    18  \n",
       "2011     0     0     0  \n",
       "2012     0     0     0  \n",
       "2013     1     1     1  \n",
       "2014     1     1     1  \n",
       "2015    49  4320     1  \n",
       "2016     1     2     5  \n",
       "2017  2041     1     1  \n",
       "2018  2256  1056     0  \n",
       "2019   553   624     0  \n",
       "2020  1224   336     0  \n",
       "2021     0     0  1176  \n",
       "2022  2928  4055  5880  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_vals_per_year_all_sensors[missing_vals_per_year_all_sensors.columns[~missing_vals_per_year_all_sensors.isnull().any()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that where there are 0s in the  missing_blocks_sizes_df that there is also a 0 in the dataframe with the number of missing vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Set values over or equal to 1 in both dataframes\n",
    "missing_block_or_not = missing_vals_block_sizes.copy()\n",
    "missing_block_or_not[missing_block_or_not >= 1] = 1\n",
    "missing_vals_or_not = missing_vals_per_year_all_sensors.copy()\n",
    "missing_vals_or_not[missing_vals_or_not >= 1] = 1\n",
    "\n",
    "# Check if they are the same\n",
    "equality  = missing_block_or_not.eq(missing_vals_or_not)|(missing_block_or_not.isna()&missing_vals_or_not.isna())\n",
    "print(np.all(equality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>73</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>8472</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5664</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1609</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2208</td>\n",
       "      <td>2184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1369</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>3649</td>\n",
       "      <td>3096</td>\n",
       "      <td>1</td>\n",
       "      <td>433</td>\n",
       "      <td>433</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>433</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "      <td>802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2352</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8040.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>7272.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>2880.0</td>\n",
       "      <td>2880.0</td>\n",
       "      <td>6073.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2928</td>\n",
       "      <td>2928</td>\n",
       "      <td>2928</td>\n",
       "      <td>5880</td>\n",
       "      <td>2928</td>\n",
       "      <td>2928</td>\n",
       "      <td>8112</td>\n",
       "      <td>2928</td>\n",
       "      <td>3191</td>\n",
       "      <td>2928</td>\n",
       "      <td>...</td>\n",
       "      <td>7344.0</td>\n",
       "      <td>2928.0</td>\n",
       "      <td>2928.0</td>\n",
       "      <td>2928.0</td>\n",
       "      <td>2928.0</td>\n",
       "      <td>3191.0</td>\n",
       "      <td>2928.0</td>\n",
       "      <td>2928.0</td>\n",
       "      <td>3287.0</td>\n",
       "      <td>7272.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2     3     4     5     6     7     8     9     10  ...      73  \\\n",
       "2011  8472     0    24     0     0     0     0     0     0   432  ...     NaN   \n",
       "2012     0     0     0     0     0     0     0     0     0     0  ...     NaN   \n",
       "2013     1     1     1     1     1     1   409     1     1     1  ...     NaN   \n",
       "2014  1105     1     1   337     1     1  5664     1     1     1  ...     NaN   \n",
       "2015  1129     1     1     1     1     1  1609   193     1     1  ...     NaN   \n",
       "2016     1     1  2208  2184     1     1  1369    19     4    11  ...     NaN   \n",
       "2017     1     1   577  3649  3096     1   433   433     1     1  ...     NaN   \n",
       "2018     0     0   768     0   264   433    24     0     0     0  ...     NaN   \n",
       "2019   144   240   802     0     0     0  2352   504     0     0  ...     NaN   \n",
       "2020     0     0   120     0     0     0     0   312     0     0  ...  8040.0   \n",
       "2021   216     0   504     0     0     1     0     0     0   120  ...  7272.0   \n",
       "2022  2928  2928  2928  5880  2928  2928  8112  2928  3191  2928  ...  7344.0   \n",
       "\n",
       "          75      76      77      78      79      84      85      86      87  \n",
       "2011     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2012     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2013     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2014     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2015     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2016     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2017     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2018     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2019     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2020     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2021   744.0  1416.0  2880.0  2880.0  6073.0     NaN     NaN     NaN     NaN  \n",
       "2022  2928.0  2928.0  2928.0  2928.0  3191.0  2928.0  2928.0  3287.0  7272.0  \n",
       "\n",
       "[12 rows x 82 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_vals_per_year_all_sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at trends in sensor counts\n",
    "Look to see which sensors have valid records for a full calendar year at a time. Some sensors were added at later years, and some stop working at points throughout the year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Datasets with city features and location coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Dataset with building information across the city\n",
    " \"Data collected as part of the City of Melbourne's Census of Land Use and Employment (CLUE). The data covers the period 2002-2018. It shows selected building attributes including location, construction year, refurbished year, number of floors above ground, predominant space use, bicycle/shower facilities and building accessibility. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:31:27.922632Z",
     "start_time": "2020-05-20T09:31:25.946315Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buildings = pd.read_csv('Data/Buildings_with_name__age__size__accessibility__and_bicycle_facilities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean buildings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:31:28.192567Z",
     "start_time": "2020-05-20T09:31:28.125456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove columns not needed\n",
    "buildings.drop(['Block ID', 'Property ID', 'Base property ID', 'Building name', 'Construction year', 'Location',\n",
    "                'Street address', 'CLUE small area', 'Refurbished year', 'Has showers', 'Accessibility type description'], axis = 1, inplace = True)\n",
    "# Rename columns\n",
    "buildings.rename({'Census year': 'year', 'Number of floors (above ground)': 'n_floors', \n",
    "                 'Predominant space use': 'building_use', 'Accessibility type': 'access_type',\n",
    "                 'Accessibility rating': 'access_rating', 'Bicycle spaces': 'bike_spaces',\n",
    "                 'x coordinate': 'Longitude', 'y coordinate': 'Latitude'}, axis =1, inplace = True)\n",
    "\n",
    "# Drop 130 buildings that don't have location coordinates\n",
    "buildings.dropna(subset = ['Longitude'], axis = 0, inplace = True)\n",
    "\n",
    "# Keep only buildings from 2010 onwards (as this is when camera data is for)\n",
    "buildings = buildings[buildings['year'] >= 2010]\n",
    "\n",
    "# Shorten variable names for access type, and convert the variable to categorical\n",
    "buildings.access_type = buildings.access_type.replace({'Not determined or not applicable': np.nan, 'Low level of accessibility': 'low', \n",
    "                               'Moderate level of accessibility': 'moderate', 'High level of accessibility': 'high'})\n",
    "cat_type = pd.CategoricalDtype(categories = ['low', 'moderate', 'high'], ordered = True)\n",
    "buildings.access_type = buildings.access_type.astype(cat_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for variables with missing values\n",
    "Columns which have a high proportion of NULL should perhaps be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:31:28.340778Z",
     "start_time": "2020-05-20T09:31:28.213324Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year              0.0\n",
       "n_floors          0.0\n",
       "building_use      0.0\n",
       "access_type      63.3\n",
       "access_rating     8.7\n",
       "bike_spaces      65.2\n",
       "longitude         0.0\n",
       "latitude          0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(buildings.isnull().sum()/len(buildings) * 100,1)\n",
    "# buildings['access_type'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:31:33.073735Z",
     "start_time": "2020-05-20T09:31:32.058428Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#see correlations\n",
    "# sns.heatmap(buildings.corr(), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.to_csv('Cleaned_data/buildings_clean.csv', header = buildings.columns, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Dataset with Landmarks & Places of Interest\n",
    "\"This dataset contains a description and co-ordinates of places of interest within the City of Melbourne.\n",
    "\n",
    "Themes include: Community Use, Education Centre, Health Services, Leisure/Recreation, Mixed Use, Office, Place Of Assembly, Place of Worship, Purpose Built, Retail, Transport, Vacant Land\n",
    "\n",
    "Sub-themes include: Art Gallery/Museum, Church, Function/Conference/Exhibition Centre, Informal Outdoor Facility (Park/Garden/Reserve), Major Sports & Recreation Facility, Office, Public Buildings, Public Hospital, Railway Station, Retail/Office/Carpark, Tertiary (University), Theatre Live\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:39:10.390156Z",
     "start_time": "2020-05-20T09:39:10.334812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "landmarks = pd.read_csv('Data/Landmarks_and_places_of_interest__including_schools__theatres__health_services__sports_facilities__places_of_worship__galleries_and_museums..csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning landmarks dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:39:11.396173Z",
     "start_time": "2020-05-20T09:39:11.380519Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check whether any of the variables have missing data\n",
    "landmarks.isnull().sum()\n",
    "\n",
    "# Split co-ordinates into latitude and longitude columns like building data is in\n",
    "split_data = landmarks['Co-ordinates'].str.strip(')').str.strip('(').str.split(', ')\n",
    "landmarks['latitude'] = split_data.apply(lambda x: x[0])\n",
    "landmarks['longitude'] = split_data.apply(lambda x: x[1])\n",
    "landmarks.drop('Co-ordinates', axis = 1, inplace = True)\n",
    "\n",
    "# Rename columns\n",
    "landmarks.rename({'Theme': 'theme', 'Sub Theme': 'sub_theme', 'Feature Name': 'feature_name'}, axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print a summary of the kind of landmarks present in the dataset by theme and subtheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:40:51.802436Z",
     "start_time": "2020-05-20T09:40:51.773986Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# landmarks.groupby(['theme', 'sub_theme'])['sub_theme'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks.to_csv('Cleaned_data/landmarks_clean.csv', header = landmarks.columns, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Dataset with Bike Share Locations and capacity\n",
    "### Even though this program ended in 2019, the docks were in use for the majority of years that this analysis will use\n",
    "\"This dataset show the historical Melbourne Bike Share docks. This program came to an end in November 2019.\n",
    "\n",
    "Contains the bike share dock locations that were deployed across Melbourne as part of the Melbourne Bike Share Program.\n",
    "\n",
    "Melbourne Bike Share is a joint RACV/Victorian Government bicycle hire scheme. It allows commuters to hire a bike from a dock location and return it to another dock location in the city. This dataset contains the bike share dock locations and capacity across the city.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:45:41.185902Z",
     "start_time": "2020-05-20T09:45:41.155449Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('Data/Bike_Share_Dock_Locations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean bike share data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:45:41.609798Z",
     "start_time": "2020-05-20T09:45:41.595211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check for variables with missing values\n",
    "bikes.isnull().sum()\n",
    "# Remove unneeded columns\n",
    "bikes.drop(['rental_method', 'location', 'name'], axis =1, inplace= True)\n",
    "# Rename columns\n",
    "bikes.rename({'lat': 'latitude', 'lon': 'longitude'}, axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## City Lighting\n",
    "\"This dataset contains information such as location, lighting type and wattage of feature lighting across City of Melbourne.\n",
    "\n",
    "Feature lights are usually found around high profile areas of the city.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:47:03.550685Z",
     "start_time": "2020-05-20T09:47:03.456493Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lights = pd.read_csv('Data/Feature_Lighting__including_light_type__wattage_and_location_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean lighting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:47:04.896043Z",
     "start_time": "2020-05-20T09:47:04.881063Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check for variables with missing values\n",
    "lights.isnull().sum()\n",
    "# Remove unneeded columns\n",
    "lights.drop(['asset_number', 'asset_description', 'mounting_type_lupvalue', 'location'], axis = 1, inplace = True)\n",
    "# Rename columns\n",
    "lights.rename({'lat': 'latitude', 'lon': 'longitude'}, axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "lights.to_csv('Cleaned_data/lights_clean.csv', header = lights.columns, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Street Infrastructure\n",
    "\"The City of Melbourne owns and maintains various objects and pieces of equipment installed on streets and roads for various purposes. This dataset includes Barbeques, Bicycle Rails, Bin Corrals, Bollards, Drinking Fountains, Floral Crate/Planter Boxs, Hoops, Horse Troughs, Information Pillars, Litter Bins, Picnic Setting, Seats.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:50:50.055125Z",
     "start_time": "2020-05-20T09:50:49.753058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "street_inf = pd.read_csv('Data/Street_furniture_including_bollards__bicycle_rails__bins__drinking_fountains__horse_troughs__planter_boxes__seats__barbecues.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:50:50.112124Z",
     "start_time": "2020-05-20T09:50:50.063476Z"
    },
    "hidden": true
   },
   "source": [
    "#### Clean street infrastructure dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:50:50.214563Z",
     "start_time": "2020-05-20T09:50:50.202595Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check for variables with missing values\n",
    "street_inf.isnull().sum()\n",
    "\n",
    "# Drop unneeded columns\n",
    "street_inf.drop(['GIS_ID', 'DESCRIPTION', 'MODEL_NO', 'MODEL_DESCR', 'DIVISION', 'COMPANY',\n",
    "                'LOCATION_DESC', 'EVALUATION_DATE', 'EASTING', 'NORTHING', 'UploadDate'], axis = 1, inplace = True)\n",
    "\n",
    "# Split coordinates into lat/long coordinate columns\n",
    "split_data = street_inf['CoordinateLocation'].str.strip(')').str.strip('(').str.split(', ')\n",
    "street_inf['latitude'] = split_data.apply(lambda x: x[0])\n",
    "street_inf['longitude'] = split_data.apply(lambda x: x[1])\n",
    "street_inf.drop('CoordinateLocation', axis = 1, inplace = True)\n",
    "\n",
    "# Rename columns to be only lowercase\n",
    "street_inf.rename({'ASSET_CLASS': 'asset_class', 'ASSET_TYPE': 'feature', 'CONDITION_RATING': 'condition_rating'},\n",
    "                 axis = 1, inplace = True)\n",
    "\n",
    "# Drop the asset class as the only value present is street furniture\n",
    "street_inf.drop('asset_class', axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T09:51:22.686738Z",
     "start_time": "2020-05-20T09:51:22.532787Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "street_inf.to_csv('Cleaned_data/street_inf_clean.csv', header = street_inf.columns, index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
